{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c977cfb4-5797-42fd-82c4-fb7e4a6e5804",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "\n",
      "============================================================\n",
      "开始实验配置: TinyImageNet_ResNet-18_pretrained\n",
      "Dataset: TinyImageNet (Root: ./tiny-imagenet-200, Classes: 200, Input Size: 224)\n",
      "Backbone: ResNet-18_pretrained\n",
      "Max Epochs: 200, Patience: 15, LR: 0.0001\n",
      "Osc Params: alpha=2.0, beta=0.1, gamma=0.1, omega=1.0, dt=0.05\n",
      "Lorenz Params: sigma=10.00, rho=28.00, beta=2.67, dt=0.05\n",
      "SNN Params: steps=5, decay_beta=0.95, chaos_dim=64\n",
      "============================================================\n",
      "Tiny ImageNet - Found 100000 training images belonging to 200 classes.\n",
      "Tiny ImageNet - Found 10000 validation images.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "\n",
      "--- Training Baseline (CNN-ANN) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 4.4196 Train Acc: 8.08% Test Acc: 19.44% Total Spikes: 0 Epoch Time: 50.72s LR: 1.0e-05\n",
      "  -> New best test accuracy: 19.44%. Model saved.\n",
      "Epoch [2/200] Loss: 3.1506 Train Acc: 25.75% Test Acc: 32.55% Total Spikes: 0 Epoch Time: 50.73s LR: 1.0e-05\n",
      "  -> New best test accuracy: 32.55%. Model saved.\n",
      "Epoch [3/200] Loss: 2.6059 Train Acc: 37.20% Test Acc: 41.86% Total Spikes: 0 Epoch Time: 51.74s LR: 1.0e-05\n",
      "  -> New best test accuracy: 41.86%. Model saved.\n",
      "Epoch [4/200] Loss: 2.2652 Train Acc: 44.76% Test Acc: 47.62% Total Spikes: 0 Epoch Time: 51.73s LR: 1.0e-05\n",
      "  -> New best test accuracy: 47.62%. Model saved.\n",
      "Epoch [5/200] Loss: 2.0300 Train Acc: 50.18% Test Acc: 51.00% Total Spikes: 0 Epoch Time: 52.46s LR: 1.0e-05\n",
      "  -> New best test accuracy: 51.00%. Model saved.\n",
      "Epoch [6/200] Loss: 1.8391 Train Acc: 54.54% Test Acc: 54.22% Total Spikes: 0 Epoch Time: 52.85s LR: 1.0e-05\n",
      "  -> New best test accuracy: 54.22%. Model saved.\n",
      "Epoch [7/200] Loss: 1.6943 Train Acc: 57.75% Test Acc: 56.36% Total Spikes: 0 Epoch Time: 51.14s LR: 1.0e-05\n",
      "  -> New best test accuracy: 56.36%. Model saved.\n",
      "Epoch [8/200] Loss: 1.5751 Train Acc: 60.70% Test Acc: 58.51% Total Spikes: 0 Epoch Time: 50.97s LR: 1.0e-05\n",
      "  -> New best test accuracy: 58.51%. Model saved.\n",
      "Epoch [9/200] Loss: 1.4649 Train Acc: 62.97% Test Acc: 59.37% Total Spikes: 0 Epoch Time: 51.07s LR: 1.0e-05\n",
      "  -> New best test accuracy: 59.37%. Model saved.\n",
      "Epoch [10/200] Loss: 1.3723 Train Acc: 64.80% Test Acc: 60.36% Total Spikes: 0 Epoch Time: 51.09s LR: 1.0e-05\n",
      "  -> New best test accuracy: 60.36%. Model saved.\n",
      "Epoch [11/200] Loss: 1.2843 Train Acc: 66.92% Test Acc: 60.86% Total Spikes: 0 Epoch Time: 50.95s LR: 9.9e-06\n",
      "  -> New best test accuracy: 60.86%. Model saved.\n",
      "Epoch [12/200] Loss: 1.2083 Train Acc: 68.31% Test Acc: 61.69% Total Spikes: 0 Epoch Time: 51.06s LR: 9.9e-06\n",
      "  -> New best test accuracy: 61.69%. Model saved.\n",
      "Epoch [13/200] Loss: 1.1420 Train Acc: 69.88% Test Acc: 62.38% Total Spikes: 0 Epoch Time: 51.15s LR: 9.9e-06\n",
      "  -> New best test accuracy: 62.38%. Model saved.\n",
      "Epoch [14/200] Loss: 1.0858 Train Acc: 71.14% Test Acc: 62.70% Total Spikes: 0 Epoch Time: 51.19s LR: 9.9e-06\n",
      "  -> New best test accuracy: 62.70%. Model saved.\n",
      "Epoch [15/200] Loss: 1.0225 Train Acc: 72.56% Test Acc: 63.34% Total Spikes: 0 Epoch Time: 52.06s LR: 9.9e-06\n",
      "  -> New best test accuracy: 63.34%. Model saved.\n",
      "Epoch [16/200] Loss: 0.9712 Train Acc: 73.85% Test Acc: 63.13% Total Spikes: 0 Epoch Time: 51.25s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 63.34%\n",
      "Epoch [17/200] Loss: 0.9191 Train Acc: 74.95% Test Acc: 63.28% Total Spikes: 0 Epoch Time: 51.00s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 63.34%\n",
      "Epoch [18/200] Loss: 0.8679 Train Acc: 76.11% Test Acc: 63.81% Total Spikes: 0 Epoch Time: 51.04s LR: 9.8e-06\n",
      "  -> New best test accuracy: 63.81%. Model saved.\n",
      "Epoch [19/200] Loss: 0.8264 Train Acc: 77.28% Test Acc: 63.64% Total Spikes: 0 Epoch Time: 50.99s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 63.81%\n",
      "Epoch [20/200] Loss: 0.7842 Train Acc: 78.15% Test Acc: 63.99% Total Spikes: 0 Epoch Time: 51.40s LR: 9.8e-06\n",
      "  -> New best test accuracy: 63.99%. Model saved.\n",
      "Epoch [21/200] Loss: 0.7397 Train Acc: 79.30% Test Acc: 64.26% Total Spikes: 0 Epoch Time: 51.25s LR: 9.8e-06\n",
      "  -> New best test accuracy: 64.26%. Model saved.\n",
      "Epoch [22/200] Loss: 0.7006 Train Acc: 80.23% Test Acc: 63.76% Total Spikes: 0 Epoch Time: 51.39s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 64.26%\n",
      "Epoch [23/200] Loss: 0.6619 Train Acc: 81.26% Test Acc: 63.81% Total Spikes: 0 Epoch Time: 51.27s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 64.26%\n",
      "Epoch [24/200] Loss: 0.6361 Train Acc: 81.81% Test Acc: 63.90% Total Spikes: 0 Epoch Time: 51.80s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 64.26%\n",
      "Epoch [25/200] Loss: 0.6020 Train Acc: 82.74% Test Acc: 64.20% Total Spikes: 0 Epoch Time: 51.20s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 64.26%\n",
      "Epoch [26/200] Loss: 0.5699 Train Acc: 83.58% Test Acc: 64.15% Total Spikes: 0 Epoch Time: 51.26s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 64.26%\n",
      "Epoch [27/200] Loss: 0.5398 Train Acc: 84.37% Test Acc: 64.15% Total Spikes: 0 Epoch Time: 51.58s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 64.26%\n",
      "Epoch [28/200] Loss: 0.5093 Train Acc: 85.26% Test Acc: 64.01% Total Spikes: 0 Epoch Time: 51.33s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 64.26%\n",
      "Epoch [29/200] Loss: 0.4856 Train Acc: 85.83% Test Acc: 63.99% Total Spikes: 0 Epoch Time: 51.45s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 64.26%\n",
      "Epoch [30/200] Loss: 0.4652 Train Acc: 86.41% Test Acc: 63.83% Total Spikes: 0 Epoch Time: 51.55s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 64.26%\n",
      "Epoch [31/200] Loss: 0.4367 Train Acc: 87.05% Test Acc: 64.10% Total Spikes: 0 Epoch Time: 51.37s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 64.26%\n",
      "Epoch [32/200] Loss: 0.4230 Train Acc: 87.49% Test Acc: 64.38% Total Spikes: 0 Epoch Time: 51.08s LR: 9.4e-06\n",
      "  -> New best test accuracy: 64.38%. Model saved.\n",
      "Epoch [33/200] Loss: 0.3957 Train Acc: 88.32% Test Acc: 64.17% Total Spikes: 0 Epoch Time: 51.19s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 64.38%\n",
      "Epoch [34/200] Loss: 0.3782 Train Acc: 88.77% Test Acc: 64.37% Total Spikes: 0 Epoch Time: 50.98s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 64.38%\n",
      "Epoch [35/200] Loss: 0.3642 Train Acc: 89.26% Test Acc: 64.28% Total Spikes: 0 Epoch Time: 50.94s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 64.38%\n",
      "Epoch [36/200] Loss: 0.3474 Train Acc: 89.67% Test Acc: 64.32% Total Spikes: 0 Epoch Time: 51.36s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 64.38%\n",
      "Epoch [37/200] Loss: 0.3296 Train Acc: 90.17% Test Acc: 64.34% Total Spikes: 0 Epoch Time: 51.01s LR: 9.2e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 64.38%\n",
      "Epoch [38/200] Loss: 0.3134 Train Acc: 90.60% Test Acc: 64.13% Total Spikes: 0 Epoch Time: 50.81s LR: 9.2e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 64.38%\n",
      "Epoch [39/200] Loss: 0.3010 Train Acc: 91.10% Test Acc: 64.32% Total Spikes: 0 Epoch Time: 50.93s LR: 9.1e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 64.38%\n",
      "Epoch [40/200] Loss: 0.2835 Train Acc: 91.46% Test Acc: 64.26% Total Spikes: 0 Epoch Time: 51.31s LR: 9.1e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 64.38%\n",
      "Epoch [41/200] Loss: 0.2739 Train Acc: 91.78% Test Acc: 64.54% Total Spikes: 0 Epoch Time: 51.02s LR: 9.0e-06\n",
      "  -> New best test accuracy: 64.54%. Model saved.\n",
      "Epoch [42/200] Loss: 0.2655 Train Acc: 92.11% Test Acc: 64.50% Total Spikes: 0 Epoch Time: 50.93s LR: 9.0e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 64.54%\n",
      "Epoch [43/200] Loss: 0.2494 Train Acc: 92.53% Test Acc: 64.84% Total Spikes: 0 Epoch Time: 51.74s LR: 9.0e-06\n",
      "  -> New best test accuracy: 64.84%. Model saved.\n",
      "Epoch [44/200] Loss: 0.2405 Train Acc: 92.87% Test Acc: 64.32% Total Spikes: 0 Epoch Time: 51.86s LR: 8.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 64.84%\n",
      "Epoch [45/200] Loss: 0.2278 Train Acc: 93.18% Test Acc: 63.95% Total Spikes: 0 Epoch Time: 51.71s LR: 8.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 64.84%\n",
      "Epoch [46/200] Loss: 0.2231 Train Acc: 93.30% Test Acc: 63.78% Total Spikes: 0 Epoch Time: 51.85s LR: 8.8e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 64.84%\n",
      "Epoch [47/200] Loss: 0.2145 Train Acc: 93.58% Test Acc: 64.38% Total Spikes: 0 Epoch Time: 51.55s LR: 8.8e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 64.84%\n",
      "Epoch [48/200] Loss: 0.2028 Train Acc: 93.98% Test Acc: 64.05% Total Spikes: 0 Epoch Time: 51.45s LR: 8.7e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 64.84%\n",
      "Epoch [49/200] Loss: 0.1974 Train Acc: 94.21% Test Acc: 64.06% Total Spikes: 0 Epoch Time: 51.54s LR: 8.6e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 64.84%\n",
      "Epoch [50/200] Loss: 0.1900 Train Acc: 94.35% Test Acc: 64.04% Total Spikes: 0 Epoch Time: 51.60s LR: 8.6e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 64.84%\n",
      "Epoch [51/200] Loss: 0.1830 Train Acc: 94.65% Test Acc: 64.30% Total Spikes: 0 Epoch Time: 51.50s LR: 8.5e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 64.84%\n",
      "Epoch [52/200] Loss: 0.1754 Train Acc: 94.83% Test Acc: 64.33% Total Spikes: 0 Epoch Time: 51.19s LR: 8.5e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 64.84%\n",
      "Epoch [53/200] Loss: 0.1666 Train Acc: 95.17% Test Acc: 64.42% Total Spikes: 0 Epoch Time: 51.27s LR: 8.4e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 64.84%\n",
      "Epoch [54/200] Loss: 0.1628 Train Acc: 95.20% Test Acc: 64.50% Total Spikes: 0 Epoch Time: 51.53s LR: 8.4e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 64.84%\n",
      "Epoch [55/200] Loss: 0.1589 Train Acc: 95.37% Test Acc: 64.51% Total Spikes: 0 Epoch Time: 50.87s LR: 8.3e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 64.84%\n",
      "Epoch [56/200] Loss: 0.1498 Train Acc: 95.69% Test Acc: 64.15% Total Spikes: 0 Epoch Time: 51.50s LR: 8.2e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 64.84%\n",
      "Epoch [57/200] Loss: 0.1470 Train Acc: 95.77% Test Acc: 64.33% Total Spikes: 0 Epoch Time: 51.55s LR: 8.2e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 64.84%\n",
      "Epoch [58/200] Loss: 0.1422 Train Acc: 95.90% Test Acc: 64.56% Total Spikes: 0 Epoch Time: 51.43s LR: 8.1e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 64.84%\n",
      "\n",
      "--- Early stopping triggered after 58 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 64.84%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 64.84%\n",
      "--- Baseline (CNN-ANN) finished. Best Acc: 64.84%, Spikes at Convergence (Epoch 43): 0, Time: 3206.45s, Epochs Trained: 58 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Baseline (CNN-ANN): Best Acc=64.84, Spikes at Convergence=0, Time=3206.45s, Epochs=58, Convergence Epoch=43\n",
      "\n",
      "--- Training Baseline (CNN-SNN) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 4.9666 Train Acc: 13.06% Test Acc: 28.14% Total Spikes: 2099820 Epoch Time: 53.02s LR: 1.0e-05\n",
      "  -> New best test accuracy: 28.14%. Model saved.\n",
      "Epoch [2/200] Loss: 4.3290 Train Acc: 31.87% Test Acc: 37.89% Total Spikes: 2312874 Epoch Time: 53.20s LR: 1.0e-05\n",
      "  -> New best test accuracy: 37.89%. Model saved.\n",
      "Epoch [3/200] Loss: 3.8087 Train Acc: 39.44% Test Acc: 43.08% Total Spikes: 2367307 Epoch Time: 53.28s LR: 1.0e-05\n",
      "  -> New best test accuracy: 43.08%. Model saved.\n",
      "Epoch [4/200] Loss: 3.3865 Train Acc: 44.42% Test Acc: 47.15% Total Spikes: 2432069 Epoch Time: 53.18s LR: 1.0e-05\n",
      "  -> New best test accuracy: 47.15%. Model saved.\n",
      "Epoch [5/200] Loss: 3.0435 Train Acc: 48.86% Test Acc: 50.92% Total Spikes: 2457451 Epoch Time: 53.12s LR: 1.0e-05\n",
      "  -> New best test accuracy: 50.92%. Model saved.\n",
      "Epoch [6/200] Loss: 2.7626 Train Acc: 52.53% Test Acc: 53.62% Total Spikes: 2475292 Epoch Time: 53.40s LR: 1.0e-05\n",
      "  -> New best test accuracy: 53.62%. Model saved.\n",
      "Epoch [7/200] Loss: 2.5321 Train Acc: 55.85% Test Acc: 55.81% Total Spikes: 2496185 Epoch Time: 53.17s LR: 1.0e-05\n",
      "  -> New best test accuracy: 55.81%. Model saved.\n",
      "Epoch [8/200] Loss: 2.3394 Train Acc: 58.82% Test Acc: 57.90% Total Spikes: 2505862 Epoch Time: 53.41s LR: 1.0e-05\n",
      "  -> New best test accuracy: 57.90%. Model saved.\n",
      "Epoch [9/200] Loss: 2.1806 Train Acc: 61.04% Test Acc: 60.09% Total Spikes: 2532649 Epoch Time: 53.23s LR: 1.0e-05\n",
      "  -> New best test accuracy: 60.09%. Model saved.\n",
      "Epoch [10/200] Loss: 2.0461 Train Acc: 63.26% Test Acc: 60.92% Total Spikes: 2524091 Epoch Time: 53.21s LR: 1.0e-05\n",
      "  -> New best test accuracy: 60.92%. Model saved.\n",
      "Epoch [11/200] Loss: 1.9278 Train Acc: 65.08% Test Acc: 62.12% Total Spikes: 2543899 Epoch Time: 53.17s LR: 9.9e-06\n",
      "  -> New best test accuracy: 62.12%. Model saved.\n",
      "Epoch [12/200] Loss: 1.8245 Train Acc: 66.85% Test Acc: 62.60% Total Spikes: 2520962 Epoch Time: 53.34s LR: 9.9e-06\n",
      "  -> New best test accuracy: 62.60%. Model saved.\n",
      "Epoch [13/200] Loss: 1.7338 Train Acc: 68.35% Test Acc: 64.22% Total Spikes: 2528464 Epoch Time: 53.37s LR: 9.9e-06\n",
      "  -> New best test accuracy: 64.22%. Model saved.\n",
      "Epoch [14/200] Loss: 1.6578 Train Acc: 69.65% Test Acc: 64.82% Total Spikes: 2562654 Epoch Time: 53.20s LR: 9.9e-06\n",
      "  -> New best test accuracy: 64.82%. Model saved.\n",
      "Epoch [15/200] Loss: 1.5878 Train Acc: 71.08% Test Acc: 65.26% Total Spikes: 2542019 Epoch Time: 53.35s LR: 9.9e-06\n",
      "  -> New best test accuracy: 65.26%. Model saved.\n",
      "Epoch [16/200] Loss: 1.5204 Train Acc: 72.02% Test Acc: 65.91% Total Spikes: 2539343 Epoch Time: 53.18s LR: 9.9e-06\n",
      "  -> New best test accuracy: 65.91%. Model saved.\n",
      "Epoch [17/200] Loss: 1.4627 Train Acc: 73.18% Test Acc: 66.49% Total Spikes: 2537843 Epoch Time: 53.07s LR: 9.8e-06\n",
      "  -> New best test accuracy: 66.49%. Model saved.\n",
      "Epoch [18/200] Loss: 1.4108 Train Acc: 74.08% Test Acc: 66.60% Total Spikes: 2548219 Epoch Time: 53.16s LR: 9.8e-06\n",
      "  -> New best test accuracy: 66.60%. Model saved.\n",
      "Epoch [19/200] Loss: 1.3638 Train Acc: 75.01% Test Acc: 67.48% Total Spikes: 2546735 Epoch Time: 53.27s LR: 9.8e-06\n",
      "  -> New best test accuracy: 67.48%. Model saved.\n",
      "Epoch [20/200] Loss: 1.3196 Train Acc: 75.92% Test Acc: 68.01% Total Spikes: 2548256 Epoch Time: 53.42s LR: 9.8e-06\n",
      "  -> New best test accuracy: 68.01%. Model saved.\n",
      "Epoch [21/200] Loss: 1.2780 Train Acc: 76.65% Test Acc: 68.30% Total Spikes: 2549140 Epoch Time: 53.15s LR: 9.8e-06\n",
      "  -> New best test accuracy: 68.30%. Model saved.\n",
      "Epoch [22/200] Loss: 1.2403 Train Acc: 77.53% Test Acc: 68.19% Total Spikes: 2562558 Epoch Time: 53.36s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 68.30%\n",
      "Epoch [23/200] Loss: 1.2020 Train Acc: 78.19% Test Acc: 68.46% Total Spikes: 2537671 Epoch Time: 53.24s LR: 9.7e-06\n",
      "  -> New best test accuracy: 68.46%. Model saved.\n",
      "Epoch [24/200] Loss: 1.1697 Train Acc: 78.84% Test Acc: 68.92% Total Spikes: 2553152 Epoch Time: 52.93s LR: 9.7e-06\n",
      "  -> New best test accuracy: 68.92%. Model saved.\n",
      "Epoch [25/200] Loss: 1.1365 Train Acc: 79.59% Test Acc: 69.13% Total Spikes: 2551621 Epoch Time: 53.31s LR: 9.6e-06\n",
      "  -> New best test accuracy: 69.13%. Model saved.\n",
      "Epoch [26/200] Loss: 1.1075 Train Acc: 80.25% Test Acc: 68.92% Total Spikes: 2554902 Epoch Time: 53.46s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 69.13%\n",
      "Epoch [27/200] Loss: 1.0768 Train Acc: 80.78% Test Acc: 69.27% Total Spikes: 2540030 Epoch Time: 53.27s LR: 9.6e-06\n",
      "  -> New best test accuracy: 69.27%. Model saved.\n",
      "Epoch [28/200] Loss: 1.0516 Train Acc: 81.32% Test Acc: 69.61% Total Spikes: 2546315 Epoch Time: 53.07s LR: 9.6e-06\n",
      "  -> New best test accuracy: 69.61%. Model saved.\n",
      "Epoch [29/200] Loss: 1.0248 Train Acc: 82.04% Test Acc: 69.84% Total Spikes: 2556087 Epoch Time: 53.25s LR: 9.5e-06\n",
      "  -> New best test accuracy: 69.84%. Model saved.\n",
      "Epoch [30/200] Loss: 1.0003 Train Acc: 82.50% Test Acc: 70.07% Total Spikes: 2524215 Epoch Time: 53.09s LR: 9.5e-06\n",
      "  -> New best test accuracy: 70.07%. Model saved.\n",
      "Epoch [31/200] Loss: 0.9810 Train Acc: 83.10% Test Acc: 69.40% Total Spikes: 2538480 Epoch Time: 53.19s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 70.07%\n",
      "Epoch [32/200] Loss: 0.9577 Train Acc: 83.43% Test Acc: 70.04% Total Spikes: 2560110 Epoch Time: 53.40s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 70.07%\n",
      "Epoch [33/200] Loss: 0.9350 Train Acc: 84.04% Test Acc: 69.86% Total Spikes: 2541600 Epoch Time: 53.40s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 70.07%\n",
      "Epoch [34/200] Loss: 0.9147 Train Acc: 84.55% Test Acc: 70.35% Total Spikes: 2563033 Epoch Time: 53.41s LR: 9.3e-06\n",
      "  -> New best test accuracy: 70.35%. Model saved.\n",
      "Epoch [35/200] Loss: 0.8904 Train Acc: 85.27% Test Acc: 70.14% Total Spikes: 2556818 Epoch Time: 53.05s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 70.35%\n",
      "Epoch [36/200] Loss: 0.8720 Train Acc: 85.49% Test Acc: 70.11% Total Spikes: 2552554 Epoch Time: 52.95s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 70.35%\n",
      "Epoch [37/200] Loss: 0.8520 Train Acc: 86.03% Test Acc: 70.58% Total Spikes: 2536371 Epoch Time: 52.98s LR: 9.2e-06\n",
      "  -> New best test accuracy: 70.58%. Model saved.\n",
      "Epoch [38/200] Loss: 0.8352 Train Acc: 86.47% Test Acc: 70.60% Total Spikes: 2539981 Epoch Time: 53.19s LR: 9.2e-06\n",
      "  -> New best test accuracy: 70.60%. Model saved.\n",
      "Epoch [39/200] Loss: 0.8180 Train Acc: 86.74% Test Acc: 70.45% Total Spikes: 2544436 Epoch Time: 53.07s LR: 9.1e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 70.60%\n",
      "Epoch [40/200] Loss: 0.8012 Train Acc: 87.27% Test Acc: 70.43% Total Spikes: 2544741 Epoch Time: 52.80s LR: 9.1e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 70.60%\n",
      "Epoch [41/200] Loss: 0.7858 Train Acc: 87.57% Test Acc: 70.31% Total Spikes: 2539021 Epoch Time: 53.17s LR: 9.0e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 70.60%\n",
      "Epoch [42/200] Loss: 0.7699 Train Acc: 87.92% Test Acc: 70.51% Total Spikes: 2542883 Epoch Time: 53.34s LR: 9.0e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 70.60%\n",
      "Epoch [43/200] Loss: 0.7532 Train Acc: 88.39% Test Acc: 70.66% Total Spikes: 2540983 Epoch Time: 52.93s LR: 9.0e-06\n",
      "  -> New best test accuracy: 70.66%. Model saved.\n",
      "Epoch [44/200] Loss: 0.7380 Train Acc: 88.67% Test Acc: 70.52% Total Spikes: 2536227 Epoch Time: 53.13s LR: 8.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 70.66%\n",
      "Epoch [45/200] Loss: 0.7262 Train Acc: 89.03% Test Acc: 70.59% Total Spikes: 2547862 Epoch Time: 53.22s LR: 8.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 70.66%\n",
      "Epoch [46/200] Loss: 0.7112 Train Acc: 89.37% Test Acc: 70.65% Total Spikes: 2558365 Epoch Time: 53.16s LR: 8.8e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 70.66%\n",
      "Epoch [47/200] Loss: 0.6966 Train Acc: 89.69% Test Acc: 70.27% Total Spikes: 2545225 Epoch Time: 53.16s LR: 8.8e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 70.66%\n",
      "Epoch [48/200] Loss: 0.6846 Train Acc: 89.99% Test Acc: 70.57% Total Spikes: 2538579 Epoch Time: 53.38s LR: 8.7e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 70.66%\n",
      "Epoch [49/200] Loss: 0.6728 Train Acc: 90.31% Test Acc: 70.48% Total Spikes: 2538290 Epoch Time: 53.19s LR: 8.6e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 70.66%\n",
      "Epoch [50/200] Loss: 0.6603 Train Acc: 90.63% Test Acc: 70.70% Total Spikes: 2545019 Epoch Time: 53.21s LR: 8.6e-06\n",
      "  -> New best test accuracy: 70.70%. Model saved.\n",
      "Epoch [51/200] Loss: 0.6477 Train Acc: 90.90% Test Acc: 70.68% Total Spikes: 2547245 Epoch Time: 53.31s LR: 8.5e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 70.70%\n",
      "Epoch [52/200] Loss: 0.6367 Train Acc: 91.12% Test Acc: 70.48% Total Spikes: 2544327 Epoch Time: 53.37s LR: 8.5e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 70.70%\n",
      "Epoch [53/200] Loss: 0.6271 Train Acc: 91.29% Test Acc: 70.42% Total Spikes: 2552188 Epoch Time: 53.34s LR: 8.4e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 70.70%\n",
      "Epoch [54/200] Loss: 0.6134 Train Acc: 91.68% Test Acc: 70.61% Total Spikes: 2546486 Epoch Time: 53.44s LR: 8.4e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 70.70%\n",
      "Epoch [55/200] Loss: 0.6065 Train Acc: 91.80% Test Acc: 70.57% Total Spikes: 2535875 Epoch Time: 53.04s LR: 8.3e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 70.70%\n",
      "Epoch [56/200] Loss: 0.5950 Train Acc: 92.16% Test Acc: 70.58% Total Spikes: 2548463 Epoch Time: 53.07s LR: 8.2e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 70.70%\n",
      "Epoch [57/200] Loss: 0.5850 Train Acc: 92.40% Test Acc: 70.72% Total Spikes: 2540882 Epoch Time: 53.16s LR: 8.2e-06\n",
      "  -> New best test accuracy: 70.72%. Model saved.\n",
      "Epoch [58/200] Loss: 0.5762 Train Acc: 92.55% Test Acc: 70.77% Total Spikes: 2537163 Epoch Time: 53.10s LR: 8.1e-06\n",
      "  -> New best test accuracy: 70.77%. Model saved.\n",
      "Epoch [59/200] Loss: 0.5692 Train Acc: 92.79% Test Acc: 70.40% Total Spikes: 2540070 Epoch Time: 53.12s LR: 8.1e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 70.77%\n",
      "Epoch [60/200] Loss: 0.5578 Train Acc: 93.03% Test Acc: 70.42% Total Spikes: 2534504 Epoch Time: 53.41s LR: 8.0e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 70.77%\n",
      "Epoch [61/200] Loss: 0.5489 Train Acc: 93.26% Test Acc: 70.55% Total Spikes: 2537552 Epoch Time: 53.19s LR: 7.9e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 70.77%\n",
      "Epoch [62/200] Loss: 0.5402 Train Acc: 93.41% Test Acc: 70.19% Total Spikes: 2536623 Epoch Time: 52.97s LR: 7.9e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 70.77%\n",
      "Epoch [63/200] Loss: 0.5338 Train Acc: 93.57% Test Acc: 70.48% Total Spikes: 2531547 Epoch Time: 53.12s LR: 7.8e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 70.77%\n",
      "Epoch [64/200] Loss: 0.5256 Train Acc: 93.79% Test Acc: 70.41% Total Spikes: 2528728 Epoch Time: 53.52s LR: 7.7e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 70.77%\n",
      "Epoch [65/200] Loss: 0.5151 Train Acc: 94.12% Test Acc: 70.17% Total Spikes: 2551316 Epoch Time: 53.50s LR: 7.7e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 70.77%\n",
      "Epoch [66/200] Loss: 0.5105 Train Acc: 94.18% Test Acc: 70.51% Total Spikes: 2540245 Epoch Time: 54.06s LR: 7.6e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 70.77%\n",
      "Epoch [67/200] Loss: 0.5019 Train Acc: 94.40% Test Acc: 70.62% Total Spikes: 2531877 Epoch Time: 53.37s LR: 7.5e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 70.77%\n",
      "Epoch [68/200] Loss: 0.4949 Train Acc: 94.48% Test Acc: 70.28% Total Spikes: 2531853 Epoch Time: 53.71s LR: 7.5e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 70.77%\n",
      "Epoch [69/200] Loss: 0.4884 Train Acc: 94.68% Test Acc: 70.34% Total Spikes: 2537154 Epoch Time: 53.05s LR: 7.4e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 70.77%\n",
      "Epoch [70/200] Loss: 0.4816 Train Acc: 94.80% Test Acc: 70.56% Total Spikes: 2534837 Epoch Time: 53.30s LR: 7.3e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 70.77%\n",
      "Epoch [71/200] Loss: 0.4753 Train Acc: 94.95% Test Acc: 70.37% Total Spikes: 2544494 Epoch Time: 53.31s LR: 7.3e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 70.77%\n",
      "Epoch [72/200] Loss: 0.4685 Train Acc: 95.13% Test Acc: 70.11% Total Spikes: 2531075 Epoch Time: 53.55s LR: 7.2e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 70.77%\n",
      "Epoch [73/200] Loss: 0.4608 Train Acc: 95.34% Test Acc: 70.53% Total Spikes: 2537017 Epoch Time: 53.28s LR: 7.1e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 70.77%\n",
      "\n",
      "--- Early stopping triggered after 73 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 70.77%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 70.77%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 58): 2537163\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 2537163\n",
      "--- Baseline (CNN-SNN) finished. Best Acc: 70.77%, Spikes at Convergence (Epoch 58): 2537163, Time: 4175.60s, Epochs Trained: 73 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Baseline (CNN-SNN): Best Acc=70.77, Spikes at Convergence=2537163, Time=4175.60s, Epochs=73, Convergence Epoch=58\n",
      "\n",
      "--- Training Proposed (CNN-Lorenz-SNN) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 3.7756 Train Acc: 23.61% Test Acc: 44.96% Total Spikes: 4245660 Epoch Time: 55.34s LR: 1.0e-05\n",
      "  -> New best test accuracy: 44.96%. Model saved.\n",
      "Epoch [2/200] Loss: 2.1346 Train Acc: 51.16% Test Acc: 57.93% Total Spikes: 4573317 Epoch Time: 55.34s LR: 1.0e-05\n",
      "  -> New best test accuracy: 57.93%. Model saved.\n",
      "Epoch [3/200] Loss: 1.6639 Train Acc: 59.79% Test Acc: 62.98% Total Spikes: 4653779 Epoch Time: 55.18s LR: 1.0e-05\n",
      "  -> New best test accuracy: 62.98%. Model saved.\n",
      "Epoch [4/200] Loss: 1.4314 Train Acc: 64.38% Test Acc: 65.14% Total Spikes: 4735364 Epoch Time: 55.51s LR: 1.0e-05\n",
      "  -> New best test accuracy: 65.14%. Model saved.\n",
      "Epoch [5/200] Loss: 1.2865 Train Acc: 67.50% Test Acc: 66.72% Total Spikes: 4764378 Epoch Time: 55.28s LR: 1.0e-05\n",
      "  -> New best test accuracy: 66.72%. Model saved.\n",
      "Epoch [6/200] Loss: 1.1771 Train Acc: 69.86% Test Acc: 67.77% Total Spikes: 4889032 Epoch Time: 55.27s LR: 1.0e-05\n",
      "  -> New best test accuracy: 67.77%. Model saved.\n",
      "Epoch [7/200] Loss: 1.0977 Train Acc: 71.47% Test Acc: 68.46% Total Spikes: 4874104 Epoch Time: 54.90s LR: 1.0e-05\n",
      "  -> New best test accuracy: 68.46%. Model saved.\n",
      "Epoch [8/200] Loss: 1.0276 Train Acc: 73.15% Test Acc: 69.33% Total Spikes: 4885670 Epoch Time: 55.34s LR: 1.0e-05\n",
      "  -> New best test accuracy: 69.33%. Model saved.\n",
      "Epoch [9/200] Loss: 0.9672 Train Acc: 74.53% Test Acc: 69.55% Total Spikes: 4951148 Epoch Time: 55.67s LR: 1.0e-05\n",
      "  -> New best test accuracy: 69.55%. Model saved.\n",
      "Epoch [10/200] Loss: 0.9130 Train Acc: 75.78% Test Acc: 70.06% Total Spikes: 4951261 Epoch Time: 55.41s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.06%. Model saved.\n",
      "Epoch [11/200] Loss: 0.8614 Train Acc: 77.09% Test Acc: 69.92% Total Spikes: 4972859 Epoch Time: 55.05s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 70.06%\n",
      "Epoch [12/200] Loss: 0.8189 Train Acc: 78.28% Test Acc: 70.11% Total Spikes: 5045034 Epoch Time: 54.83s LR: 9.9e-06\n",
      "  -> New best test accuracy: 70.11%. Model saved.\n",
      "Epoch [13/200] Loss: 0.7818 Train Acc: 79.22% Test Acc: 70.82% Total Spikes: 5047448 Epoch Time: 55.33s LR: 9.9e-06\n",
      "  -> New best test accuracy: 70.82%. Model saved.\n",
      "Epoch [14/200] Loss: 0.7361 Train Acc: 80.16% Test Acc: 71.15% Total Spikes: 5103709 Epoch Time: 55.29s LR: 9.9e-06\n",
      "  -> New best test accuracy: 71.15%. Model saved.\n",
      "Epoch [15/200] Loss: 0.7002 Train Acc: 81.21% Test Acc: 70.87% Total Spikes: 5055370 Epoch Time: 55.20s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 71.15%\n",
      "Epoch [16/200] Loss: 0.6676 Train Acc: 81.95% Test Acc: 71.30% Total Spikes: 5158856 Epoch Time: 55.26s LR: 9.9e-06\n",
      "  -> New best test accuracy: 71.30%. Model saved.\n",
      "Epoch [17/200] Loss: 0.6364 Train Acc: 82.74% Test Acc: 70.90% Total Spikes: 5170000 Epoch Time: 54.95s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 71.30%\n",
      "Epoch [18/200] Loss: 0.6071 Train Acc: 83.42% Test Acc: 70.88% Total Spikes: 5184953 Epoch Time: 55.63s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 71.30%\n",
      "Epoch [19/200] Loss: 0.5761 Train Acc: 84.29% Test Acc: 71.06% Total Spikes: 5171871 Epoch Time: 55.01s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 71.30%\n",
      "Epoch [20/200] Loss: 0.5520 Train Acc: 84.92% Test Acc: 71.13% Total Spikes: 5222980 Epoch Time: 54.92s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 71.30%\n",
      "Epoch [21/200] Loss: 0.5204 Train Acc: 85.84% Test Acc: 71.28% Total Spikes: 5218627 Epoch Time: 55.18s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 71.30%\n",
      "Epoch [22/200] Loss: 0.4989 Train Acc: 86.37% Test Acc: 71.49% Total Spikes: 5245859 Epoch Time: 55.36s LR: 9.7e-06\n",
      "  -> New best test accuracy: 71.49%. Model saved.\n",
      "Epoch [23/200] Loss: 0.4734 Train Acc: 87.13% Test Acc: 71.09% Total Spikes: 5271458 Epoch Time: 55.17s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 71.49%\n",
      "Epoch [24/200] Loss: 0.4549 Train Acc: 87.48% Test Acc: 71.30% Total Spikes: 5250086 Epoch Time: 55.56s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 71.49%\n",
      "Epoch [25/200] Loss: 0.4295 Train Acc: 88.34% Test Acc: 71.18% Total Spikes: 5297015 Epoch Time: 55.30s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 71.49%\n",
      "Epoch [26/200] Loss: 0.4129 Train Acc: 88.80% Test Acc: 70.73% Total Spikes: 5268368 Epoch Time: 54.89s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 71.49%\n",
      "Epoch [27/200] Loss: 0.3928 Train Acc: 89.21% Test Acc: 71.02% Total Spikes: 5322923 Epoch Time: 55.15s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 71.49%\n",
      "Epoch [28/200] Loss: 0.3722 Train Acc: 89.91% Test Acc: 71.02% Total Spikes: 5276477 Epoch Time: 55.34s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 71.49%\n",
      "Epoch [29/200] Loss: 0.3592 Train Acc: 90.29% Test Acc: 71.13% Total Spikes: 5301041 Epoch Time: 55.29s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 71.49%\n",
      "Epoch [30/200] Loss: 0.3411 Train Acc: 90.72% Test Acc: 71.07% Total Spikes: 5365993 Epoch Time: 55.44s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 71.49%\n",
      "Epoch [31/200] Loss: 0.3274 Train Acc: 91.12% Test Acc: 71.00% Total Spikes: 5345611 Epoch Time: 55.46s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 71.49%\n",
      "Epoch [32/200] Loss: 0.3099 Train Acc: 91.69% Test Acc: 71.18% Total Spikes: 5341821 Epoch Time: 55.64s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 71.49%\n",
      "Epoch [33/200] Loss: 0.2964 Train Acc: 92.07% Test Acc: 70.59% Total Spikes: 5372779 Epoch Time: 55.49s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 71.49%\n",
      "Epoch [34/200] Loss: 0.2846 Train Acc: 92.41% Test Acc: 70.51% Total Spikes: 5426135 Epoch Time: 55.75s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 71.49%\n",
      "Epoch [35/200] Loss: 0.2700 Train Acc: 92.92% Test Acc: 70.48% Total Spikes: 5402738 Epoch Time: 55.47s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 71.49%\n",
      "Epoch [36/200] Loss: 0.2598 Train Acc: 93.11% Test Acc: 70.81% Total Spikes: 5401740 Epoch Time: 55.42s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 71.49%\n",
      "Epoch [37/200] Loss: 0.2487 Train Acc: 93.56% Test Acc: 70.82% Total Spikes: 5438267 Epoch Time: 55.12s LR: 9.2e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 71.49%\n",
      "\n",
      "--- Early stopping triggered after 37 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 71.49%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 71.49%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 22): 5245859\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 5245859\n",
      "--- Proposed (CNN-Lorenz-SNN) finished. Best Acc: 71.49%, Spikes at Convergence (Epoch 22): 5245859, Time: 2196.25s, Epochs Trained: 37 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Proposed (CNN-Lorenz-SNN): Best Acc=71.49, Spikes at Convergence=5245859, Time=2196.25s, Epochs=37, Convergence Epoch=22\n",
      "\n",
      "--- Training Proposed (CNN-Osc-SNN Delta=-1.5) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 3.9239 Train Acc: 22.11% Test Acc: 43.59% Total Spikes: 2864124 Epoch Time: 55.60s LR: 1.0e-05\n",
      "  -> New best test accuracy: 43.59%. Model saved.\n",
      "Epoch [2/200] Loss: 2.3200 Train Acc: 49.56% Test Acc: 57.26% Total Spikes: 3033714 Epoch Time: 55.89s LR: 1.0e-05\n",
      "  -> New best test accuracy: 57.26%. Model saved.\n",
      "Epoch [3/200] Loss: 1.7738 Train Acc: 58.97% Test Acc: 61.87% Total Spikes: 3107606 Epoch Time: 55.96s LR: 1.0e-05\n",
      "  -> New best test accuracy: 61.87%. Model saved.\n",
      "Epoch [4/200] Loss: 1.5014 Train Acc: 63.98% Test Acc: 64.69% Total Spikes: 3147164 Epoch Time: 56.13s LR: 1.0e-05\n",
      "  -> New best test accuracy: 64.69%. Model saved.\n",
      "Epoch [5/200] Loss: 1.3416 Train Acc: 66.94% Test Acc: 66.35% Total Spikes: 3160461 Epoch Time: 56.00s LR: 1.0e-05\n",
      "  -> New best test accuracy: 66.35%. Model saved.\n",
      "Epoch [6/200] Loss: 1.2274 Train Acc: 69.22% Test Acc: 68.00% Total Spikes: 3197539 Epoch Time: 55.98s LR: 1.0e-05\n",
      "  -> New best test accuracy: 68.00%. Model saved.\n",
      "Epoch [7/200] Loss: 1.1336 Train Acc: 71.37% Test Acc: 68.59% Total Spikes: 3206600 Epoch Time: 55.74s LR: 1.0e-05\n",
      "  -> New best test accuracy: 68.59%. Model saved.\n",
      "Epoch [8/200] Loss: 1.0642 Train Acc: 72.83% Test Acc: 69.44% Total Spikes: 3215937 Epoch Time: 56.23s LR: 1.0e-05\n",
      "  -> New best test accuracy: 69.44%. Model saved.\n",
      "Epoch [9/200] Loss: 0.9917 Train Acc: 74.40% Test Acc: 69.61% Total Spikes: 3237729 Epoch Time: 55.66s LR: 1.0e-05\n",
      "  -> New best test accuracy: 69.61%. Model saved.\n",
      "Epoch [10/200] Loss: 0.9382 Train Acc: 75.59% Test Acc: 70.07% Total Spikes: 3244186 Epoch Time: 56.27s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.07%. Model saved.\n",
      "Epoch [11/200] Loss: 0.8867 Train Acc: 76.87% Test Acc: 70.25% Total Spikes: 3265307 Epoch Time: 56.41s LR: 9.9e-06\n",
      "  -> New best test accuracy: 70.25%. Model saved.\n",
      "Epoch [12/200] Loss: 0.8448 Train Acc: 77.90% Test Acc: 70.53% Total Spikes: 3272246 Epoch Time: 56.44s LR: 9.9e-06\n",
      "  -> New best test accuracy: 70.53%. Model saved.\n",
      "Epoch [13/200] Loss: 0.8030 Train Acc: 78.81% Test Acc: 70.58% Total Spikes: 3284888 Epoch Time: 56.42s LR: 9.9e-06\n",
      "  -> New best test accuracy: 70.58%. Model saved.\n",
      "Epoch [14/200] Loss: 0.7609 Train Acc: 79.84% Test Acc: 71.02% Total Spikes: 3292699 Epoch Time: 56.15s LR: 9.9e-06\n",
      "  -> New best test accuracy: 71.02%. Model saved.\n",
      "Epoch [15/200] Loss: 0.7239 Train Acc: 80.83% Test Acc: 70.58% Total Spikes: 3304429 Epoch Time: 55.67s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 71.02%\n",
      "Epoch [16/200] Loss: 0.6892 Train Acc: 81.69% Test Acc: 71.16% Total Spikes: 3307390 Epoch Time: 55.91s LR: 9.9e-06\n",
      "  -> New best test accuracy: 71.16%. Model saved.\n",
      "Epoch [17/200] Loss: 0.6586 Train Acc: 82.39% Test Acc: 71.44% Total Spikes: 3319864 Epoch Time: 55.82s LR: 9.8e-06\n",
      "  -> New best test accuracy: 71.44%. Model saved.\n",
      "Epoch [18/200] Loss: 0.6277 Train Acc: 83.32% Test Acc: 70.73% Total Spikes: 3337871 Epoch Time: 56.37s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 71.44%\n",
      "Epoch [19/200] Loss: 0.5981 Train Acc: 83.96% Test Acc: 71.08% Total Spikes: 3342186 Epoch Time: 56.34s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 71.44%\n",
      "Epoch [20/200] Loss: 0.5697 Train Acc: 84.73% Test Acc: 71.34% Total Spikes: 3354830 Epoch Time: 55.99s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 71.44%\n",
      "Epoch [21/200] Loss: 0.5396 Train Acc: 85.68% Test Acc: 71.30% Total Spikes: 3360720 Epoch Time: 55.87s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 71.44%\n",
      "Epoch [22/200] Loss: 0.5172 Train Acc: 86.16% Test Acc: 71.18% Total Spikes: 3362339 Epoch Time: 55.97s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 71.44%\n",
      "Epoch [23/200] Loss: 0.4917 Train Acc: 86.83% Test Acc: 71.46% Total Spikes: 3378165 Epoch Time: 55.90s LR: 9.7e-06\n",
      "  -> New best test accuracy: 71.46%. Model saved.\n",
      "Epoch [24/200] Loss: 0.4698 Train Acc: 87.41% Test Acc: 71.08% Total Spikes: 3381034 Epoch Time: 55.86s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 71.46%\n",
      "Epoch [25/200] Loss: 0.4497 Train Acc: 88.03% Test Acc: 71.33% Total Spikes: 3389596 Epoch Time: 55.78s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 71.46%\n",
      "Epoch [26/200] Loss: 0.4300 Train Acc: 88.53% Test Acc: 70.94% Total Spikes: 3388360 Epoch Time: 55.64s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 71.46%\n",
      "Epoch [27/200] Loss: 0.4116 Train Acc: 88.98% Test Acc: 71.29% Total Spikes: 3399739 Epoch Time: 55.60s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 71.46%\n",
      "Epoch [28/200] Loss: 0.3915 Train Acc: 89.60% Test Acc: 71.20% Total Spikes: 3405457 Epoch Time: 55.51s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 71.46%\n",
      "Epoch [29/200] Loss: 0.3695 Train Acc: 90.22% Test Acc: 71.19% Total Spikes: 3412246 Epoch Time: 56.30s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 71.46%\n",
      "Epoch [30/200] Loss: 0.3526 Train Acc: 90.74% Test Acc: 71.13% Total Spikes: 3418177 Epoch Time: 55.62s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 71.46%\n",
      "Epoch [31/200] Loss: 0.3385 Train Acc: 91.18% Test Acc: 71.00% Total Spikes: 3426008 Epoch Time: 56.01s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 71.46%\n",
      "Epoch [32/200] Loss: 0.3267 Train Acc: 91.48% Test Acc: 70.83% Total Spikes: 3436066 Epoch Time: 55.98s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 71.46%\n",
      "Epoch [33/200] Loss: 0.3126 Train Acc: 91.92% Test Acc: 71.01% Total Spikes: 3443283 Epoch Time: 55.98s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 71.46%\n",
      "Epoch [34/200] Loss: 0.2979 Train Acc: 92.41% Test Acc: 71.15% Total Spikes: 3441884 Epoch Time: 55.71s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 71.46%\n",
      "Epoch [35/200] Loss: 0.2870 Train Acc: 92.63% Test Acc: 71.11% Total Spikes: 3447433 Epoch Time: 55.83s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 71.46%\n",
      "Epoch [36/200] Loss: 0.2730 Train Acc: 92.97% Test Acc: 70.87% Total Spikes: 3456687 Epoch Time: 55.93s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 71.46%\n",
      "Epoch [37/200] Loss: 0.2602 Train Acc: 93.50% Test Acc: 71.21% Total Spikes: 3458273 Epoch Time: 55.95s LR: 9.2e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 71.46%\n",
      "Epoch [38/200] Loss: 0.2513 Train Acc: 93.67% Test Acc: 70.73% Total Spikes: 3461718 Epoch Time: 55.60s LR: 9.2e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 71.46%\n",
      "\n",
      "--- Early stopping triggered after 38 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 71.46%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 71.46%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 23): 3378165\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 3378165\n",
      "--- Proposed (CNN-Osc-SNN Delta=-1.5) finished. Best Acc: 71.46%, Spikes at Convergence (Epoch 23): 3378165, Time: 2280.83s, Epochs Trained: 38 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Proposed (CNN-Osc-SNN Delta=-1.5): Best Acc=71.46, Spikes at Convergence=3378165, Time=2280.83s, Epochs=38, Convergence Epoch=23\n",
      "\n",
      "--- Training Proposed (CNN-Osc-SNN Delta=10.0) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 4.2309 Train Acc: 19.31% Test Acc: 39.43% Total Spikes: 2259100 Epoch Time: 56.01s LR: 1.0e-05\n",
      "  -> New best test accuracy: 39.43%. Model saved.\n",
      "Epoch [2/200] Loss: 2.7364 Train Acc: 45.92% Test Acc: 54.14% Total Spikes: 2448816 Epoch Time: 55.85s LR: 1.0e-05\n",
      "  -> New best test accuracy: 54.14%. Model saved.\n",
      "Epoch [3/200] Loss: 2.1043 Train Acc: 55.95% Test Acc: 59.53% Total Spikes: 2510534 Epoch Time: 55.88s LR: 1.0e-05\n",
      "  -> New best test accuracy: 59.53%. Model saved.\n",
      "Epoch [4/200] Loss: 1.7562 Train Acc: 61.62% Test Acc: 62.65% Total Spikes: 2576205 Epoch Time: 55.94s LR: 1.0e-05\n",
      "  -> New best test accuracy: 62.65%. Model saved.\n",
      "Epoch [5/200] Loss: 1.5454 Train Acc: 64.88% Test Acc: 64.36% Total Spikes: 2607646 Epoch Time: 55.65s LR: 1.0e-05\n",
      "  -> New best test accuracy: 64.36%. Model saved.\n",
      "Epoch [6/200] Loss: 1.3936 Train Acc: 67.49% Test Acc: 66.41% Total Spikes: 2659036 Epoch Time: 55.69s LR: 1.0e-05\n",
      "  -> New best test accuracy: 66.41%. Model saved.\n",
      "Epoch [7/200] Loss: 1.2824 Train Acc: 69.48% Test Acc: 67.36% Total Spikes: 2708752 Epoch Time: 55.84s LR: 1.0e-05\n",
      "  -> New best test accuracy: 67.36%. Model saved.\n",
      "Epoch [8/200] Loss: 1.1979 Train Acc: 71.13% Test Acc: 68.43% Total Spikes: 2688192 Epoch Time: 55.76s LR: 1.0e-05\n",
      "  -> New best test accuracy: 68.43%. Model saved.\n",
      "Epoch [9/200] Loss: 1.1260 Train Acc: 72.57% Test Acc: 68.97% Total Spikes: 2734457 Epoch Time: 56.09s LR: 1.0e-05\n",
      "  -> New best test accuracy: 68.97%. Model saved.\n",
      "Epoch [10/200] Loss: 1.0581 Train Acc: 74.03% Test Acc: 69.11% Total Spikes: 2752060 Epoch Time: 55.71s LR: 1.0e-05\n",
      "  -> New best test accuracy: 69.11%. Model saved.\n",
      "Epoch [11/200] Loss: 1.0029 Train Acc: 75.19% Test Acc: 69.15% Total Spikes: 2770630 Epoch Time: 55.50s LR: 9.9e-06\n",
      "  -> New best test accuracy: 69.15%. Model saved.\n",
      "Epoch [12/200] Loss: 0.9557 Train Acc: 76.15% Test Acc: 69.44% Total Spikes: 2799127 Epoch Time: 55.72s LR: 9.9e-06\n",
      "  -> New best test accuracy: 69.44%. Model saved.\n",
      "Epoch [13/200] Loss: 0.9069 Train Acc: 77.40% Test Acc: 69.60% Total Spikes: 2828647 Epoch Time: 56.07s LR: 9.9e-06\n",
      "  -> New best test accuracy: 69.60%. Model saved.\n",
      "Epoch [14/200] Loss: 0.8681 Train Acc: 78.16% Test Acc: 69.86% Total Spikes: 2796140 Epoch Time: 55.70s LR: 9.9e-06\n",
      "  -> New best test accuracy: 69.86%. Model saved.\n",
      "Epoch [15/200] Loss: 0.8298 Train Acc: 79.19% Test Acc: 70.36% Total Spikes: 2847292 Epoch Time: 55.86s LR: 9.9e-06\n",
      "  -> New best test accuracy: 70.36%. Model saved.\n",
      "Epoch [16/200] Loss: 0.7875 Train Acc: 80.25% Test Acc: 70.41% Total Spikes: 2849899 Epoch Time: 56.02s LR: 9.9e-06\n",
      "  -> New best test accuracy: 70.41%. Model saved.\n",
      "Epoch [17/200] Loss: 0.7558 Train Acc: 80.98% Test Acc: 70.55% Total Spikes: 2856961 Epoch Time: 55.63s LR: 9.8e-06\n",
      "  -> New best test accuracy: 70.55%. Model saved.\n",
      "Epoch [18/200] Loss: 0.7255 Train Acc: 81.75% Test Acc: 70.54% Total Spikes: 2856786 Epoch Time: 55.91s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 70.55%\n",
      "Epoch [19/200] Loss: 0.6912 Train Acc: 82.53% Test Acc: 70.51% Total Spikes: 2864820 Epoch Time: 55.88s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 70.55%\n",
      "Epoch [20/200] Loss: 0.6652 Train Acc: 83.21% Test Acc: 70.38% Total Spikes: 2884291 Epoch Time: 55.70s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 70.55%\n",
      "Epoch [21/200] Loss: 0.6339 Train Acc: 83.92% Test Acc: 70.46% Total Spikes: 2897210 Epoch Time: 56.24s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 70.55%\n",
      "Epoch [22/200] Loss: 0.6099 Train Acc: 84.50% Test Acc: 70.83% Total Spikes: 2894490 Epoch Time: 56.14s LR: 9.7e-06\n",
      "  -> New best test accuracy: 70.83%. Model saved.\n",
      "Epoch [23/200] Loss: 0.5843 Train Acc: 85.13% Test Acc: 70.57% Total Spikes: 2874358 Epoch Time: 56.47s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 70.83%\n",
      "Epoch [24/200] Loss: 0.5589 Train Acc: 85.99% Test Acc: 70.79% Total Spikes: 2888544 Epoch Time: 55.93s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 70.83%\n",
      "Epoch [25/200] Loss: 0.5375 Train Acc: 86.40% Test Acc: 71.11% Total Spikes: 2929003 Epoch Time: 56.40s LR: 9.6e-06\n",
      "  -> New best test accuracy: 71.11%. Model saved.\n",
      "Epoch [26/200] Loss: 0.5191 Train Acc: 86.87% Test Acc: 70.86% Total Spikes: 2925978 Epoch Time: 55.85s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 71.11%\n",
      "Epoch [27/200] Loss: 0.4933 Train Acc: 87.62% Test Acc: 70.83% Total Spikes: 2930903 Epoch Time: 56.34s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 71.11%\n",
      "Epoch [28/200] Loss: 0.4754 Train Acc: 88.18% Test Acc: 71.05% Total Spikes: 2904642 Epoch Time: 55.82s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 71.11%\n",
      "Epoch [29/200] Loss: 0.4555 Train Acc: 88.63% Test Acc: 71.10% Total Spikes: 2926024 Epoch Time: 55.87s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 71.11%\n",
      "Epoch [30/200] Loss: 0.4364 Train Acc: 89.19% Test Acc: 70.57% Total Spikes: 2938249 Epoch Time: 55.77s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 71.11%\n",
      "Epoch [31/200] Loss: 0.4195 Train Acc: 89.56% Test Acc: 70.94% Total Spikes: 2940068 Epoch Time: 55.99s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 71.11%\n",
      "Epoch [32/200] Loss: 0.4013 Train Acc: 90.20% Test Acc: 70.72% Total Spikes: 2926546 Epoch Time: 56.17s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 71.11%\n",
      "Epoch [33/200] Loss: 0.3881 Train Acc: 90.42% Test Acc: 70.92% Total Spikes: 2935106 Epoch Time: 56.31s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 71.11%\n",
      "Epoch [34/200] Loss: 0.3713 Train Acc: 90.87% Test Acc: 70.76% Total Spikes: 2935921 Epoch Time: 56.44s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 71.11%\n",
      "Epoch [35/200] Loss: 0.3593 Train Acc: 91.23% Test Acc: 70.90% Total Spikes: 2954430 Epoch Time: 56.42s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 71.11%\n",
      "Epoch [36/200] Loss: 0.3433 Train Acc: 91.73% Test Acc: 70.91% Total Spikes: 2921015 Epoch Time: 56.22s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 71.11%\n",
      "Epoch [37/200] Loss: 0.3308 Train Acc: 92.10% Test Acc: 70.94% Total Spikes: 2936982 Epoch Time: 56.28s LR: 9.2e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 71.11%\n",
      "Epoch [38/200] Loss: 0.3187 Train Acc: 92.51% Test Acc: 70.94% Total Spikes: 2950073 Epoch Time: 55.99s LR: 9.2e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 71.11%\n",
      "Epoch [39/200] Loss: 0.3038 Train Acc: 92.82% Test Acc: 70.98% Total Spikes: 2934229 Epoch Time: 56.22s LR: 9.1e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 71.11%\n",
      "Epoch [40/200] Loss: 0.2942 Train Acc: 93.18% Test Acc: 70.63% Total Spikes: 2939198 Epoch Time: 56.47s LR: 9.1e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 71.11%\n",
      "\n",
      "--- Early stopping triggered after 40 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 71.11%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 71.11%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 25): 2929003\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 2929003\n",
      "--- Proposed (CNN-Osc-SNN Delta=10.0) finished. Best Acc: 71.11%, Spikes at Convergence (Epoch 25): 2929003, Time: 2402.44s, Epochs Trained: 40 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Proposed (CNN-Osc-SNN Delta=10.0): Best Acc=71.11, Spikes at Convergence=2929003, Time=2402.44s, Epochs=40, Convergence Epoch=25\n",
      "\n",
      "--- All models processed for this configuration ---\n",
      "Results saved to experiment_results_TinyImageNet_ResNet-18_pretrained/results.json\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Baseline (CNN-ANN)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Baseline (CNN-SNN)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Proposed (CNN-Lorenz-SNN)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Proposed (CNN-Osc-SNN Delta=-1.5)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Proposed (CNN-Osc-SNN Delta=10.0)_spikes.csv\n",
      "Summary table saved to experiment_results_TinyImageNet_ResNet-18_pretrained/summary.csv\n",
      "\n",
      "============================================================\n",
      "实验完成! 结果保存在 'experiment_results_TinyImageNet_ResNet-18_pretrained' 目录中\n",
      "============================================================\n",
      "\n",
      "结果汇总:\n",
      "                      Config Name                             Model Delta/System Best Test Accuracy (%) Spikes at Convergence Training Time (s)  Epochs Trained  Convergence Epoch\n",
      "TinyImageNet_ResNet-18_pretrained                Baseline (CNN-ANN)          ANN                  64.84                     0           3206.45              58                 43\n",
      "TinyImageNet_ResNet-18_pretrained                Baseline (CNN-SNN)   Direct SNN                  70.77               2537163           4175.60              73                 58\n",
      "TinyImageNet_ResNet-18_pretrained         Proposed (CNN-Lorenz-SNN)       Lorenz                  71.49               5245859           2196.25              37                 22\n",
      "TinyImageNet_ResNet-18_pretrained Proposed (CNN-Osc-SNN Delta=-1.5)  Osc(Δ=-1.5)                  71.46               3378165           2280.83              38                 23\n",
      "TinyImageNet_ResNet-18_pretrained Proposed (CNN-Osc-SNN Delta=10.0)  Osc(Δ=10.0)                  71.11               2929003           2402.44              40                 25\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder # Useful for Tiny ImageNet structure\n",
    "import torchvision.transforms as transforms\n",
    "# import matplotlib.pyplot as plt # Keep if needed later\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import copy\n",
    "# from itertools import product # No longer needed for CNN configs\n",
    "import os\n",
    "import json\n",
    "import snntorch as snn\n",
    "import snntorch.surrogate as surrogate\n",
    "from snntorch import utils\n",
    "from snntorch import functional as SF\n",
    "from PIL import Image # Needed for TinyImageNet loading potentially\n",
    "\n",
    "# --- Configuration Class (Updated for Tiny ImageNet & ResNet) ---\n",
    "class Config:\n",
    "    # 数据集\n",
    "    dataset_name = \"TinyImageNet\"\n",
    "    data_root = './tiny-imagenet-200' # <<<--- IMPORTANT: SET PATH TO YOUR TINY IMAGENET FOLDER\n",
    "    batch_size = 64 # May need to reduce based on GPU memory with ResNet\n",
    "    input_size = 224 # Standard input size for ImageNet pre-trained models\n",
    "    num_classes = 200 # Tiny ImageNet has 200 classes\n",
    "\n",
    "    # CNN Backbone (Fixed to ResNet-18)\n",
    "    backbone_name = \"ResNet-18_pretrained\"\n",
    "\n",
    "    # Common SNN/Encoding Parameters\n",
    "    # Projecting 512 ResNet features to 32 might be aggressive.\n",
    "    # Consider increasing chaos_dim, e.g., 128 or 256, for better results.\n",
    "    chaos_dim = 64 # Dimension for projection before oscillator/lorenz/SNN layers\n",
    "    num_steps = 5 # Reduced num_steps initially for faster testing with ResNet\n",
    "\n",
    "    # --- Oscillator Parameters ---\n",
    "    osc_alpha = 2.0\n",
    "    osc_beta = 0.1\n",
    "    osc_gamma = 0.1\n",
    "    osc_omega = 1.0\n",
    "    osc_drive = 0.0\n",
    "    # osc_delta will be set specifically\n",
    "    osc_dt = 0.05\n",
    "\n",
    "    # --- Lorenz Parameters ---\n",
    "    lorenz_sigma = 10.0\n",
    "    lorenz_rho = 28.0\n",
    "    lorenz_beta = 8.0/3.0\n",
    "    lorenz_dt = 0.05\n",
    "\n",
    "    # SNN Decay Rate\n",
    "    beta = 0.95 # SNN Leaky Neuron Beta (Decay Rate)\n",
    "\n",
    "    # 训练\n",
    "    epochs = 200 # Adjust max epochs for Tiny ImageNet & fine-tuning\n",
    "    # Learning rate might need adjustment for fine-tuning ResNet\n",
    "    lr = 1e-4 # Lower initial LR often better for fine-tuning\n",
    "    weight_decay = 5e-4\n",
    "    # Early Stopping\n",
    "    patience = 15 # Maybe increase patience slightly\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "spike_grad = surrogate.fast_sigmoid()\n",
    "\n",
    "# --- OscillatorTransformFast Class (Unchanged) ---\n",
    "class OscillatorTransformFast(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.alpha = config.osc_alpha\n",
    "        self.beta_osc = config.osc_beta\n",
    "        self.gamma = config.osc_gamma\n",
    "        self.delta = getattr(config, 'osc_delta', 0.0)\n",
    "        self.omega = config.osc_omega\n",
    "        self.dt = config.osc_dt\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, dim = x.shape\n",
    "        device = x.device\n",
    "        trajectories = torch.zeros(batch_size, self.num_steps, dim * 3, device=device)\n",
    "        current_delta = self.delta\n",
    "        state = torch.cat([x, x*0.2, -x], dim=1)\n",
    "        trajectories[:, 0, :] = state\n",
    "        for t in range(1, self.num_steps):\n",
    "            x_cur = state[:, :dim]\n",
    "            y_cur = state[:, dim:2 * dim]\n",
    "            z_cur = state[:, 2 * dim:]\n",
    "            dx = y_cur\n",
    "            dy = -self.alpha * x_cur - self.beta_osc * (x_cur**3) - current_delta * y_cur + self.gamma * z_cur\n",
    "            dz = -self.omega * x_cur - current_delta * z_cur + self.gamma * x_cur * y_cur\n",
    "            derivatives = torch.cat([dx, dy, dz], dim=1)\n",
    "            state = state + self.dt * derivatives\n",
    "            trajectories[:, t, :] = state\n",
    "        return trajectories\n",
    "\n",
    "# --- LorenzTransformFast Class (Unchanged) ---\n",
    "class LorenzTransformFast(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.sigma = config.lorenz_sigma\n",
    "        self.rho = config.lorenz_rho\n",
    "        self.lorenz_beta_param = config.lorenz_beta\n",
    "        self.dt = config.lorenz_dt\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, dim = x.shape\n",
    "        device = x.device\n",
    "        trajectories = torch.zeros(batch_size, self.num_steps, dim * 3, device=device)\n",
    "        state = torch.cat([\n",
    "            x,\n",
    "            0.2*x,\n",
    "            -x\n",
    "        ], dim=1)\n",
    "        trajectories[:, 0, :] = state\n",
    "        for t in range(1, self.num_steps):\n",
    "            x_cur = state[:, :dim]\n",
    "            y_cur = state[:, dim:2 * dim]\n",
    "            z_cur = state[:, 2 * dim:]\n",
    "            dx = self.sigma * (y_cur - x_cur)\n",
    "            dy = x_cur * (self.rho - z_cur) - y_cur\n",
    "            dz = x_cur * y_cur - self.lorenz_beta_param * z_cur\n",
    "            state = state + self.dt * torch.cat([dx, dy, dz], dim=1)\n",
    "            trajectories[:, t, :] = state\n",
    "        return trajectories\n",
    "\n",
    "# --- Helper function to get ResNet-18 backbone ---\n",
    "def _get_resnet_backbone(pretrained=True):\n",
    "    \"\"\"Loads a pretrained ResNet-18 model and removes the final fc layer.\"\"\"\n",
    "    if pretrained:\n",
    "        weights = torchvision.models.ResNet18_Weights.IMAGENET1K_V1\n",
    "        model = torchvision.models.resnet18(weights=weights)\n",
    "        print(\"Loaded PRETRAINED ResNet-18 weights.\")\n",
    "    else:\n",
    "        model = torchvision.models.resnet18(weights=None)\n",
    "        print(\"Initialized ResNet-18 weights FROM SCRATCH.\")\n",
    "\n",
    "    # Remove the final fully connected layer (classifier)\n",
    "    model.fc = nn.Identity() # Replace fc layer with identity\n",
    "    return model\n",
    "\n",
    "# --- CNNOscSNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class CNNOscSNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.oscillator = OscillatorTransformFast(config)\n",
    "        self.lif1 = snn.Leaky(beta=config.beta)\n",
    "        self.lif2 = snn.Leaky(beta=config.beta)\n",
    "        self.fc_out = nn.Linear(config.chaos_dim * 3, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, return_spikes=False):\n",
    "        features = self.backbone(x)\n",
    "        x = torch.tanh(self.proj(features))\n",
    "        encoded = self.oscillator(x)\n",
    "        outputs = []\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        batch_total_spikes = 0.0\n",
    "        for step in range(self.num_steps):\n",
    "            cur = encoded[:, step]\n",
    "            spk1, mem1 = self.lif1(cur, mem1)\n",
    "            spk2, mem2 = self.lif2(spk1, mem2)\n",
    "            outputs.append(self.fc_out(spk2))\n",
    "            if return_spikes:\n",
    "                batch_total_spikes += spk1.sum().item() + spk2.sum().item()\n",
    "        final_output = torch.stack(outputs).sum(0)\n",
    "        if return_spikes:\n",
    "            return final_output, torch.tensor(batch_total_spikes, device=final_output.device)\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "# --- CNNLorenzSNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class CNNLorenzSNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.lorenz = LorenzTransformFast(config)\n",
    "        self.lif1 = snn.Leaky(beta=config.beta)\n",
    "        self.lif2 = snn.Leaky(beta=config.beta)\n",
    "        self.fc_out = nn.Linear(config.chaos_dim * 3, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, return_spikes=False):\n",
    "        features = self.backbone(x)\n",
    "        x = torch.tanh(self.proj(features))\n",
    "        encoded = self.lorenz(x)\n",
    "        outputs = []\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        batch_total_spikes = 0.0\n",
    "        for step in range(self.num_steps):\n",
    "            cur = encoded[:, step]\n",
    "            spk1, mem1 = self.lif1(cur, mem1)\n",
    "            spk2, mem2 = self.lif2(spk1, mem2)\n",
    "            outputs.append(self.fc_out(spk2))\n",
    "            if return_spikes:\n",
    "                batch_total_spikes += spk1.sum().item() + spk2.sum().item()\n",
    "        final_output = torch.stack(outputs).sum(0)\n",
    "        if return_spikes:\n",
    "            return final_output, torch.tensor(batch_total_spikes, device=final_output.device)\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "# --- BasicCSNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class BasicCSNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.lif1 = snn.Leaky(beta=config.beta)\n",
    "        self.lif2 = snn.Leaky(beta=config.beta)\n",
    "        self.fc_out = nn.Linear(config.chaos_dim, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, return_spikes=False):\n",
    "        features = self.backbone(x)\n",
    "        cnn_features = torch.tanh(self.proj(features))\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        total_output_mem = 0\n",
    "        batch_total_spikes = 0.0\n",
    "        for _ in range(self.num_steps):\n",
    "            spk1, mem1 = self.lif1(cnn_features, mem1)\n",
    "            spk2, mem2 = self.lif2(spk1, mem2)\n",
    "            total_output_mem += self.fc_out(spk2)\n",
    "            if return_spikes:\n",
    "                batch_total_spikes += spk1.sum().item() + spk2.sum().item()\n",
    "        final_output = total_output_mem / self.num_steps\n",
    "        if return_spikes:\n",
    "            return final_output, torch.tensor(batch_total_spikes, device=final_output.device)\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "# --- BaseCNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class BaseCNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.fc1 = nn.Linear(config.chaos_dim, config.chaos_dim)\n",
    "        self.fc2 = nn.Linear(config.chaos_dim, config.chaos_dim)\n",
    "        self.classifier = nn.Linear(config.chaos_dim, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        features = self.backbone(x)\n",
    "        x = torch.tanh(self.proj(features))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# --- 修改后的 Evaluate 函数 - 返回 total_spikes 而不是 average ---\n",
    "def evaluate(model, loader, config):\n",
    "    \"\"\"Evaluates the model, returns accuracy and total spikes.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_spikes_evaluated = 0.0\n",
    "    is_snn = isinstance(model, (CNNOscSNN, BasicCSNN, CNNLorenzSNN))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            if is_snn:\n",
    "                outputs, batch_spikes = model(images, return_spikes=True)\n",
    "                total_spikes_evaluated += batch_spikes.item()\n",
    "            else:\n",
    "                outputs = model(images) # **kwargs in BaseCNN handles extra args\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    # 修改: 返回 total_spikes 而不是平均值\n",
    "    return accuracy, total_spikes_evaluated\n",
    "\n",
    "\n",
    "# --- 修改后的 Train and Evaluate with History ---\n",
    "def train_and_evaluate_with_history(model, train_loader, test_loader, config):\n",
    "    \"\"\"Trains model with early stopping, returns best test acc, epoch history, and spikes at convergence.\"\"\"\n",
    "    model = model.to(device)\n",
    "    # --- OPTIONAL: Differential Learning Rate ---\n",
    "    # You might want different LRs for backbone and head\n",
    "    # Example:\n",
    "    head_params = [p for n, p in model.named_parameters() if not n.startswith('backbone.')]\n",
    "    backbone_params = [p for n, p in model.named_parameters() if n.startswith('backbone.')]\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': backbone_params, 'lr': config.lr * 0.1}, # Lower LR for backbone\n",
    "        {'params': head_params, 'lr': config.lr} # Normal LR for head\n",
    "    ], weight_decay=config.weight_decay)\n",
    "    # --- Using single LR for simplicity now ---\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_test_acc_epoch = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    patience = config.patience\n",
    "    # Ensure output directory exists before saving temp model\n",
    "    output_dir = f\"experiment_results_{config.dataset_name}_{config.backbone_name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True) # Ensure directory exists\n",
    "    best_model_path = os.path.join(output_dir, f\"temp_best_model_{time.time()}_{id(model)}.pth\") # Save inside output dir\n",
    "    \n",
    "    # 修改: 添加 spike 记录\n",
    "    history = []\n",
    "    spike_counts = []  # 记录每个epoch的spikes\n",
    "    best_epoch = 0  # 记录达到最佳性能的epoch\n",
    "\n",
    "    print(f\"--- Starting Training (Max Epochs: {config.epochs}, Patience: {patience}) ---\")\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        start_epoch_time = time.time()\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader): # Add index i for progress printing\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images, return_spikes=False) # No need for spikes during training loop\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                print(f\"WARNING: Loss is {loss.item()} at epoch {epoch+1}, batch {i}. Skipping backward pass.\")\n",
    "                continue # Skip batch if loss is invalid\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Optional: Print progress within epoch\n",
    "            # if (i + 1) % 100 == 0:\n",
    "            #     print(f'  Epoch [{epoch+1}/{config.epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "        end_epoch_time = time.time()\n",
    "        epoch_duration = end_epoch_time - start_epoch_time\n",
    "\n",
    "        # 修改: 在每个epoch结束后评估并记录spikes\n",
    "        test_acc, epoch_spikes = evaluate(model, test_loader, config)\n",
    "        history.append(test_acc)\n",
    "        spike_counts.append(epoch_spikes)  # 记录总spike数\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader) if len(train_loader) > 0 else 0\n",
    "        train_acc = 100. * train_correct / train_total if train_total > 0 else 0\n",
    "\n",
    "        # 修改: 打印spike信息\n",
    "        print(f\"Epoch [{epoch + 1}/{config.epochs}] Loss: {avg_loss:.4f} \"\n",
    "              f\"Train Acc: {train_acc:.2f}% Test Acc: {test_acc:.2f}% \"\n",
    "              f\"Total Spikes: {epoch_spikes:.0f} \"\n",
    "              f\"Epoch Time: {epoch_duration:.2f}s LR: {scheduler.get_last_lr()[0]:.1e}\")\n",
    "\n",
    "        # Early Stopping Logic\n",
    "        if test_acc > best_test_acc_epoch:\n",
    "            best_test_acc_epoch = test_acc\n",
    "            best_epoch = epoch  # 记录最佳epoch索引\n",
    "            epochs_no_improve = 0\n",
    "            try:\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f\"  -> New best test accuracy: {best_test_acc_epoch:.2f}%. Model saved.\")\n",
    "            except Exception as e:\n",
    "                print(f\"  -> Error saving model: {e}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  -> Test accuracy did not improve for {epochs_no_improve} epoch(s). Best: {best_test_acc_epoch:.2f}%\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"\\n--- Early stopping triggered after {epoch + 1} epochs. ---\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Post-Training: Load Best Model and Final Evaluation\n",
    "    print(\"\\n--- Training finished. Loading best model for final evaluation. ---\")\n",
    "    if os.path.exists(best_model_path):\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(best_model_path))\n",
    "            print(f\"Successfully loaded best model state (Accuracy: {best_test_acc_epoch:.2f}%)\")\n",
    "            os.remove(best_model_path)\n",
    "            # print(f\"Removed temporary model file: {best_model_path}\") # Optional: uncomment to confirm\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading best model state from {best_model_path}: {e}. Using model from last epoch.\")\n",
    "            best_test_acc_epoch = history[-1] if history else 0.0\n",
    "    else:\n",
    "        print(\"No best model was saved (or file missing). Using model from last epoch.\")\n",
    "        best_test_acc_epoch = history[-1] if history else 0.0\n",
    "\n",
    "    print(\"--- Running final evaluation on the best performing model state ---\")\n",
    "    final_test_acc, final_total_spikes = evaluate(model, test_loader, config)\n",
    "\n",
    "    # 修改: 获取收敛时的spike数\n",
    "    spikes_at_convergence = spike_counts[best_epoch] if spike_counts and best_epoch < len(spike_counts) else 0\n",
    "\n",
    "    print(f\"Final Evaluation - Test Accuracy: {final_test_acc:.2f}%\")\n",
    "    if isinstance(model, (CNNOscSNN, BasicCSNN, CNNLorenzSNN)):\n",
    "        print(f\"Final Evaluation - Total Spikes at Convergence (Epoch {best_epoch+1}): {spikes_at_convergence:.0f}\")\n",
    "        print(f\"Final Evaluation - Total Spikes in Final Evaluation: {final_total_spikes:.0f}\")\n",
    "\n",
    "    # 修改: 返回收敛时的spikes (不是平均值)\n",
    "    return best_test_acc_epoch, history, spikes_at_convergence, spike_counts\n",
    "\n",
    "# --- Tiny ImageNet Loading Function (未更改) ---\n",
    "def load_tiny_imagenet(config):\n",
    "    \"\"\"Loads the Tiny ImageNet dataset.\"\"\"\n",
    "    data_dir = config.data_root\n",
    "    num_workers = min(4, os.cpu_count()) if os.cpu_count() else 0\n",
    "    image_size = config.input_size # Should be 224 for pre-trained ResNet\n",
    "\n",
    "    # Standard ImageNet normalization\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # Data augmentation and normalization for training\n",
    "    # Adjust augmentation based on standard practices for ImageNet fine-tuning\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size), # Resize first\n",
    "        transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)), # Standard crop\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    # Just normalization for validation/testing\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size), # Ensure validation images are also resized\n",
    "        transforms.CenterCrop(image_size), # Use CenterCrop for validation\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    # --- Dataset Loading ---\n",
    "    # Tiny ImageNet structure: train/[wnid]/images/*.JPEG, val/images/*.JPEG, val/val_annotations.txt\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    val_dir = os.path.join(data_dir, 'val', 'images') # Validation images are flat\n",
    "\n",
    "    if not os.path.exists(train_dir) or not os.path.exists(val_dir):\n",
    "         raise FileNotFoundError(f\"Tiny ImageNet data not found at expected paths: {train_dir} and {val_dir}. \"\n",
    "                                f\"Please ensure Tiny ImageNet is downloaded and extracted to '{data_dir}' \"\n",
    "                                \"following the standard directory structure.\")\n",
    "\n",
    "    train_dataset = ImageFolder(train_dir, transform=train_transform)\n",
    "\n",
    "    # Validation dataset requires special handling due to annotations file\n",
    "    # Creating a custom Dataset class is cleaner\n",
    "    class TinyImageNetVal(Dataset):\n",
    "        def __init__(self, val_dir, annotations_file, class_to_idx, transform=None):\n",
    "            self.val_dir = val_dir\n",
    "            self.transform = transform\n",
    "            self.class_to_idx = class_to_idx\n",
    "            self.samples = []\n",
    "            try:\n",
    "                with open(annotations_file, 'r') as f:\n",
    "                    for line in f:\n",
    "                        parts = line.strip().split('\\t')\n",
    "                        if len(parts) >= 2:\n",
    "                            img_name, wnid = parts[0], parts[1]\n",
    "                            img_path = os.path.join(self.val_dir, img_name)\n",
    "                            if os.path.exists(img_path) and wnid in self.class_to_idx:\n",
    "                                self.samples.append((img_path, self.class_to_idx[wnid]))\n",
    "                            # else:\n",
    "                                # print(f\"Warning: Skipping invalid validation entry: {line.strip()}\")\n",
    "            except FileNotFoundError:\n",
    "                 raise FileNotFoundError(f\"Validation annotations file not found: {annotations_file}\")\n",
    "\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.samples)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img_path, target = self.samples[idx]\n",
    "            # Ensure images are loaded in RGB format\n",
    "            try:\n",
    "                with open(img_path, 'rb') as f:\n",
    "                    img = Image.open(f).convert('RGB')\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "                # Return a dummy image/target or handle appropriately\n",
    "                return torch.zeros(3, image_size, image_size), -1 # Indicate error\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, target\n",
    "\n",
    "    # Need class_to_idx mapping from the training set folders\n",
    "    class_to_idx = train_dataset.class_to_idx\n",
    "    val_annotations_file = os.path.join(data_dir, 'val', 'val_annotations.txt')\n",
    "    val_dataset = TinyImageNetVal(val_dir, val_annotations_file, class_to_idx, transform=val_transform)\n",
    "\n",
    "\n",
    "    print(f\"Tiny ImageNet - Found {len(train_dataset)} training images belonging to {len(train_dataset.classes)} classes.\")\n",
    "    print(f\"Tiny ImageNet - Found {len(val_dataset)} validation images.\")\n",
    "\n",
    "\n",
    "    # Data Loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=config.batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    # Use validation set as the test set for Tiny ImageNet evaluation\n",
    "    test_loader = DataLoader(\n",
    "        val_dataset, batch_size=config.batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "# --- 修改 Experiment Logger Class ---\n",
    "class ExperimentLogger:\n",
    "    def __init__(self, output_dir=\"experiment_results_tinyimagenet_resnet18\"): # Changed dir name\n",
    "        self.results = {}\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        # 修改: 更新CSV标题，将Average Spikes改为Spikes at Convergence\n",
    "        self.csv_headers = [\n",
    "            \"Config Name\", # Renamed from CNN Config\n",
    "            \"Model\",\n",
    "            \"Delta/System\",\n",
    "            \"Best Test Accuracy (%)\",\n",
    "            \"Spikes at Convergence\", # 修改: 更改列名\n",
    "            \"Training Time (s)\",\n",
    "            \"Epochs Trained\",\n",
    "            \"Convergence Epoch\" # 添加收敛epoch的列\n",
    "        ]\n",
    "\n",
    "    def log_config(self, config_name, config):\n",
    "        config_dict = {}\n",
    "        config_dict['patience'] = config.patience\n",
    "        for key, value in vars(config).items():\n",
    "             if isinstance(value, (int, float, str, bool, list, tuple, dict, type(None))):\n",
    "                 config_dict[key] = value\n",
    "             # ... (rest of serialization logic from previous version)\n",
    "        self.results[config_name] = {\n",
    "            \"config\": config_dict,\n",
    "            \"models\": {}\n",
    "        }\n",
    "\n",
    "    # 修改: 更新log_model_result参数和逻辑\n",
    "    def log_model_result(self, config_name, model_name, accuracy, training_time, epochs_history, spikes_at_convergence, spike_counts, best_epoch):\n",
    "        if config_name not in self.results:\n",
    "            self.results[config_name] = {\"config\": {}, \"models\": {}}\n",
    "            print(f\"Warning: Config '{config_name}' not pre-logged. Creating entry.\")\n",
    "        epochs_trained = len(epochs_history)\n",
    "        self.results[config_name][\"models\"][model_name] = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"training_time\": training_time,\n",
    "            \"epochs_history\": epochs_history, # Storing history can make JSON large\n",
    "            \"spikes_at_convergence\": spikes_at_convergence, # 修改: 改为收敛时的spikes\n",
    "            \"epochs_trained\": epochs_trained,\n",
    "            \"spike_counts\": spike_counts, # 添加: 存储每个epoch的spike数据\n",
    "            \"convergence_epoch\": best_epoch + 1 # 添加: 转换为1-indexed的epoch号\n",
    "        }\n",
    "        print(f\"Logged for {config_name} - {model_name}: Best Acc={accuracy:.2f}, Spikes at Convergence={spikes_at_convergence:.0f}, \"\n",
    "              f\"Time={training_time:.2f}s, Epochs={epochs_trained}, Convergence Epoch={best_epoch+1}\")\n",
    "\n",
    "    def save_results(self):\n",
    "        filepath = os.path.join(self.output_dir, \"results.json\")\n",
    "        try:\n",
    "            # Save only essential results to JSON to avoid large files due to history\n",
    "            results_to_save = {}\n",
    "            for cfg_name, cfg_data in self.results.items():\n",
    "                results_to_save[cfg_name] = {\"config\": cfg_data[\"config\"], \"models\": {}}\n",
    "                for mdl_name, mdl_data in cfg_data[\"models\"].items():\n",
    "                    results_to_save[cfg_name][\"models\"][mdl_name] = {\n",
    "                        k: v for k, v in mdl_data.items() if k not in ['epochs_history', 'spike_counts']\n",
    "                    }\n",
    "            with open(filepath, \"w\") as f:\n",
    "                json.dump(results_to_save, f, indent=4, default=lambda o: '<not serializable>')\n",
    "            print(f\"Results saved to {filepath}\")\n",
    "            \n",
    "            # 添加: 保存spike数据到CSV文件\n",
    "            for cfg_name, cfg_data in self.results.items():\n",
    "                for mdl_name, mdl_data in cfg_data[\"models\"].items():\n",
    "                    if 'spike_counts' in mdl_data and mdl_data['spike_counts']:\n",
    "                        spike_df = pd.DataFrame({\n",
    "                            'Epoch': range(1, len(mdl_data['spike_counts'])+1),\n",
    "                            'Total Spikes': mdl_data['spike_counts']\n",
    "                        })\n",
    "                        spike_file = os.path.join(self.output_dir, f\"{cfg_name}_{mdl_name}_spikes.csv\")\n",
    "                        spike_df.to_csv(spike_file, index=False)\n",
    "                        print(f\"Spike data saved to {spike_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving JSON results: {e}\")\n",
    "\n",
    "\n",
    "    def generate_summary_table(self):\n",
    "        rows = []\n",
    "        for config_name, data in self.results.items():\n",
    "            for model_name, model_data in data[\"models\"].items():\n",
    "                delta_str = \"N/A\"\n",
    "                # Simplified model type identification for summary\n",
    "                if \"Osc-SNN Delta=\" in model_name:\n",
    "                    delta_str = f\"Osc(Δ={model_name.split('=')[-1].split(')')[0]})\"\n",
    "                elif \"Lorenz-SNN\" in model_name:\n",
    "                    delta_str = \"Lorenz\"\n",
    "                elif \"CNN-SNN\" in model_name and \"Osc\" not in model_name and \"Lorenz\" not in model_name:\n",
    "                     delta_str = \"Direct SNN\"\n",
    "                elif \"CNN-ANN\" in model_name:\n",
    "                     delta_str = \"ANN\"\n",
    "\n",
    "                spikes = model_data.get(\"spikes_at_convergence\", 0.0)  # 修改: 使用收敛时的spikes\n",
    "                epochs_trained = model_data.get(\"epochs_trained\", \"N/A\")\n",
    "                convergence_epoch = model_data.get(\"convergence_epoch\", \"N/A\")  # 添加: 获取收敛epoch\n",
    "\n",
    "                row = {\n",
    "                    self.csv_headers[0]: config_name, # Use \"Config Name\"\n",
    "                    self.csv_headers[1]: model_name,\n",
    "                    self.csv_headers[2]: delta_str,\n",
    "                    self.csv_headers[3]: model_data[\"accuracy\"],\n",
    "                    self.csv_headers[4]: spikes,  # 修改: 使用收敛时的spikes\n",
    "                    self.csv_headers[5]: model_data[\"training_time\"],\n",
    "                    self.csv_headers[6]: epochs_trained,\n",
    "                    self.csv_headers[7]: convergence_epoch  # 添加: 收敛epoch\n",
    "                }\n",
    "                rows.append(row)\n",
    "        if not rows: return pd.DataFrame(columns=self.csv_headers)\n",
    "        df = pd.DataFrame(rows)\n",
    "        df = df[self.csv_headers] # Ensure column order\n",
    "        try:\n",
    "            df[self.csv_headers[3]] = pd.to_numeric(df[self.csv_headers[3]], errors='coerce').map('{:.2f}'.format)\n",
    "            df[self.csv_headers[4]] = pd.to_numeric(df[self.csv_headers[4]], errors='coerce').map('{:.0f}'.format)  # 修改: 整数格式\n",
    "            df[self.csv_headers[5]] = pd.to_numeric(df[self.csv_headers[5]], errors='coerce').map('{:.2f}'.format)\n",
    "        except Exception as e: print(f\"Error formatting summary table columns: {e}\")\n",
    "        filepath = os.path.join(self.output_dir, \"summary.csv\")\n",
    "        try: df.to_csv(filepath, index=False); print(f\"Summary table saved to {filepath}\")\n",
    "        except Exception as e: print(f\"Error saving summary CSV: {e}\")\n",
    "        return df\n",
    "\n",
    "    # --- Plotting (Requires Matplotlib) ---\n",
    "    # Consider simplifying or removing plotting if matplotlib is not available/needed now\n",
    "    # def plot_results(self):\n",
    "    #     # ... (Plotting code from previous version - needs matplotlib)\n",
    "    #     # If keeping plots, update logic to handle single config name and model types\n",
    "    #     pass\n",
    "\n",
    "# --- 修改 Main Experiment Function ---\n",
    "def run_experiment():\n",
    "    print(f\"使用设备: {device}\")\n",
    "    config = Config() # Use the updated config\n",
    "    config_name = f\"{config.dataset_name}_{config.backbone_name}\" # Single config name\n",
    "    logger = ExperimentLogger(output_dir=f\"experiment_results_{config_name}\")\n",
    "\n",
    "    # Define the specific oscillator deltas for the two modes\n",
    "    # Use values inspired by Table D1, e.g., one expansive, one dissipative\n",
    "    osc_delta_mode_b = -1.5 # High performance potential (Expansive)\n",
    "    osc_delta_mode_a = 10.0 # High efficiency (Dissipative)\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"开始实验配置: {config_name}\")\n",
    "    print(f\"Dataset: {config.dataset_name} (Root: {config.data_root}, Classes: {config.num_classes}, Input Size: {config.input_size})\")\n",
    "    print(f\"Backbone: {config.backbone_name}\")\n",
    "    print(f\"Max Epochs: {config.epochs}, Patience: {config.patience}, LR: {config.lr}\")\n",
    "    print(f\"Osc Params: alpha={config.osc_alpha}, beta={config.osc_beta}, gamma={config.osc_gamma}, omega={config.osc_omega}, dt={config.osc_dt}\")\n",
    "    print(f\"Lorenz Params: sigma={config.lorenz_sigma:.2f}, rho={config.lorenz_rho:.2f}, beta={config.lorenz_beta:.2f}, dt={config.lorenz_dt}\")\n",
    "    print(f\"SNN Params: steps={config.num_steps}, decay_beta={config.beta:.2f}, chaos_dim={config.chaos_dim}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    logger.log_config(config_name, config)\n",
    "\n",
    "    try:\n",
    "        # Load Tiny ImageNet data\n",
    "        train_loader, test_loader = load_tiny_imagenet(config)\n",
    "    except Exception as e:\n",
    "        print(f\"无法加载数据集 {config_name}. 终止实验. 错误: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None # Exit if data loading fails\n",
    "\n",
    "    # --- Define Models to Run ---\n",
    "    # Ensure pretrained_backbone=True is passed correctly\n",
    "    models_to_run = {\n",
    "        \"Baseline (CNN-ANN)\": BaseCNN(config, pretrained_backbone=True),\n",
    "        \"Baseline (CNN-SNN)\": BasicCSNN(config, pretrained_backbone=True),\n",
    "        \"Proposed (CNN-Lorenz-SNN)\": CNNLorenzSNN(config, pretrained_backbone=True)\n",
    "    }\n",
    "    # Add Oscillator SNNs with specific deltas\n",
    "    osc_config_b = copy.deepcopy(config); osc_config_b.osc_delta = osc_delta_mode_b\n",
    "    models_to_run[f\"Proposed (CNN-Osc-SNN Delta={osc_delta_mode_b})\"] = CNNOscSNN(osc_config_b, pretrained_backbone=True)\n",
    "\n",
    "    osc_config_a = copy.deepcopy(config); osc_config_a.osc_delta = osc_delta_mode_a\n",
    "    models_to_run[f\"Proposed (CNN-Osc-SNN Delta={osc_delta_mode_a})\"] = CNNOscSNN(osc_config_a, pretrained_backbone=True)\n",
    "\n",
    "\n",
    "    # --- Train and Evaluate Models ---\n",
    "    for model_name, model_instance in models_to_run.items():\n",
    "        print(f\"\\n--- Training {model_name} for {config_name} ---\")\n",
    "        start_time = time.time()\n",
    "        # Use a fresh copy for each training run (already done by creating new instances above)\n",
    "        current_model = model_instance\n",
    "        current_config = config # Default config for non-oscillator models\n",
    "        if \"Osc-SNN Delta=\" in model_name:\n",
    "             delta_val = float(model_name.split('=')[-1].split(')')[0])\n",
    "             if delta_val == osc_delta_mode_a: current_config = osc_config_a\n",
    "             elif delta_val == osc_delta_mode_b: current_config = osc_config_b\n",
    "             else: print(f\"Warning: Could not match delta for {model_name}\")\n",
    "\n",
    "\n",
    "        try:\n",
    "            # 修改: 添加对spike_counts和best_epoch的接收\n",
    "            best_acc, epochs_history, spikes_at_convergence, spike_counts = train_and_evaluate_with_history(\n",
    "                current_model, train_loader, test_loader, current_config # Pass correct config\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "            \n",
    "            # 计算best_epoch (0-indexed)\n",
    "            best_epoch = epochs_history.index(best_acc) if best_acc in epochs_history else 0\n",
    "            \n",
    "            print(f\"--- {model_name} finished. Best Acc: {best_acc:.2f}%, \"\n",
    "                 f\"Spikes at Convergence (Epoch {best_epoch+1}): {spikes_at_convergence:.0f}, \"\n",
    "                 f\"Time: {training_time:.2f}s, Epochs Trained: {len(epochs_history)} ---\")\n",
    "                 \n",
    "            # 修改: 更新logger.log_model_result调用\n",
    "            logger.log_model_result(\n",
    "                config_name, model_name, best_acc, training_time, \n",
    "                epochs_history, spikes_at_convergence, spike_counts, best_epoch\n",
    "            )\n",
    "        except Exception as e:\n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "            print(f\"!!! ERROR during training/evaluation for {model_name} on {config_name}: {e}\")\n",
    "            # 修改: 更新错误情况下的logger.log_model_result调用\n",
    "            logger.log_model_result(config_name, model_name, 0.0, training_time, [], 0.0, [], 0)\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            # Decide whether to continue with other models upon error\n",
    "            # continue\n",
    "\n",
    "\n",
    "    # --- Finalize and Save Results ---\n",
    "    print(\"\\n--- All models processed for this configuration ---\")\n",
    "    logger.save_results()\n",
    "    summary_df = logger.generate_summary_table()\n",
    "    # try:\n",
    "    #     logger.plot_results() # Optional plotting\n",
    "    # except Exception as e:\n",
    "    #     print(f\"An error occurred during final plotting: {e}\")\n",
    "    #     import traceback\n",
    "    #     traceback.print_exc()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"实验完成! 结果保存在 '{logger.output_dir}' 目录中\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    if not summary_df.empty:\n",
    "        print(\"结果汇总:\")\n",
    "        # Configure pandas for wider output\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', 2000)\n",
    "        pd.set_option('display.max_colwidth', None) # Show full column width\n",
    "        print(summary_df.to_string(index=False)) # Use to_string for better control\n",
    "        pd.reset_option('all') # Reset pandas display options\n",
    "    else:\n",
    "        print(\"结果汇总为空.\")\n",
    "\n",
    "    return logger\n",
    "\n",
    "# --- Run Experiment ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Optional: Set seeds for reproducibility\n",
    "    # seed = 42\n",
    "    # torch.manual_seed(seed)\n",
    "    # np.random.seed(seed)\n",
    "    # if torch.cuda.is_available():\n",
    "    #     torch.cuda.manual_seed_all(seed)\n",
    "    # # Note: Full determinism can impact performance and might not be guaranteed on GPU\n",
    "    # # torch.backends.cudnn.deterministic = True\n",
    "    # # torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    logger = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b3d66e-6b1f-4bdd-88b9-6443adb7a11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "\n",
      "============================================================\n",
      "开始实验配置: TinyImageNet_ResNet-18_pretrained\n",
      "Dataset: TinyImageNet (Root: ./tiny-imagenet-200, Classes: 200, Input Size: 224)\n",
      "Backbone: ResNet-18_pretrained\n",
      "Max Epochs: 200, Patience: 15, LR: 0.0001\n",
      "Osc Params: alpha=2.0, beta=0.1, gamma=0.1, omega=1.0, dt=0.05\n",
      "Lorenz Params: sigma=10.00, rho=28.00, beta=2.67, dt=0.05\n",
      "SNN Params: steps=5, decay_beta=0.95, chaos_dim=128\n",
      "============================================================\n",
      "Tiny ImageNet - Found 100000 training images belonging to 200 classes.\n",
      "Tiny ImageNet - Found 10000 validation images.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "\n",
      "--- Training Baseline (CNN-ANN) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 3.9273 Train Acc: 15.43% Test Acc: 32.57% Total Spikes: 0 Epoch Time: 51.82s LR: 1.0e-05\n",
      "  -> New best test accuracy: 32.57%. Model saved.\n",
      "Epoch [2/200] Loss: 2.4845 Train Acc: 39.41% Test Acc: 47.39% Total Spikes: 0 Epoch Time: 52.73s LR: 1.0e-05\n",
      "  -> New best test accuracy: 47.39%. Model saved.\n",
      "Epoch [3/200] Loss: 2.0326 Train Acc: 49.59% Test Acc: 53.61% Total Spikes: 0 Epoch Time: 52.33s LR: 1.0e-05\n",
      "  -> New best test accuracy: 53.61%. Model saved.\n",
      "Epoch [4/200] Loss: 1.7697 Train Acc: 55.62% Test Acc: 57.44% Total Spikes: 0 Epoch Time: 51.94s LR: 1.0e-05\n",
      "  -> New best test accuracy: 57.44%. Model saved.\n",
      "Epoch [5/200] Loss: 1.5852 Train Acc: 59.91% Test Acc: 59.94% Total Spikes: 0 Epoch Time: 51.81s LR: 1.0e-05\n",
      "  -> New best test accuracy: 59.94%. Model saved.\n",
      "Epoch [6/200] Loss: 1.4474 Train Acc: 63.04% Test Acc: 62.53% Total Spikes: 0 Epoch Time: 51.79s LR: 1.0e-05\n",
      "  -> New best test accuracy: 62.53%. Model saved.\n",
      "Epoch [7/200] Loss: 1.3290 Train Acc: 65.56% Test Acc: 63.15% Total Spikes: 0 Epoch Time: 52.15s LR: 1.0e-05\n",
      "  -> New best test accuracy: 63.15%. Model saved.\n",
      "Epoch [8/200] Loss: 1.2365 Train Acc: 67.72% Test Acc: 63.78% Total Spikes: 0 Epoch Time: 51.50s LR: 1.0e-05\n",
      "  -> New best test accuracy: 63.78%. Model saved.\n",
      "Epoch [9/200] Loss: 1.1564 Train Acc: 69.57% Test Acc: 64.67% Total Spikes: 0 Epoch Time: 52.26s LR: 1.0e-05\n",
      "  -> New best test accuracy: 64.67%. Model saved.\n",
      "Epoch [10/200] Loss: 1.0760 Train Acc: 71.42% Test Acc: 65.33% Total Spikes: 0 Epoch Time: 52.37s LR: 1.0e-05\n",
      "  -> New best test accuracy: 65.33%. Model saved.\n",
      "Epoch [11/200] Loss: 1.0094 Train Acc: 72.99% Test Acc: 66.15% Total Spikes: 0 Epoch Time: 52.41s LR: 9.9e-06\n",
      "  -> New best test accuracy: 66.15%. Model saved.\n",
      "Epoch [12/200] Loss: 0.9484 Train Acc: 74.34% Test Acc: 66.67% Total Spikes: 0 Epoch Time: 52.27s LR: 9.9e-06\n",
      "  -> New best test accuracy: 66.67%. Model saved.\n",
      "Epoch [13/200] Loss: 0.8932 Train Acc: 75.50% Test Acc: 66.56% Total Spikes: 0 Epoch Time: 52.36s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 66.67%\n",
      "Epoch [14/200] Loss: 0.8394 Train Acc: 76.93% Test Acc: 66.87% Total Spikes: 0 Epoch Time: 52.02s LR: 9.9e-06\n",
      "  -> New best test accuracy: 66.87%. Model saved.\n",
      "Epoch [15/200] Loss: 0.7916 Train Acc: 77.90% Test Acc: 67.09% Total Spikes: 0 Epoch Time: 52.17s LR: 9.9e-06\n",
      "  -> New best test accuracy: 67.09%. Model saved.\n",
      "Epoch [16/200] Loss: 0.7420 Train Acc: 79.49% Test Acc: 67.13% Total Spikes: 0 Epoch Time: 52.54s LR: 9.9e-06\n",
      "  -> New best test accuracy: 67.13%. Model saved.\n",
      "Epoch [17/200] Loss: 0.7010 Train Acc: 80.24% Test Acc: 67.01% Total Spikes: 0 Epoch Time: 52.05s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 67.13%\n",
      "Epoch [18/200] Loss: 0.6595 Train Acc: 81.30% Test Acc: 67.71% Total Spikes: 0 Epoch Time: 52.71s LR: 9.8e-06\n",
      "  -> New best test accuracy: 67.71%. Model saved.\n",
      "Epoch [19/200] Loss: 0.6195 Train Acc: 82.39% Test Acc: 67.32% Total Spikes: 0 Epoch Time: 52.19s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 67.71%\n",
      "Epoch [20/200] Loss: 0.5875 Train Acc: 83.22% Test Acc: 67.68% Total Spikes: 0 Epoch Time: 52.26s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 67.71%\n",
      "Epoch [21/200] Loss: 0.5526 Train Acc: 84.02% Test Acc: 67.33% Total Spikes: 0 Epoch Time: 52.31s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 67.71%\n",
      "Epoch [22/200] Loss: 0.5189 Train Acc: 84.89% Test Acc: 66.62% Total Spikes: 0 Epoch Time: 52.09s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 67.71%\n",
      "Epoch [23/200] Loss: 0.4859 Train Acc: 85.89% Test Acc: 67.27% Total Spikes: 0 Epoch Time: 52.03s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 67.71%\n",
      "Epoch [24/200] Loss: 0.4635 Train Acc: 86.44% Test Acc: 67.15% Total Spikes: 0 Epoch Time: 52.38s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 67.71%\n",
      "Epoch [25/200] Loss: 0.4326 Train Acc: 87.27% Test Acc: 67.26% Total Spikes: 0 Epoch Time: 52.67s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 67.71%\n",
      "Epoch [26/200] Loss: 0.4075 Train Acc: 87.85% Test Acc: 67.37% Total Spikes: 0 Epoch Time: 51.93s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 67.71%\n",
      "Epoch [27/200] Loss: 0.3918 Train Acc: 88.38% Test Acc: 66.71% Total Spikes: 0 Epoch Time: 52.15s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 67.71%\n",
      "Epoch [28/200] Loss: 0.3638 Train Acc: 89.11% Test Acc: 66.82% Total Spikes: 0 Epoch Time: 52.46s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 67.71%\n",
      "Epoch [29/200] Loss: 0.3427 Train Acc: 89.71% Test Acc: 67.05% Total Spikes: 0 Epoch Time: 51.71s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 67.71%\n",
      "Epoch [30/200] Loss: 0.3274 Train Acc: 90.17% Test Acc: 66.96% Total Spikes: 0 Epoch Time: 51.92s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 67.71%\n",
      "Epoch [31/200] Loss: 0.3092 Train Acc: 90.59% Test Acc: 66.95% Total Spikes: 0 Epoch Time: 51.62s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 67.71%\n",
      "Epoch [32/200] Loss: 0.2887 Train Acc: 91.30% Test Acc: 67.11% Total Spikes: 0 Epoch Time: 51.69s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 67.71%\n",
      "Epoch [33/200] Loss: 0.2777 Train Acc: 91.59% Test Acc: 67.38% Total Spikes: 0 Epoch Time: 52.09s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 67.71%\n",
      "\n",
      "--- Early stopping triggered after 33 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 67.71%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 67.71%\n",
      "--- Baseline (CNN-ANN) finished. Best Acc: 67.71%, Spikes at Convergence (Epoch 18): 0, Time: 1856.11s, Epochs Trained: 33 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Baseline (CNN-ANN): Best Acc=67.71, Spikes at Convergence=0, Time=1856.11s, Epochs=33, Convergence Epoch=18\n",
      "\n",
      "--- Training Baseline (CNN-SNN) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 4.7303 Train Acc: 20.19% Test Acc: 36.32% Total Spikes: 4291928 Epoch Time: 53.60s LR: 1.0e-05\n",
      "  -> New best test accuracy: 36.32%. Model saved.\n",
      "Epoch [2/200] Loss: 3.7041 Train Acc: 39.50% Test Acc: 46.49% Total Spikes: 4618283 Epoch Time: 54.07s LR: 1.0e-05\n",
      "  -> New best test accuracy: 46.49%. Model saved.\n",
      "Epoch [3/200] Loss: 3.0079 Train Acc: 48.39% Test Acc: 52.80% Total Spikes: 4742627 Epoch Time: 53.49s LR: 1.0e-05\n",
      "  -> New best test accuracy: 52.80%. Model saved.\n",
      "Epoch [4/200] Loss: 2.5274 Train Acc: 54.94% Test Acc: 56.99% Total Spikes: 4801607 Epoch Time: 54.30s LR: 1.0e-05\n",
      "  -> New best test accuracy: 56.99%. Model saved.\n",
      "Epoch [5/200] Loss: 2.1902 Train Acc: 59.42% Test Acc: 60.87% Total Spikes: 4876213 Epoch Time: 54.26s LR: 1.0e-05\n",
      "  -> New best test accuracy: 60.87%. Model saved.\n",
      "Epoch [6/200] Loss: 1.9454 Train Acc: 62.89% Test Acc: 62.56% Total Spikes: 4878322 Epoch Time: 54.10s LR: 1.0e-05\n",
      "  -> New best test accuracy: 62.56%. Model saved.\n",
      "Epoch [7/200] Loss: 1.7570 Train Acc: 65.76% Test Acc: 65.05% Total Spikes: 4897623 Epoch Time: 54.70s LR: 1.0e-05\n",
      "  -> New best test accuracy: 65.05%. Model saved.\n",
      "Epoch [8/200] Loss: 1.6105 Train Acc: 68.18% Test Acc: 66.20% Total Spikes: 4917647 Epoch Time: 55.03s LR: 1.0e-05\n",
      "  -> New best test accuracy: 66.20%. Model saved.\n",
      "Epoch [9/200] Loss: 1.4971 Train Acc: 70.03% Test Acc: 67.01% Total Spikes: 4940628 Epoch Time: 53.91s LR: 1.0e-05\n",
      "  -> New best test accuracy: 67.01%. Model saved.\n",
      "Epoch [10/200] Loss: 1.3999 Train Acc: 71.78% Test Acc: 67.87% Total Spikes: 4931739 Epoch Time: 53.75s LR: 1.0e-05\n",
      "  -> New best test accuracy: 67.87%. Model saved.\n",
      "Epoch [11/200] Loss: 1.3203 Train Acc: 72.94% Test Acc: 68.30% Total Spikes: 4930082 Epoch Time: 53.65s LR: 9.9e-06\n",
      "  -> New best test accuracy: 68.30%. Model saved.\n",
      "Epoch [12/200] Loss: 1.2511 Train Acc: 74.47% Test Acc: 69.29% Total Spikes: 4951024 Epoch Time: 54.00s LR: 9.9e-06\n",
      "  -> New best test accuracy: 69.29%. Model saved.\n",
      "Epoch [13/200] Loss: 1.1916 Train Acc: 75.49% Test Acc: 69.90% Total Spikes: 4954940 Epoch Time: 53.86s LR: 9.9e-06\n",
      "  -> New best test accuracy: 69.90%. Model saved.\n",
      "Epoch [14/200] Loss: 1.1338 Train Acc: 76.57% Test Acc: 70.57% Total Spikes: 4946976 Epoch Time: 53.62s LR: 9.9e-06\n",
      "  -> New best test accuracy: 70.57%. Model saved.\n",
      "Epoch [15/200] Loss: 1.0859 Train Acc: 77.69% Test Acc: 70.72% Total Spikes: 4954930 Epoch Time: 53.82s LR: 9.9e-06\n",
      "  -> New best test accuracy: 70.72%. Model saved.\n",
      "Epoch [16/200] Loss: 1.0402 Train Acc: 78.55% Test Acc: 71.17% Total Spikes: 4953653 Epoch Time: 53.73s LR: 9.9e-06\n",
      "  -> New best test accuracy: 71.17%. Model saved.\n",
      "Epoch [17/200] Loss: 1.0020 Train Acc: 79.47% Test Acc: 71.02% Total Spikes: 4908655 Epoch Time: 53.70s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 71.17%\n",
      "Epoch [18/200] Loss: 0.9658 Train Acc: 80.28% Test Acc: 71.22% Total Spikes: 4943376 Epoch Time: 53.64s LR: 9.8e-06\n",
      "  -> New best test accuracy: 71.22%. Model saved.\n",
      "Epoch [19/200] Loss: 0.9311 Train Acc: 81.07% Test Acc: 71.57% Total Spikes: 4913130 Epoch Time: 53.82s LR: 9.8e-06\n",
      "  -> New best test accuracy: 71.57%. Model saved.\n",
      "Epoch [20/200] Loss: 0.8974 Train Acc: 81.93% Test Acc: 71.69% Total Spikes: 4921286 Epoch Time: 53.86s LR: 9.8e-06\n",
      "  -> New best test accuracy: 71.69%. Model saved.\n",
      "Epoch [21/200] Loss: 0.8685 Train Acc: 82.46% Test Acc: 71.33% Total Spikes: 4915284 Epoch Time: 53.85s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 71.69%\n",
      "Epoch [22/200] Loss: 0.8386 Train Acc: 83.19% Test Acc: 71.72% Total Spikes: 4911717 Epoch Time: 53.78s LR: 9.7e-06\n",
      "  -> New best test accuracy: 71.72%. Model saved.\n",
      "Epoch [23/200] Loss: 0.8137 Train Acc: 83.83% Test Acc: 71.67% Total Spikes: 4933784 Epoch Time: 53.82s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 71.72%\n",
      "Epoch [24/200] Loss: 0.7904 Train Acc: 84.44% Test Acc: 71.61% Total Spikes: 4914101 Epoch Time: 53.87s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 71.72%\n",
      "Epoch [25/200] Loss: 0.7604 Train Acc: 85.30% Test Acc: 71.64% Total Spikes: 4917377 Epoch Time: 53.88s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 71.72%\n",
      "Epoch [26/200] Loss: 0.7399 Train Acc: 85.57% Test Acc: 71.96% Total Spikes: 4912211 Epoch Time: 53.43s LR: 9.6e-06\n",
      "  -> New best test accuracy: 71.96%. Model saved.\n",
      "Epoch [27/200] Loss: 0.7170 Train Acc: 86.25% Test Acc: 71.75% Total Spikes: 4923979 Epoch Time: 54.02s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 71.96%\n",
      "Epoch [28/200] Loss: 0.6969 Train Acc: 86.72% Test Acc: 71.88% Total Spikes: 4909610 Epoch Time: 53.68s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 71.96%\n",
      "Epoch [29/200] Loss: 0.6749 Train Acc: 87.22% Test Acc: 71.99% Total Spikes: 4933688 Epoch Time: 53.74s LR: 9.5e-06\n",
      "  -> New best test accuracy: 71.99%. Model saved.\n",
      "Epoch [30/200] Loss: 0.6555 Train Acc: 87.73% Test Acc: 72.03% Total Spikes: 4901189 Epoch Time: 53.69s LR: 9.5e-06\n",
      "  -> New best test accuracy: 72.03%. Model saved.\n",
      "Epoch [31/200] Loss: 0.6389 Train Acc: 88.06% Test Acc: 72.10% Total Spikes: 4913525 Epoch Time: 53.58s LR: 9.5e-06\n",
      "  -> New best test accuracy: 72.10%. Model saved.\n",
      "Epoch [32/200] Loss: 0.6217 Train Acc: 88.72% Test Acc: 72.00% Total Spikes: 4899148 Epoch Time: 53.35s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 72.10%\n",
      "Epoch [33/200] Loss: 0.6039 Train Acc: 89.14% Test Acc: 71.92% Total Spikes: 4911630 Epoch Time: 54.08s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 72.10%\n",
      "Epoch [34/200] Loss: 0.5869 Train Acc: 89.51% Test Acc: 71.69% Total Spikes: 4900062 Epoch Time: 53.76s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 72.10%\n",
      "Epoch [35/200] Loss: 0.5703 Train Acc: 89.94% Test Acc: 72.02% Total Spikes: 4917269 Epoch Time: 53.76s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 72.10%\n",
      "Epoch [36/200] Loss: 0.5546 Train Acc: 90.36% Test Acc: 71.82% Total Spikes: 4891551 Epoch Time: 53.57s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 72.10%\n",
      "Epoch [37/200] Loss: 0.5387 Train Acc: 90.75% Test Acc: 71.89% Total Spikes: 4908530 Epoch Time: 53.64s LR: 9.2e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 72.10%\n",
      "Epoch [38/200] Loss: 0.5267 Train Acc: 91.06% Test Acc: 71.87% Total Spikes: 4888177 Epoch Time: 53.71s LR: 9.2e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 72.10%\n",
      "Epoch [39/200] Loss: 0.5117 Train Acc: 91.45% Test Acc: 71.89% Total Spikes: 4890739 Epoch Time: 53.59s LR: 9.1e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 72.10%\n",
      "Epoch [40/200] Loss: 0.4992 Train Acc: 91.83% Test Acc: 72.01% Total Spikes: 4892027 Epoch Time: 53.41s LR: 9.1e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 72.10%\n",
      "Epoch [41/200] Loss: 0.4873 Train Acc: 92.07% Test Acc: 71.58% Total Spikes: 4880093 Epoch Time: 53.67s LR: 9.0e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 72.10%\n",
      "Epoch [42/200] Loss: 0.4760 Train Acc: 92.47% Test Acc: 71.93% Total Spikes: 4894405 Epoch Time: 53.37s LR: 9.0e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 72.10%\n",
      "Epoch [43/200] Loss: 0.4623 Train Acc: 92.81% Test Acc: 71.53% Total Spikes: 4894483 Epoch Time: 54.06s LR: 9.0e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 72.10%\n",
      "Epoch [44/200] Loss: 0.4513 Train Acc: 93.06% Test Acc: 71.92% Total Spikes: 4866399 Epoch Time: 53.49s LR: 8.9e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 72.10%\n",
      "Epoch [45/200] Loss: 0.4405 Train Acc: 93.35% Test Acc: 71.77% Total Spikes: 4869804 Epoch Time: 53.45s LR: 8.9e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 72.10%\n",
      "Epoch [46/200] Loss: 0.4311 Train Acc: 93.56% Test Acc: 71.76% Total Spikes: 4867903 Epoch Time: 53.85s LR: 8.8e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 72.10%\n",
      "\n",
      "--- Early stopping triggered after 46 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 72.10%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 72.10%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 31): 4913525\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 4913525\n",
      "--- Baseline (CNN-SNN) finished. Best Acc: 72.10%, Spikes at Convergence (Epoch 31): 4913525, Time: 2663.74s, Epochs Trained: 46 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Baseline (CNN-SNN): Best Acc=72.10, Spikes at Convergence=4913525, Time=2663.74s, Epochs=46, Convergence Epoch=31\n",
      "\n",
      "--- Training Proposed (CNN-Lorenz-SNN) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 3.2527 Train Acc: 32.73% Test Acc: 55.28% Total Spikes: 7826487 Epoch Time: 56.03s LR: 1.0e-05\n",
      "  -> New best test accuracy: 55.28%. Model saved.\n",
      "Epoch [2/200] Loss: 1.7165 Train Acc: 58.77% Test Acc: 64.07% Total Spikes: 8208031 Epoch Time: 55.37s LR: 1.0e-05\n",
      "  -> New best test accuracy: 64.07%. Model saved.\n",
      "Epoch [3/200] Loss: 1.3611 Train Acc: 65.69% Test Acc: 67.54% Total Spikes: 8435512 Epoch Time: 55.56s LR: 1.0e-05\n",
      "  -> New best test accuracy: 67.54%. Model saved.\n",
      "Epoch [4/200] Loss: 1.1847 Train Acc: 69.47% Test Acc: 69.38% Total Spikes: 8451651 Epoch Time: 55.74s LR: 1.0e-05\n",
      "  -> New best test accuracy: 69.38%. Model saved.\n",
      "Epoch [5/200] Loss: 1.0706 Train Acc: 71.95% Test Acc: 70.35% Total Spikes: 8745835 Epoch Time: 56.04s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.35%. Model saved.\n",
      "Epoch [6/200] Loss: 0.9813 Train Acc: 74.02% Test Acc: 70.93% Total Spikes: 8754472 Epoch Time: 55.93s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.93%. Model saved.\n",
      "Epoch [7/200] Loss: 0.9096 Train Acc: 75.72% Test Acc: 71.70% Total Spikes: 8845877 Epoch Time: 55.69s LR: 1.0e-05\n",
      "  -> New best test accuracy: 71.70%. Model saved.\n",
      "Epoch [8/200] Loss: 0.8481 Train Acc: 77.23% Test Acc: 72.28% Total Spikes: 8941101 Epoch Time: 56.21s LR: 1.0e-05\n",
      "  -> New best test accuracy: 72.28%. Model saved.\n",
      "Epoch [9/200] Loss: 0.7955 Train Acc: 78.36% Test Acc: 72.28% Total Spikes: 8968089 Epoch Time: 55.81s LR: 1.0e-05\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 72.28%\n",
      "Epoch [10/200] Loss: 0.7407 Train Acc: 79.97% Test Acc: 72.24% Total Spikes: 9118256 Epoch Time: 55.74s LR: 1.0e-05\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 72.28%\n",
      "Epoch [11/200] Loss: 0.7003 Train Acc: 80.84% Test Acc: 72.72% Total Spikes: 9162726 Epoch Time: 56.15s LR: 9.9e-06\n",
      "  -> New best test accuracy: 72.72%. Model saved.\n",
      "Epoch [12/200] Loss: 0.6586 Train Acc: 81.91% Test Acc: 72.87% Total Spikes: 9244696 Epoch Time: 55.79s LR: 9.9e-06\n",
      "  -> New best test accuracy: 72.87%. Model saved.\n",
      "Epoch [13/200] Loss: 0.6191 Train Acc: 82.90% Test Acc: 72.89% Total Spikes: 9239371 Epoch Time: 55.63s LR: 9.9e-06\n",
      "  -> New best test accuracy: 72.89%. Model saved.\n",
      "Epoch [14/200] Loss: 0.5844 Train Acc: 83.83% Test Acc: 72.63% Total Spikes: 9206343 Epoch Time: 56.30s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 72.89%\n",
      "Epoch [15/200] Loss: 0.5484 Train Acc: 84.80% Test Acc: 72.88% Total Spikes: 9312485 Epoch Time: 55.83s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 72.89%\n",
      "Epoch [16/200] Loss: 0.5185 Train Acc: 85.54% Test Acc: 72.83% Total Spikes: 9377913 Epoch Time: 55.89s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 72.89%\n",
      "Epoch [17/200] Loss: 0.4850 Train Acc: 86.52% Test Acc: 72.36% Total Spikes: 9420846 Epoch Time: 55.94s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 72.89%\n",
      "Epoch [18/200] Loss: 0.4590 Train Acc: 87.25% Test Acc: 72.71% Total Spikes: 9460844 Epoch Time: 56.14s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 72.89%\n",
      "Epoch [19/200] Loss: 0.4342 Train Acc: 87.96% Test Acc: 72.51% Total Spikes: 9513015 Epoch Time: 55.50s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 72.89%\n",
      "Epoch [20/200] Loss: 0.4057 Train Acc: 88.78% Test Acc: 72.83% Total Spikes: 9481831 Epoch Time: 55.97s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 72.89%\n",
      "Epoch [21/200] Loss: 0.3833 Train Acc: 89.36% Test Acc: 72.50% Total Spikes: 9590886 Epoch Time: 56.15s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 72.89%\n",
      "Epoch [22/200] Loss: 0.3629 Train Acc: 89.83% Test Acc: 72.67% Total Spikes: 9584259 Epoch Time: 55.76s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 72.89%\n",
      "Epoch [23/200] Loss: 0.3400 Train Acc: 90.51% Test Acc: 72.11% Total Spikes: 9575188 Epoch Time: 55.38s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 72.89%\n",
      "Epoch [24/200] Loss: 0.3233 Train Acc: 90.91% Test Acc: 72.43% Total Spikes: 9681575 Epoch Time: 56.06s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 72.89%\n",
      "Epoch [25/200] Loss: 0.3042 Train Acc: 91.58% Test Acc: 72.69% Total Spikes: 9709994 Epoch Time: 56.07s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 72.89%\n",
      "Epoch [26/200] Loss: 0.2897 Train Acc: 92.01% Test Acc: 72.28% Total Spikes: 9759864 Epoch Time: 55.73s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 72.89%\n",
      "Epoch [27/200] Loss: 0.2753 Train Acc: 92.44% Test Acc: 72.24% Total Spikes: 9768140 Epoch Time: 55.71s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 72.89%\n",
      "Epoch [28/200] Loss: 0.2561 Train Acc: 93.03% Test Acc: 72.22% Total Spikes: 9807311 Epoch Time: 55.59s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 72.89%\n",
      "\n",
      "--- Early stopping triggered after 28 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 72.89%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 72.89%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 13): 9239371\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 9239371\n",
      "--- Proposed (CNN-Lorenz-SNN) finished. Best Acc: 72.89%, Spikes at Convergence (Epoch 13): 9239371, Time: 1677.97s, Epochs Trained: 28 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Proposed (CNN-Lorenz-SNN): Best Acc=72.89, Spikes at Convergence=9239371, Time=1677.97s, Epochs=28, Convergence Epoch=13\n",
      "\n",
      "--- Training Proposed (CNN-Osc-SNN Delta=-1.5) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 3.3791 Train Acc: 32.37% Test Acc: 54.24% Total Spikes: 5314164 Epoch Time: 56.52s LR: 1.0e-05\n",
      "  -> New best test accuracy: 54.24%. Model saved.\n",
      "Epoch [2/200] Loss: 1.7958 Train Acc: 58.27% Test Acc: 63.84% Total Spikes: 5543505 Epoch Time: 56.35s LR: 1.0e-05\n",
      "  -> New best test accuracy: 63.84%. Model saved.\n",
      "Epoch [3/200] Loss: 1.4074 Train Acc: 65.24% Test Acc: 66.98% Total Spikes: 5636717 Epoch Time: 56.42s LR: 1.0e-05\n",
      "  -> New best test accuracy: 66.98%. Model saved.\n",
      "Epoch [4/200] Loss: 1.2197 Train Acc: 69.06% Test Acc: 68.72% Total Spikes: 5699427 Epoch Time: 56.38s LR: 1.0e-05\n",
      "  -> New best test accuracy: 68.72%. Model saved.\n",
      "Epoch [5/200] Loss: 1.0956 Train Acc: 71.71% Test Acc: 69.96% Total Spikes: 5754861 Epoch Time: 56.16s LR: 1.0e-05\n",
      "  -> New best test accuracy: 69.96%. Model saved.\n",
      "Epoch [6/200] Loss: 1.0031 Train Acc: 73.83% Test Acc: 70.69% Total Spikes: 5824415 Epoch Time: 56.60s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.69%. Model saved.\n",
      "Epoch [7/200] Loss: 0.9288 Train Acc: 75.59% Test Acc: 72.03% Total Spikes: 5866318 Epoch Time: 56.20s LR: 1.0e-05\n",
      "  -> New best test accuracy: 72.03%. Model saved.\n",
      "Epoch [8/200] Loss: 0.8638 Train Acc: 76.97% Test Acc: 71.98% Total Spikes: 5886286 Epoch Time: 56.30s LR: 1.0e-05\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 72.03%\n",
      "Epoch [9/200] Loss: 0.8096 Train Acc: 78.40% Test Acc: 72.57% Total Spikes: 5936586 Epoch Time: 56.20s LR: 1.0e-05\n",
      "  -> New best test accuracy: 72.57%. Model saved.\n",
      "Epoch [10/200] Loss: 0.7536 Train Acc: 79.83% Test Acc: 72.44% Total Spikes: 5962421 Epoch Time: 56.11s LR: 1.0e-05\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 72.57%\n",
      "Epoch [11/200] Loss: 0.7103 Train Acc: 80.80% Test Acc: 73.07% Total Spikes: 5969861 Epoch Time: 56.50s LR: 9.9e-06\n",
      "  -> New best test accuracy: 73.07%. Model saved.\n",
      "Epoch [12/200] Loss: 0.6703 Train Acc: 81.81% Test Acc: 72.92% Total Spikes: 6015872 Epoch Time: 56.66s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 73.07%\n",
      "Epoch [13/200] Loss: 0.6319 Train Acc: 82.85% Test Acc: 73.04% Total Spikes: 6041550 Epoch Time: 56.88s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 73.07%\n",
      "Epoch [14/200] Loss: 0.5901 Train Acc: 83.96% Test Acc: 72.38% Total Spikes: 6060413 Epoch Time: 56.62s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 73.07%\n",
      "Epoch [15/200] Loss: 0.5591 Train Acc: 84.80% Test Acc: 73.15% Total Spikes: 6075912 Epoch Time: 56.13s LR: 9.9e-06\n",
      "  -> New best test accuracy: 73.15%. Model saved.\n",
      "Epoch [16/200] Loss: 0.5280 Train Acc: 85.67% Test Acc: 73.23% Total Spikes: 6093862 Epoch Time: 56.55s LR: 9.9e-06\n",
      "  -> New best test accuracy: 73.23%. Model saved.\n",
      "Epoch [17/200] Loss: 0.4968 Train Acc: 86.38% Test Acc: 72.89% Total Spikes: 6106361 Epoch Time: 56.44s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 73.23%\n",
      "Epoch [18/200] Loss: 0.4697 Train Acc: 87.16% Test Acc: 73.08% Total Spikes: 6141187 Epoch Time: 56.57s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 73.23%\n",
      "Epoch [19/200] Loss: 0.4431 Train Acc: 87.89% Test Acc: 72.88% Total Spikes: 6139991 Epoch Time: 55.94s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 73.23%\n",
      "Epoch [20/200] Loss: 0.4154 Train Acc: 88.65% Test Acc: 72.83% Total Spikes: 6163432 Epoch Time: 56.21s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 73.23%\n",
      "Epoch [21/200] Loss: 0.3936 Train Acc: 89.26% Test Acc: 72.55% Total Spikes: 6209562 Epoch Time: 56.47s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 73.23%\n",
      "Epoch [22/200] Loss: 0.3685 Train Acc: 90.08% Test Acc: 72.64% Total Spikes: 6224052 Epoch Time: 56.65s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 73.23%\n",
      "Epoch [23/200] Loss: 0.3493 Train Acc: 90.61% Test Acc: 72.74% Total Spikes: 6242498 Epoch Time: 56.49s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 73.23%\n",
      "Epoch [24/200] Loss: 0.3293 Train Acc: 91.13% Test Acc: 72.57% Total Spikes: 6257132 Epoch Time: 56.15s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 73.23%\n",
      "Epoch [25/200] Loss: 0.3126 Train Acc: 91.74% Test Acc: 72.29% Total Spikes: 6282414 Epoch Time: 56.61s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 73.23%\n",
      "Epoch [26/200] Loss: 0.2931 Train Acc: 92.18% Test Acc: 72.41% Total Spikes: 6276178 Epoch Time: 56.30s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 73.23%\n",
      "Epoch [27/200] Loss: 0.2776 Train Acc: 92.59% Test Acc: 72.46% Total Spikes: 6302621 Epoch Time: 56.61s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 73.23%\n",
      "Epoch [28/200] Loss: 0.2644 Train Acc: 93.00% Test Acc: 72.07% Total Spikes: 6312353 Epoch Time: 56.22s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 73.23%\n",
      "Epoch [29/200] Loss: 0.2468 Train Acc: 93.56% Test Acc: 72.23% Total Spikes: 6315769 Epoch Time: 56.28s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 73.23%\n",
      "Epoch [30/200] Loss: 0.2371 Train Acc: 93.88% Test Acc: 72.17% Total Spikes: 6359052 Epoch Time: 56.24s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 73.23%\n",
      "Epoch [31/200] Loss: 0.2208 Train Acc: 94.36% Test Acc: 72.36% Total Spikes: 6371648 Epoch Time: 56.41s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 73.23%\n",
      "\n",
      "--- Early stopping triggered after 31 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 73.23%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 73.23%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 16): 6093862\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 6093862\n",
      "--- Proposed (CNN-Osc-SNN Delta=-1.5) finished. Best Acc: 73.23%, Spikes at Convergence (Epoch 16): 6093862, Time: 1873.33s, Epochs Trained: 31 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Proposed (CNN-Osc-SNN Delta=-1.5): Best Acc=73.23, Spikes at Convergence=6093862, Time=1873.33s, Epochs=31, Convergence Epoch=16\n",
      "\n",
      "--- Training Proposed (CNN-Osc-SNN Delta=10.0) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 3.7103 Train Acc: 29.68% Test Acc: 51.15% Total Spikes: 4471528 Epoch Time: 56.60s LR: 1.0e-05\n",
      "  -> New best test accuracy: 51.15%. Model saved.\n",
      "Epoch [2/200] Loss: 2.0667 Train Acc: 56.39% Test Acc: 62.11% Total Spikes: 4739314 Epoch Time: 56.27s LR: 1.0e-05\n",
      "  -> New best test accuracy: 62.11%. Model saved.\n",
      "Epoch [3/200] Loss: 1.5768 Train Acc: 64.04% Test Acc: 65.94% Total Spikes: 4882170 Epoch Time: 56.46s LR: 1.0e-05\n",
      "  -> New best test accuracy: 65.94%. Model saved.\n",
      "Epoch [4/200] Loss: 1.3391 Train Acc: 68.11% Test Acc: 67.95% Total Spikes: 4918663 Epoch Time: 56.34s LR: 1.0e-05\n",
      "  -> New best test accuracy: 67.95%. Model saved.\n",
      "Epoch [5/200] Loss: 1.1921 Train Acc: 70.80% Test Acc: 69.30% Total Spikes: 4978958 Epoch Time: 56.75s LR: 1.0e-05\n",
      "  -> New best test accuracy: 69.30%. Model saved.\n",
      "Epoch [6/200] Loss: 1.0836 Train Acc: 73.14% Test Acc: 70.38% Total Spikes: 5134445 Epoch Time: 56.82s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.38%. Model saved.\n",
      "Epoch [7/200] Loss: 1.0048 Train Acc: 74.54% Test Acc: 71.26% Total Spikes: 5151351 Epoch Time: 56.33s LR: 1.0e-05\n",
      "  -> New best test accuracy: 71.26%. Model saved.\n",
      "Epoch [8/200] Loss: 0.9347 Train Acc: 76.16% Test Acc: 71.32% Total Spikes: 5179443 Epoch Time: 55.89s LR: 1.0e-05\n",
      "  -> New best test accuracy: 71.32%. Model saved.\n",
      "Epoch [9/200] Loss: 0.8747 Train Acc: 77.51% Test Acc: 71.63% Total Spikes: 5244883 Epoch Time: 56.05s LR: 1.0e-05\n",
      "  -> New best test accuracy: 71.63%. Model saved.\n",
      "Epoch [10/200] Loss: 0.8236 Train Acc: 78.82% Test Acc: 72.16% Total Spikes: 5240791 Epoch Time: 56.59s LR: 1.0e-05\n",
      "  -> New best test accuracy: 72.16%. Model saved.\n",
      "Epoch [11/200] Loss: 0.7760 Train Acc: 79.95% Test Acc: 72.58% Total Spikes: 5208912 Epoch Time: 56.39s LR: 9.9e-06\n",
      "  -> New best test accuracy: 72.58%. Model saved.\n",
      "Epoch [12/200] Loss: 0.7319 Train Acc: 80.95% Test Acc: 71.98% Total Spikes: 5361670 Epoch Time: 56.09s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 72.58%\n",
      "Epoch [13/200] Loss: 0.6899 Train Acc: 81.99% Test Acc: 72.27% Total Spikes: 5314452 Epoch Time: 56.20s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 72.58%\n",
      "Epoch [14/200] Loss: 0.6550 Train Acc: 82.81% Test Acc: 72.29% Total Spikes: 5372295 Epoch Time: 56.32s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 72.58%\n",
      "Epoch [15/200] Loss: 0.6211 Train Acc: 83.72% Test Acc: 72.20% Total Spikes: 5349316 Epoch Time: 56.29s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 72.58%\n",
      "Epoch [16/200] Loss: 0.5878 Train Acc: 84.48% Test Acc: 72.64% Total Spikes: 5400987 Epoch Time: 56.72s LR: 9.9e-06\n",
      "  -> New best test accuracy: 72.64%. Model saved.\n",
      "Epoch [17/200] Loss: 0.5550 Train Acc: 85.53% Test Acc: 72.50% Total Spikes: 5439978 Epoch Time: 56.63s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 72.64%\n",
      "Epoch [18/200] Loss: 0.5247 Train Acc: 86.26% Test Acc: 72.43% Total Spikes: 5405198 Epoch Time: 56.20s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 72.64%\n",
      "Epoch [19/200] Loss: 0.4955 Train Acc: 87.06% Test Acc: 72.86% Total Spikes: 5384689 Epoch Time: 56.94s LR: 9.8e-06\n",
      "  -> New best test accuracy: 72.86%. Model saved.\n",
      "Epoch [20/200] Loss: 0.4704 Train Acc: 87.76% Test Acc: 72.38% Total Spikes: 5462574 Epoch Time: 56.42s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 72.86%\n",
      "Epoch [21/200] Loss: 0.4458 Train Acc: 88.34% Test Acc: 72.20% Total Spikes: 5448786 Epoch Time: 56.40s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 72.86%\n",
      "Epoch [22/200] Loss: 0.4240 Train Acc: 89.03% Test Acc: 72.66% Total Spikes: 5421447 Epoch Time: 56.26s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 72.86%\n",
      "Epoch [23/200] Loss: 0.3989 Train Acc: 89.66% Test Acc: 72.62% Total Spikes: 5453947 Epoch Time: 56.57s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 72.86%\n",
      "Epoch [24/200] Loss: 0.3791 Train Acc: 90.22% Test Acc: 72.61% Total Spikes: 5524979 Epoch Time: 56.64s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 72.86%\n",
      "Epoch [25/200] Loss: 0.3576 Train Acc: 90.83% Test Acc: 72.53% Total Spikes: 5457079 Epoch Time: 56.24s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 72.86%\n",
      "Epoch [26/200] Loss: 0.3406 Train Acc: 91.30% Test Acc: 72.39% Total Spikes: 5484930 Epoch Time: 56.63s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 72.86%\n",
      "Epoch [27/200] Loss: 0.3234 Train Acc: 91.75% Test Acc: 72.65% Total Spikes: 5522401 Epoch Time: 56.14s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 72.86%\n",
      "Epoch [28/200] Loss: 0.3080 Train Acc: 92.17% Test Acc: 72.36% Total Spikes: 5530257 Epoch Time: 56.34s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 72.86%\n",
      "Epoch [29/200] Loss: 0.2887 Train Acc: 92.76% Test Acc: 72.32% Total Spikes: 5534127 Epoch Time: 56.84s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 72.86%\n",
      "Epoch [30/200] Loss: 0.2757 Train Acc: 93.14% Test Acc: 72.55% Total Spikes: 5552169 Epoch Time: 56.31s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 72.86%\n",
      "Epoch [31/200] Loss: 0.2623 Train Acc: 93.62% Test Acc: 72.15% Total Spikes: 5497526 Epoch Time: 56.20s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 72.86%\n",
      "Epoch [32/200] Loss: 0.2503 Train Acc: 93.89% Test Acc: 72.42% Total Spikes: 5547843 Epoch Time: 56.51s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 72.86%\n",
      "Epoch [33/200] Loss: 0.2384 Train Acc: 94.27% Test Acc: 72.38% Total Spikes: 5534909 Epoch Time: 56.46s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 72.86%\n",
      "Epoch [34/200] Loss: 0.2264 Train Acc: 94.68% Test Acc: 72.26% Total Spikes: 5547900 Epoch Time: 56.84s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 72.86%\n",
      "\n",
      "--- Early stopping triggered after 34 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 72.86%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 72.86%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 19): 5384689\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 5384689\n",
      "--- Proposed (CNN-Osc-SNN Delta=10.0) finished. Best Acc: 72.86%, Spikes at Convergence (Epoch 19): 5384689, Time: 2055.18s, Epochs Trained: 34 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Proposed (CNN-Osc-SNN Delta=10.0): Best Acc=72.86, Spikes at Convergence=5384689, Time=2055.18s, Epochs=34, Convergence Epoch=19\n",
      "\n",
      "--- All models processed for this configuration ---\n",
      "Results saved to experiment_results_TinyImageNet_ResNet-18_pretrained/results.json\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Baseline (CNN-ANN)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Baseline (CNN-SNN)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Proposed (CNN-Lorenz-SNN)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Proposed (CNN-Osc-SNN Delta=-1.5)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Proposed (CNN-Osc-SNN Delta=10.0)_spikes.csv\n",
      "Summary table saved to experiment_results_TinyImageNet_ResNet-18_pretrained/summary.csv\n",
      "\n",
      "============================================================\n",
      "实验完成! 结果保存在 'experiment_results_TinyImageNet_ResNet-18_pretrained' 目录中\n",
      "============================================================\n",
      "\n",
      "结果汇总:\n",
      "                      Config Name                             Model Delta/System Best Test Accuracy (%) Spikes at Convergence Training Time (s)  Epochs Trained  Convergence Epoch\n",
      "TinyImageNet_ResNet-18_pretrained                Baseline (CNN-ANN)          ANN                  67.71                     0           1856.11              33                 18\n",
      "TinyImageNet_ResNet-18_pretrained                Baseline (CNN-SNN)   Direct SNN                  72.10               4913525           2663.74              46                 31\n",
      "TinyImageNet_ResNet-18_pretrained         Proposed (CNN-Lorenz-SNN)       Lorenz                  72.89               9239371           1677.97              28                 13\n",
      "TinyImageNet_ResNet-18_pretrained Proposed (CNN-Osc-SNN Delta=-1.5)  Osc(Δ=-1.5)                  73.23               6093862           1873.33              31                 16\n",
      "TinyImageNet_ResNet-18_pretrained Proposed (CNN-Osc-SNN Delta=10.0)  Osc(Δ=10.0)                  72.86               5384689           2055.18              34                 19\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder # Useful for Tiny ImageNet structure\n",
    "import torchvision.transforms as transforms\n",
    "# import matplotlib.pyplot as plt # Keep if needed later\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import copy\n",
    "# from itertools import product # No longer needed for CNN configs\n",
    "import os\n",
    "import json\n",
    "import snntorch as snn\n",
    "import snntorch.surrogate as surrogate\n",
    "from snntorch import utils\n",
    "from snntorch import functional as SF\n",
    "from PIL import Image # Needed for TinyImageNet loading potentially\n",
    "\n",
    "# --- Configuration Class (Updated for Tiny ImageNet & ResNet) ---\n",
    "class Config:\n",
    "    # 数据集\n",
    "    dataset_name = \"TinyImageNet\"\n",
    "    data_root = './tiny-imagenet-200' # <<<--- IMPORTANT: SET PATH TO YOUR TINY IMAGENET FOLDER\n",
    "    batch_size = 64 # May need to reduce based on GPU memory with ResNet\n",
    "    input_size = 224 # Standard input size for ImageNet pre-trained models\n",
    "    num_classes = 200 # Tiny ImageNet has 200 classes\n",
    "\n",
    "    # CNN Backbone (Fixed to ResNet-18)\n",
    "    backbone_name = \"ResNet-18_pretrained\"\n",
    "\n",
    "    # Common SNN/Encoding Parameters\n",
    "    # Projecting 512 ResNet features to 32 might be aggressive.\n",
    "    # Consider increasing chaos_dim, e.g., 128 or 256, for better results.\n",
    "    chaos_dim = 128 # Dimension for projection before oscillator/lorenz/SNN layers\n",
    "    num_steps = 5 # Reduced num_steps initially for faster testing with ResNet\n",
    "\n",
    "    # --- Oscillator Parameters ---\n",
    "    osc_alpha = 2.0\n",
    "    osc_beta = 0.1\n",
    "    osc_gamma = 0.1\n",
    "    osc_omega = 1.0\n",
    "    osc_drive = 0.0\n",
    "    # osc_delta will be set specifically\n",
    "    osc_dt = 0.05\n",
    "\n",
    "    # --- Lorenz Parameters ---\n",
    "    lorenz_sigma = 10.0\n",
    "    lorenz_rho = 28.0\n",
    "    lorenz_beta = 8.0/3.0\n",
    "    lorenz_dt = 0.05\n",
    "\n",
    "    # SNN Decay Rate\n",
    "    beta = 0.95 # SNN Leaky Neuron Beta (Decay Rate)\n",
    "\n",
    "    # 训练\n",
    "    epochs = 200 # Adjust max epochs for Tiny ImageNet & fine-tuning\n",
    "    # Learning rate might need adjustment for fine-tuning ResNet\n",
    "    lr = 1e-4 # Lower initial LR often better for fine-tuning\n",
    "    weight_decay = 5e-4\n",
    "    # Early Stopping\n",
    "    patience = 15 # Maybe increase patience slightly\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "spike_grad = surrogate.fast_sigmoid()\n",
    "\n",
    "# --- OscillatorTransformFast Class (Unchanged) ---\n",
    "class OscillatorTransformFast(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.alpha = config.osc_alpha\n",
    "        self.beta_osc = config.osc_beta\n",
    "        self.gamma = config.osc_gamma\n",
    "        self.delta = getattr(config, 'osc_delta', 0.0)\n",
    "        self.omega = config.osc_omega\n",
    "        self.dt = config.osc_dt\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, dim = x.shape\n",
    "        device = x.device\n",
    "        trajectories = torch.zeros(batch_size, self.num_steps, dim * 3, device=device)\n",
    "        current_delta = self.delta\n",
    "        state = torch.cat([x, x*0.2, -x], dim=1)\n",
    "        trajectories[:, 0, :] = state\n",
    "        for t in range(1, self.num_steps):\n",
    "            x_cur = state[:, :dim]\n",
    "            y_cur = state[:, dim:2 * dim]\n",
    "            z_cur = state[:, 2 * dim:]\n",
    "            dx = y_cur\n",
    "            dy = -self.alpha * x_cur - self.beta_osc * (x_cur**3) - current_delta * y_cur + self.gamma * z_cur\n",
    "            dz = -self.omega * x_cur - current_delta * z_cur + self.gamma * x_cur * y_cur\n",
    "            derivatives = torch.cat([dx, dy, dz], dim=1)\n",
    "            state = state + self.dt * derivatives\n",
    "            trajectories[:, t, :] = state\n",
    "        return trajectories\n",
    "\n",
    "# --- LorenzTransformFast Class (Unchanged) ---\n",
    "class LorenzTransformFast(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.sigma = config.lorenz_sigma\n",
    "        self.rho = config.lorenz_rho\n",
    "        self.lorenz_beta_param = config.lorenz_beta\n",
    "        self.dt = config.lorenz_dt\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, dim = x.shape\n",
    "        device = x.device\n",
    "        trajectories = torch.zeros(batch_size, self.num_steps, dim * 3, device=device)\n",
    "        state = torch.cat([\n",
    "            x,\n",
    "            0.2*x,\n",
    "            -x\n",
    "        ], dim=1)\n",
    "        trajectories[:, 0, :] = state\n",
    "        for t in range(1, self.num_steps):\n",
    "            x_cur = state[:, :dim]\n",
    "            y_cur = state[:, dim:2 * dim]\n",
    "            z_cur = state[:, 2 * dim:]\n",
    "            dx = self.sigma * (y_cur - x_cur)\n",
    "            dy = x_cur * (self.rho - z_cur) - y_cur\n",
    "            dz = x_cur * y_cur - self.lorenz_beta_param * z_cur\n",
    "            state = state + self.dt * torch.cat([dx, dy, dz], dim=1)\n",
    "            trajectories[:, t, :] = state\n",
    "        return trajectories\n",
    "\n",
    "# --- Helper function to get ResNet-18 backbone ---\n",
    "def _get_resnet_backbone(pretrained=True):\n",
    "    \"\"\"Loads a pretrained ResNet-18 model and removes the final fc layer.\"\"\"\n",
    "    if pretrained:\n",
    "        weights = torchvision.models.ResNet18_Weights.IMAGENET1K_V1\n",
    "        model = torchvision.models.resnet18(weights=weights)\n",
    "        print(\"Loaded PRETRAINED ResNet-18 weights.\")\n",
    "    else:\n",
    "        model = torchvision.models.resnet18(weights=None)\n",
    "        print(\"Initialized ResNet-18 weights FROM SCRATCH.\")\n",
    "\n",
    "    # Remove the final fully connected layer (classifier)\n",
    "    model.fc = nn.Identity() # Replace fc layer with identity\n",
    "    return model\n",
    "\n",
    "# --- CNNOscSNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class CNNOscSNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.oscillator = OscillatorTransformFast(config)\n",
    "        self.lif1 = snn.Leaky(beta=config.beta)\n",
    "        self.lif2 = snn.Leaky(beta=config.beta)\n",
    "        self.fc_out = nn.Linear(config.chaos_dim * 3, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, return_spikes=False):\n",
    "        features = self.backbone(x)\n",
    "        x = torch.tanh(self.proj(features))\n",
    "        encoded = self.oscillator(x)\n",
    "        outputs = []\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        batch_total_spikes = 0.0\n",
    "        for step in range(self.num_steps):\n",
    "            cur = encoded[:, step]\n",
    "            spk1, mem1 = self.lif1(cur, mem1)\n",
    "            spk2, mem2 = self.lif2(spk1, mem2)\n",
    "            outputs.append(self.fc_out(spk2))\n",
    "            if return_spikes:\n",
    "                batch_total_spikes += spk1.sum().item() + spk2.sum().item()\n",
    "        final_output = torch.stack(outputs).sum(0)\n",
    "        if return_spikes:\n",
    "            return final_output, torch.tensor(batch_total_spikes, device=final_output.device)\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "# --- CNNLorenzSNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class CNNLorenzSNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.lorenz = LorenzTransformFast(config)\n",
    "        self.lif1 = snn.Leaky(beta=config.beta)\n",
    "        self.lif2 = snn.Leaky(beta=config.beta)\n",
    "        self.fc_out = nn.Linear(config.chaos_dim * 3, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, return_spikes=False):\n",
    "        features = self.backbone(x)\n",
    "        x = torch.tanh(self.proj(features))\n",
    "        encoded = self.lorenz(x)\n",
    "        outputs = []\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        batch_total_spikes = 0.0\n",
    "        for step in range(self.num_steps):\n",
    "            cur = encoded[:, step]\n",
    "            spk1, mem1 = self.lif1(cur, mem1)\n",
    "            spk2, mem2 = self.lif2(spk1, mem2)\n",
    "            outputs.append(self.fc_out(spk2))\n",
    "            if return_spikes:\n",
    "                batch_total_spikes += spk1.sum().item() + spk2.sum().item()\n",
    "        final_output = torch.stack(outputs).sum(0)\n",
    "        if return_spikes:\n",
    "            return final_output, torch.tensor(batch_total_spikes, device=final_output.device)\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "# --- BasicCSNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class BasicCSNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.lif1 = snn.Leaky(beta=config.beta)\n",
    "        self.lif2 = snn.Leaky(beta=config.beta)\n",
    "        self.fc_out = nn.Linear(config.chaos_dim, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, return_spikes=False):\n",
    "        features = self.backbone(x)\n",
    "        cnn_features = torch.tanh(self.proj(features))\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        total_output_mem = 0\n",
    "        batch_total_spikes = 0.0\n",
    "        for _ in range(self.num_steps):\n",
    "            spk1, mem1 = self.lif1(cnn_features, mem1)\n",
    "            spk2, mem2 = self.lif2(spk1, mem2)\n",
    "            total_output_mem += self.fc_out(spk2)\n",
    "            if return_spikes:\n",
    "                batch_total_spikes += spk1.sum().item() + spk2.sum().item()\n",
    "        final_output = total_output_mem / self.num_steps\n",
    "        if return_spikes:\n",
    "            return final_output, torch.tensor(batch_total_spikes, device=final_output.device)\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "# --- BaseCNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class BaseCNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.fc1 = nn.Linear(config.chaos_dim, config.chaos_dim)\n",
    "        self.fc2 = nn.Linear(config.chaos_dim, config.chaos_dim)\n",
    "        self.classifier = nn.Linear(config.chaos_dim, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        features = self.backbone(x)\n",
    "        x = torch.tanh(self.proj(features))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# --- 修改后的 Evaluate 函数 - 返回 total_spikes 而不是 average ---\n",
    "def evaluate(model, loader, config):\n",
    "    \"\"\"Evaluates the model, returns accuracy and total spikes.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_spikes_evaluated = 0.0\n",
    "    is_snn = isinstance(model, (CNNOscSNN, BasicCSNN, CNNLorenzSNN))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            if is_snn:\n",
    "                outputs, batch_spikes = model(images, return_spikes=True)\n",
    "                total_spikes_evaluated += batch_spikes.item()\n",
    "            else:\n",
    "                outputs = model(images) # **kwargs in BaseCNN handles extra args\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    # 修改: 返回 total_spikes 而不是平均值\n",
    "    return accuracy, total_spikes_evaluated\n",
    "\n",
    "\n",
    "# --- 修改后的 Train and Evaluate with History ---\n",
    "def train_and_evaluate_with_history(model, train_loader, test_loader, config):\n",
    "    \"\"\"Trains model with early stopping, returns best test acc, epoch history, and spikes at convergence.\"\"\"\n",
    "    model = model.to(device)\n",
    "    # --- OPTIONAL: Differential Learning Rate ---\n",
    "    # You might want different LRs for backbone and head\n",
    "    # Example:\n",
    "    head_params = [p for n, p in model.named_parameters() if not n.startswith('backbone.')]\n",
    "    backbone_params = [p for n, p in model.named_parameters() if n.startswith('backbone.')]\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': backbone_params, 'lr': config.lr * 0.1}, # Lower LR for backbone\n",
    "        {'params': head_params, 'lr': config.lr} # Normal LR for head\n",
    "    ], weight_decay=config.weight_decay)\n",
    "    # --- Using single LR for simplicity now ---\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_test_acc_epoch = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    patience = config.patience\n",
    "    # Ensure output directory exists before saving temp model\n",
    "    output_dir = f\"experiment_results_{config.dataset_name}_{config.backbone_name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True) # Ensure directory exists\n",
    "    best_model_path = os.path.join(output_dir, f\"temp_best_model_{time.time()}_{id(model)}.pth\") # Save inside output dir\n",
    "    \n",
    "    # 修改: 添加 spike 记录\n",
    "    history = []\n",
    "    spike_counts = []  # 记录每个epoch的spikes\n",
    "    best_epoch = 0  # 记录达到最佳性能的epoch\n",
    "\n",
    "    print(f\"--- Starting Training (Max Epochs: {config.epochs}, Patience: {patience}) ---\")\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        start_epoch_time = time.time()\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader): # Add index i for progress printing\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images, return_spikes=False) # No need for spikes during training loop\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                print(f\"WARNING: Loss is {loss.item()} at epoch {epoch+1}, batch {i}. Skipping backward pass.\")\n",
    "                continue # Skip batch if loss is invalid\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Optional: Print progress within epoch\n",
    "            # if (i + 1) % 100 == 0:\n",
    "            #     print(f'  Epoch [{epoch+1}/{config.epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "        end_epoch_time = time.time()\n",
    "        epoch_duration = end_epoch_time - start_epoch_time\n",
    "\n",
    "        # 修改: 在每个epoch结束后评估并记录spikes\n",
    "        test_acc, epoch_spikes = evaluate(model, test_loader, config)\n",
    "        history.append(test_acc)\n",
    "        spike_counts.append(epoch_spikes)  # 记录总spike数\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader) if len(train_loader) > 0 else 0\n",
    "        train_acc = 100. * train_correct / train_total if train_total > 0 else 0\n",
    "\n",
    "        # 修改: 打印spike信息\n",
    "        print(f\"Epoch [{epoch + 1}/{config.epochs}] Loss: {avg_loss:.4f} \"\n",
    "              f\"Train Acc: {train_acc:.2f}% Test Acc: {test_acc:.2f}% \"\n",
    "              f\"Total Spikes: {epoch_spikes:.0f} \"\n",
    "              f\"Epoch Time: {epoch_duration:.2f}s LR: {scheduler.get_last_lr()[0]:.1e}\")\n",
    "\n",
    "        # Early Stopping Logic\n",
    "        if test_acc > best_test_acc_epoch:\n",
    "            best_test_acc_epoch = test_acc\n",
    "            best_epoch = epoch  # 记录最佳epoch索引\n",
    "            epochs_no_improve = 0\n",
    "            try:\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f\"  -> New best test accuracy: {best_test_acc_epoch:.2f}%. Model saved.\")\n",
    "            except Exception as e:\n",
    "                print(f\"  -> Error saving model: {e}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  -> Test accuracy did not improve for {epochs_no_improve} epoch(s). Best: {best_test_acc_epoch:.2f}%\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"\\n--- Early stopping triggered after {epoch + 1} epochs. ---\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Post-Training: Load Best Model and Final Evaluation\n",
    "    print(\"\\n--- Training finished. Loading best model for final evaluation. ---\")\n",
    "    if os.path.exists(best_model_path):\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(best_model_path))\n",
    "            print(f\"Successfully loaded best model state (Accuracy: {best_test_acc_epoch:.2f}%)\")\n",
    "            os.remove(best_model_path)\n",
    "            # print(f\"Removed temporary model file: {best_model_path}\") # Optional: uncomment to confirm\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading best model state from {best_model_path}: {e}. Using model from last epoch.\")\n",
    "            best_test_acc_epoch = history[-1] if history else 0.0\n",
    "    else:\n",
    "        print(\"No best model was saved (or file missing). Using model from last epoch.\")\n",
    "        best_test_acc_epoch = history[-1] if history else 0.0\n",
    "\n",
    "    print(\"--- Running final evaluation on the best performing model state ---\")\n",
    "    final_test_acc, final_total_spikes = evaluate(model, test_loader, config)\n",
    "\n",
    "    # 修改: 获取收敛时的spike数\n",
    "    spikes_at_convergence = spike_counts[best_epoch] if spike_counts and best_epoch < len(spike_counts) else 0\n",
    "\n",
    "    print(f\"Final Evaluation - Test Accuracy: {final_test_acc:.2f}%\")\n",
    "    if isinstance(model, (CNNOscSNN, BasicCSNN, CNNLorenzSNN)):\n",
    "        print(f\"Final Evaluation - Total Spikes at Convergence (Epoch {best_epoch+1}): {spikes_at_convergence:.0f}\")\n",
    "        print(f\"Final Evaluation - Total Spikes in Final Evaluation: {final_total_spikes:.0f}\")\n",
    "\n",
    "    # 修改: 返回收敛时的spikes (不是平均值)\n",
    "    return best_test_acc_epoch, history, spikes_at_convergence, spike_counts\n",
    "\n",
    "# --- Tiny ImageNet Loading Function (未更改) ---\n",
    "def load_tiny_imagenet(config):\n",
    "    \"\"\"Loads the Tiny ImageNet dataset.\"\"\"\n",
    "    data_dir = config.data_root\n",
    "    num_workers = min(4, os.cpu_count()) if os.cpu_count() else 0\n",
    "    image_size = config.input_size # Should be 224 for pre-trained ResNet\n",
    "\n",
    "    # Standard ImageNet normalization\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # Data augmentation and normalization for training\n",
    "    # Adjust augmentation based on standard practices for ImageNet fine-tuning\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size), # Resize first\n",
    "        transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)), # Standard crop\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    # Just normalization for validation/testing\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size), # Ensure validation images are also resized\n",
    "        transforms.CenterCrop(image_size), # Use CenterCrop for validation\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    # --- Dataset Loading ---\n",
    "    # Tiny ImageNet structure: train/[wnid]/images/*.JPEG, val/images/*.JPEG, val/val_annotations.txt\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    val_dir = os.path.join(data_dir, 'val', 'images') # Validation images are flat\n",
    "\n",
    "    if not os.path.exists(train_dir) or not os.path.exists(val_dir):\n",
    "         raise FileNotFoundError(f\"Tiny ImageNet data not found at expected paths: {train_dir} and {val_dir}. \"\n",
    "                                f\"Please ensure Tiny ImageNet is downloaded and extracted to '{data_dir}' \"\n",
    "                                \"following the standard directory structure.\")\n",
    "\n",
    "    train_dataset = ImageFolder(train_dir, transform=train_transform)\n",
    "\n",
    "    # Validation dataset requires special handling due to annotations file\n",
    "    # Creating a custom Dataset class is cleaner\n",
    "    class TinyImageNetVal(Dataset):\n",
    "        def __init__(self, val_dir, annotations_file, class_to_idx, transform=None):\n",
    "            self.val_dir = val_dir\n",
    "            self.transform = transform\n",
    "            self.class_to_idx = class_to_idx\n",
    "            self.samples = []\n",
    "            try:\n",
    "                with open(annotations_file, 'r') as f:\n",
    "                    for line in f:\n",
    "                        parts = line.strip().split('\\t')\n",
    "                        if len(parts) >= 2:\n",
    "                            img_name, wnid = parts[0], parts[1]\n",
    "                            img_path = os.path.join(self.val_dir, img_name)\n",
    "                            if os.path.exists(img_path) and wnid in self.class_to_idx:\n",
    "                                self.samples.append((img_path, self.class_to_idx[wnid]))\n",
    "                            # else:\n",
    "                                # print(f\"Warning: Skipping invalid validation entry: {line.strip()}\")\n",
    "            except FileNotFoundError:\n",
    "                 raise FileNotFoundError(f\"Validation annotations file not found: {annotations_file}\")\n",
    "\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.samples)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img_path, target = self.samples[idx]\n",
    "            # Ensure images are loaded in RGB format\n",
    "            try:\n",
    "                with open(img_path, 'rb') as f:\n",
    "                    img = Image.open(f).convert('RGB')\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "                # Return a dummy image/target or handle appropriately\n",
    "                return torch.zeros(3, image_size, image_size), -1 # Indicate error\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, target\n",
    "\n",
    "    # Need class_to_idx mapping from the training set folders\n",
    "    class_to_idx = train_dataset.class_to_idx\n",
    "    val_annotations_file = os.path.join(data_dir, 'val', 'val_annotations.txt')\n",
    "    val_dataset = TinyImageNetVal(val_dir, val_annotations_file, class_to_idx, transform=val_transform)\n",
    "\n",
    "\n",
    "    print(f\"Tiny ImageNet - Found {len(train_dataset)} training images belonging to {len(train_dataset.classes)} classes.\")\n",
    "    print(f\"Tiny ImageNet - Found {len(val_dataset)} validation images.\")\n",
    "\n",
    "\n",
    "    # Data Loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=config.batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    # Use validation set as the test set for Tiny ImageNet evaluation\n",
    "    test_loader = DataLoader(\n",
    "        val_dataset, batch_size=config.batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "# --- 修改 Experiment Logger Class ---\n",
    "class ExperimentLogger:\n",
    "    def __init__(self, output_dir=\"experiment_results_tinyimagenet_resnet18\"): # Changed dir name\n",
    "        self.results = {}\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        # 修改: 更新CSV标题，将Average Spikes改为Spikes at Convergence\n",
    "        self.csv_headers = [\n",
    "            \"Config Name\", # Renamed from CNN Config\n",
    "            \"Model\",\n",
    "            \"Delta/System\",\n",
    "            \"Best Test Accuracy (%)\",\n",
    "            \"Spikes at Convergence\", # 修改: 更改列名\n",
    "            \"Training Time (s)\",\n",
    "            \"Epochs Trained\",\n",
    "            \"Convergence Epoch\" # 添加收敛epoch的列\n",
    "        ]\n",
    "\n",
    "    def log_config(self, config_name, config):\n",
    "        config_dict = {}\n",
    "        config_dict['patience'] = config.patience\n",
    "        for key, value in vars(config).items():\n",
    "             if isinstance(value, (int, float, str, bool, list, tuple, dict, type(None))):\n",
    "                 config_dict[key] = value\n",
    "             # ... (rest of serialization logic from previous version)\n",
    "        self.results[config_name] = {\n",
    "            \"config\": config_dict,\n",
    "            \"models\": {}\n",
    "        }\n",
    "\n",
    "    # 修改: 更新log_model_result参数和逻辑\n",
    "    def log_model_result(self, config_name, model_name, accuracy, training_time, epochs_history, spikes_at_convergence, spike_counts, best_epoch):\n",
    "        if config_name not in self.results:\n",
    "            self.results[config_name] = {\"config\": {}, \"models\": {}}\n",
    "            print(f\"Warning: Config '{config_name}' not pre-logged. Creating entry.\")\n",
    "        epochs_trained = len(epochs_history)\n",
    "        self.results[config_name][\"models\"][model_name] = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"training_time\": training_time,\n",
    "            \"epochs_history\": epochs_history, # Storing history can make JSON large\n",
    "            \"spikes_at_convergence\": spikes_at_convergence, # 修改: 改为收敛时的spikes\n",
    "            \"epochs_trained\": epochs_trained,\n",
    "            \"spike_counts\": spike_counts, # 添加: 存储每个epoch的spike数据\n",
    "            \"convergence_epoch\": best_epoch + 1 # 添加: 转换为1-indexed的epoch号\n",
    "        }\n",
    "        print(f\"Logged for {config_name} - {model_name}: Best Acc={accuracy:.2f}, Spikes at Convergence={spikes_at_convergence:.0f}, \"\n",
    "              f\"Time={training_time:.2f}s, Epochs={epochs_trained}, Convergence Epoch={best_epoch+1}\")\n",
    "\n",
    "    def save_results(self):\n",
    "        filepath = os.path.join(self.output_dir, \"results.json\")\n",
    "        try:\n",
    "            # Save only essential results to JSON to avoid large files due to history\n",
    "            results_to_save = {}\n",
    "            for cfg_name, cfg_data in self.results.items():\n",
    "                results_to_save[cfg_name] = {\"config\": cfg_data[\"config\"], \"models\": {}}\n",
    "                for mdl_name, mdl_data in cfg_data[\"models\"].items():\n",
    "                    results_to_save[cfg_name][\"models\"][mdl_name] = {\n",
    "                        k: v for k, v in mdl_data.items() if k not in ['epochs_history', 'spike_counts']\n",
    "                    }\n",
    "            with open(filepath, \"w\") as f:\n",
    "                json.dump(results_to_save, f, indent=4, default=lambda o: '<not serializable>')\n",
    "            print(f\"Results saved to {filepath}\")\n",
    "            \n",
    "            # 添加: 保存spike数据到CSV文件\n",
    "            for cfg_name, cfg_data in self.results.items():\n",
    "                for mdl_name, mdl_data in cfg_data[\"models\"].items():\n",
    "                    if 'spike_counts' in mdl_data and mdl_data['spike_counts']:\n",
    "                        spike_df = pd.DataFrame({\n",
    "                            'Epoch': range(1, len(mdl_data['spike_counts'])+1),\n",
    "                            'Total Spikes': mdl_data['spike_counts']\n",
    "                        })\n",
    "                        spike_file = os.path.join(self.output_dir, f\"{cfg_name}_{mdl_name}_spikes.csv\")\n",
    "                        spike_df.to_csv(spike_file, index=False)\n",
    "                        print(f\"Spike data saved to {spike_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving JSON results: {e}\")\n",
    "\n",
    "\n",
    "    def generate_summary_table(self):\n",
    "        rows = []\n",
    "        for config_name, data in self.results.items():\n",
    "            for model_name, model_data in data[\"models\"].items():\n",
    "                delta_str = \"N/A\"\n",
    "                # Simplified model type identification for summary\n",
    "                if \"Osc-SNN Delta=\" in model_name:\n",
    "                    delta_str = f\"Osc(Δ={model_name.split('=')[-1].split(')')[0]})\"\n",
    "                elif \"Lorenz-SNN\" in model_name:\n",
    "                    delta_str = \"Lorenz\"\n",
    "                elif \"CNN-SNN\" in model_name and \"Osc\" not in model_name and \"Lorenz\" not in model_name:\n",
    "                     delta_str = \"Direct SNN\"\n",
    "                elif \"CNN-ANN\" in model_name:\n",
    "                     delta_str = \"ANN\"\n",
    "\n",
    "                spikes = model_data.get(\"spikes_at_convergence\", 0.0)  # 修改: 使用收敛时的spikes\n",
    "                epochs_trained = model_data.get(\"epochs_trained\", \"N/A\")\n",
    "                convergence_epoch = model_data.get(\"convergence_epoch\", \"N/A\")  # 添加: 获取收敛epoch\n",
    "\n",
    "                row = {\n",
    "                    self.csv_headers[0]: config_name, # Use \"Config Name\"\n",
    "                    self.csv_headers[1]: model_name,\n",
    "                    self.csv_headers[2]: delta_str,\n",
    "                    self.csv_headers[3]: model_data[\"accuracy\"],\n",
    "                    self.csv_headers[4]: spikes,  # 修改: 使用收敛时的spikes\n",
    "                    self.csv_headers[5]: model_data[\"training_time\"],\n",
    "                    self.csv_headers[6]: epochs_trained,\n",
    "                    self.csv_headers[7]: convergence_epoch  # 添加: 收敛epoch\n",
    "                }\n",
    "                rows.append(row)\n",
    "        if not rows: return pd.DataFrame(columns=self.csv_headers)\n",
    "        df = pd.DataFrame(rows)\n",
    "        df = df[self.csv_headers] # Ensure column order\n",
    "        try:\n",
    "            df[self.csv_headers[3]] = pd.to_numeric(df[self.csv_headers[3]], errors='coerce').map('{:.2f}'.format)\n",
    "            df[self.csv_headers[4]] = pd.to_numeric(df[self.csv_headers[4]], errors='coerce').map('{:.0f}'.format)  # 修改: 整数格式\n",
    "            df[self.csv_headers[5]] = pd.to_numeric(df[self.csv_headers[5]], errors='coerce').map('{:.2f}'.format)\n",
    "        except Exception as e: print(f\"Error formatting summary table columns: {e}\")\n",
    "        filepath = os.path.join(self.output_dir, \"summary.csv\")\n",
    "        try: df.to_csv(filepath, index=False); print(f\"Summary table saved to {filepath}\")\n",
    "        except Exception as e: print(f\"Error saving summary CSV: {e}\")\n",
    "        return df\n",
    "\n",
    "    # --- Plotting (Requires Matplotlib) ---\n",
    "    # Consider simplifying or removing plotting if matplotlib is not available/needed now\n",
    "    # def plot_results(self):\n",
    "    #     # ... (Plotting code from previous version - needs matplotlib)\n",
    "    #     # If keeping plots, update logic to handle single config name and model types\n",
    "    #     pass\n",
    "\n",
    "# --- 修改 Main Experiment Function ---\n",
    "def run_experiment():\n",
    "    print(f\"使用设备: {device}\")\n",
    "    config = Config() # Use the updated config\n",
    "    config_name = f\"{config.dataset_name}_{config.backbone_name}\" # Single config name\n",
    "    logger = ExperimentLogger(output_dir=f\"experiment_results_{config_name}\")\n",
    "\n",
    "    # Define the specific oscillator deltas for the two modes\n",
    "    # Use values inspired by Table D1, e.g., one expansive, one dissipative\n",
    "    osc_delta_mode_b = -1.5 # High performance potential (Expansive)\n",
    "    osc_delta_mode_a = 10.0 # High efficiency (Dissipative)\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"开始实验配置: {config_name}\")\n",
    "    print(f\"Dataset: {config.dataset_name} (Root: {config.data_root}, Classes: {config.num_classes}, Input Size: {config.input_size})\")\n",
    "    print(f\"Backbone: {config.backbone_name}\")\n",
    "    print(f\"Max Epochs: {config.epochs}, Patience: {config.patience}, LR: {config.lr}\")\n",
    "    print(f\"Osc Params: alpha={config.osc_alpha}, beta={config.osc_beta}, gamma={config.osc_gamma}, omega={config.osc_omega}, dt={config.osc_dt}\")\n",
    "    print(f\"Lorenz Params: sigma={config.lorenz_sigma:.2f}, rho={config.lorenz_rho:.2f}, beta={config.lorenz_beta:.2f}, dt={config.lorenz_dt}\")\n",
    "    print(f\"SNN Params: steps={config.num_steps}, decay_beta={config.beta:.2f}, chaos_dim={config.chaos_dim}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    logger.log_config(config_name, config)\n",
    "\n",
    "    try:\n",
    "        # Load Tiny ImageNet data\n",
    "        train_loader, test_loader = load_tiny_imagenet(config)\n",
    "    except Exception as e:\n",
    "        print(f\"无法加载数据集 {config_name}. 终止实验. 错误: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None # Exit if data loading fails\n",
    "\n",
    "    # --- Define Models to Run ---\n",
    "    # Ensure pretrained_backbone=True is passed correctly\n",
    "    models_to_run = {\n",
    "        \"Baseline (CNN-ANN)\": BaseCNN(config, pretrained_backbone=True),\n",
    "        \"Baseline (CNN-SNN)\": BasicCSNN(config, pretrained_backbone=True),\n",
    "        \"Proposed (CNN-Lorenz-SNN)\": CNNLorenzSNN(config, pretrained_backbone=True)\n",
    "    }\n",
    "    # Add Oscillator SNNs with specific deltas\n",
    "    osc_config_b = copy.deepcopy(config); osc_config_b.osc_delta = osc_delta_mode_b\n",
    "    models_to_run[f\"Proposed (CNN-Osc-SNN Delta={osc_delta_mode_b})\"] = CNNOscSNN(osc_config_b, pretrained_backbone=True)\n",
    "\n",
    "    osc_config_a = copy.deepcopy(config); osc_config_a.osc_delta = osc_delta_mode_a\n",
    "    models_to_run[f\"Proposed (CNN-Osc-SNN Delta={osc_delta_mode_a})\"] = CNNOscSNN(osc_config_a, pretrained_backbone=True)\n",
    "\n",
    "\n",
    "    # --- Train and Evaluate Models ---\n",
    "    for model_name, model_instance in models_to_run.items():\n",
    "        print(f\"\\n--- Training {model_name} for {config_name} ---\")\n",
    "        start_time = time.time()\n",
    "        # Use a fresh copy for each training run (already done by creating new instances above)\n",
    "        current_model = model_instance\n",
    "        current_config = config # Default config for non-oscillator models\n",
    "        if \"Osc-SNN Delta=\" in model_name:\n",
    "             delta_val = float(model_name.split('=')[-1].split(')')[0])\n",
    "             if delta_val == osc_delta_mode_a: current_config = osc_config_a\n",
    "             elif delta_val == osc_delta_mode_b: current_config = osc_config_b\n",
    "             else: print(f\"Warning: Could not match delta for {model_name}\")\n",
    "\n",
    "\n",
    "        try:\n",
    "            # 修改: 添加对spike_counts和best_epoch的接收\n",
    "            best_acc, epochs_history, spikes_at_convergence, spike_counts = train_and_evaluate_with_history(\n",
    "                current_model, train_loader, test_loader, current_config # Pass correct config\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "            \n",
    "            # 计算best_epoch (0-indexed)\n",
    "            best_epoch = epochs_history.index(best_acc) if best_acc in epochs_history else 0\n",
    "            \n",
    "            print(f\"--- {model_name} finished. Best Acc: {best_acc:.2f}%, \"\n",
    "                 f\"Spikes at Convergence (Epoch {best_epoch+1}): {spikes_at_convergence:.0f}, \"\n",
    "                 f\"Time: {training_time:.2f}s, Epochs Trained: {len(epochs_history)} ---\")\n",
    "                 \n",
    "            # 修改: 更新logger.log_model_result调用\n",
    "            logger.log_model_result(\n",
    "                config_name, model_name, best_acc, training_time, \n",
    "                epochs_history, spikes_at_convergence, spike_counts, best_epoch\n",
    "            )\n",
    "        except Exception as e:\n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "            print(f\"!!! ERROR during training/evaluation for {model_name} on {config_name}: {e}\")\n",
    "            # 修改: 更新错误情况下的logger.log_model_result调用\n",
    "            logger.log_model_result(config_name, model_name, 0.0, training_time, [], 0.0, [], 0)\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            # Decide whether to continue with other models upon error\n",
    "            # continue\n",
    "\n",
    "\n",
    "    # --- Finalize and Save Results ---\n",
    "    print(\"\\n--- All models processed for this configuration ---\")\n",
    "    logger.save_results()\n",
    "    summary_df = logger.generate_summary_table()\n",
    "    # try:\n",
    "    #     logger.plot_results() # Optional plotting\n",
    "    # except Exception as e:\n",
    "    #     print(f\"An error occurred during final plotting: {e}\")\n",
    "    #     import traceback\n",
    "    #     traceback.print_exc()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"实验完成! 结果保存在 '{logger.output_dir}' 目录中\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    if not summary_df.empty:\n",
    "        print(\"结果汇总:\")\n",
    "        # Configure pandas for wider output\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', 2000)\n",
    "        pd.set_option('display.max_colwidth', None) # Show full column width\n",
    "        print(summary_df.to_string(index=False)) # Use to_string for better control\n",
    "        pd.reset_option('all') # Reset pandas display options\n",
    "    else:\n",
    "        print(\"结果汇总为空.\")\n",
    "\n",
    "    return logger\n",
    "\n",
    "# --- Run Experiment ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Optional: Set seeds for reproducibility\n",
    "    # seed = 42\n",
    "    # torch.manual_seed(seed)\n",
    "    # np.random.seed(seed)\n",
    "    # if torch.cuda.is_available():\n",
    "    #     torch.cuda.manual_seed_all(seed)\n",
    "    # # Note: Full determinism can impact performance and might not be guaranteed on GPU\n",
    "    # # torch.backends.cudnn.deterministic = True\n",
    "    # # torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    logger = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "464e2337-3aa6-4f30-a85e-366afbe14aef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "\n",
      "============================================================\n",
      "开始实验配置: TinyImageNet_ResNet-18_pretrained\n",
      "Dataset: TinyImageNet (Root: ./tiny-imagenet-200, Classes: 200, Input Size: 224)\n",
      "Backbone: ResNet-18_pretrained\n",
      "Max Epochs: 200, Patience: 15, LR: 0.0001\n",
      "Osc Params: alpha=2.0, beta=0.1, gamma=0.1, omega=1.0, dt=0.05\n",
      "Lorenz Params: sigma=10.00, rho=28.00, beta=2.67, dt=0.05\n",
      "SNN Params: steps=5, decay_beta=0.95, chaos_dim=256\n",
      "============================================================\n",
      "Tiny ImageNet - Found 100000 training images belonging to 200 classes.\n",
      "Tiny ImageNet - Found 10000 validation images.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "\n",
      "--- Training Baseline (CNN-ANN) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 3.4558 Train Acc: 22.07% Test Acc: 41.06% Total Spikes: 0 Epoch Time: 52.26s LR: 1.0e-05\n",
      "  -> New best test accuracy: 41.06%. Model saved.\n",
      "Epoch [2/200] Loss: 2.1112 Train Acc: 47.16% Test Acc: 54.56% Total Spikes: 0 Epoch Time: 51.40s LR: 1.0e-05\n",
      "  -> New best test accuracy: 54.56%. Model saved.\n",
      "Epoch [3/200] Loss: 1.6920 Train Acc: 57.00% Test Acc: 59.49% Total Spikes: 0 Epoch Time: 51.64s LR: 1.0e-05\n",
      "  -> New best test accuracy: 59.49%. Model saved.\n",
      "Epoch [4/200] Loss: 1.4693 Train Acc: 62.12% Test Acc: 62.92% Total Spikes: 0 Epoch Time: 51.46s LR: 1.0e-05\n",
      "  -> New best test accuracy: 62.92%. Model saved.\n",
      "Epoch [5/200] Loss: 1.3172 Train Acc: 65.72% Test Acc: 64.68% Total Spikes: 0 Epoch Time: 51.85s LR: 1.0e-05\n",
      "  -> New best test accuracy: 64.68%. Model saved.\n",
      "Epoch [6/200] Loss: 1.1979 Train Acc: 68.53% Test Acc: 65.87% Total Spikes: 0 Epoch Time: 51.86s LR: 1.0e-05\n",
      "  -> New best test accuracy: 65.87%. Model saved.\n",
      "Epoch [7/200] Loss: 1.1034 Train Acc: 70.63% Test Acc: 66.87% Total Spikes: 0 Epoch Time: 51.31s LR: 1.0e-05\n",
      "  -> New best test accuracy: 66.87%. Model saved.\n",
      "Epoch [8/200] Loss: 1.0277 Train Acc: 72.43% Test Acc: 67.28% Total Spikes: 0 Epoch Time: 51.80s LR: 1.0e-05\n",
      "  -> New best test accuracy: 67.28%. Model saved.\n",
      "Epoch [9/200] Loss: 0.9550 Train Acc: 74.16% Test Acc: 68.26% Total Spikes: 0 Epoch Time: 51.40s LR: 1.0e-05\n",
      "  -> New best test accuracy: 68.26%. Model saved.\n",
      "Epoch [10/200] Loss: 0.8904 Train Acc: 75.55% Test Acc: 69.04% Total Spikes: 0 Epoch Time: 52.26s LR: 1.0e-05\n",
      "  -> New best test accuracy: 69.04%. Model saved.\n",
      "Epoch [11/200] Loss: 0.8348 Train Acc: 77.11% Test Acc: 68.77% Total Spikes: 0 Epoch Time: 53.87s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 69.04%\n",
      "Epoch [12/200] Loss: 0.7764 Train Acc: 78.29% Test Acc: 68.99% Total Spikes: 0 Epoch Time: 51.63s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 69.04%\n",
      "Epoch [13/200] Loss: 0.7334 Train Acc: 79.41% Test Acc: 69.29% Total Spikes: 0 Epoch Time: 52.71s LR: 9.9e-06\n",
      "  -> New best test accuracy: 69.29%. Model saved.\n",
      "Epoch [14/200] Loss: 0.6867 Train Acc: 80.56% Test Acc: 69.56% Total Spikes: 0 Epoch Time: 51.45s LR: 9.9e-06\n",
      "  -> New best test accuracy: 69.56%. Model saved.\n",
      "Epoch [15/200] Loss: 0.6447 Train Acc: 81.56% Test Acc: 69.84% Total Spikes: 0 Epoch Time: 52.61s LR: 9.9e-06\n",
      "  -> New best test accuracy: 69.84%. Model saved.\n",
      "Epoch [16/200] Loss: 0.6017 Train Acc: 82.73% Test Acc: 69.38% Total Spikes: 0 Epoch Time: 51.54s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 69.84%\n",
      "Epoch [17/200] Loss: 0.5669 Train Acc: 83.79% Test Acc: 69.80% Total Spikes: 0 Epoch Time: 51.55s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 69.84%\n",
      "Epoch [18/200] Loss: 0.5327 Train Acc: 84.57% Test Acc: 69.47% Total Spikes: 0 Epoch Time: 51.53s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 69.84%\n",
      "Epoch [19/200] Loss: 0.4968 Train Acc: 85.45% Test Acc: 69.56% Total Spikes: 0 Epoch Time: 52.13s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 69.84%\n",
      "Epoch [20/200] Loss: 0.4643 Train Acc: 86.22% Test Acc: 69.51% Total Spikes: 0 Epoch Time: 52.23s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 69.84%\n",
      "Epoch [21/200] Loss: 0.4355 Train Acc: 87.08% Test Acc: 69.07% Total Spikes: 0 Epoch Time: 51.92s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 69.84%\n",
      "Epoch [22/200] Loss: 0.4081 Train Acc: 87.77% Test Acc: 69.52% Total Spikes: 0 Epoch Time: 51.89s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 69.84%\n",
      "Epoch [23/200] Loss: 0.3846 Train Acc: 88.56% Test Acc: 69.20% Total Spikes: 0 Epoch Time: 51.58s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 69.84%\n",
      "Epoch [24/200] Loss: 0.3615 Train Acc: 89.16% Test Acc: 69.16% Total Spikes: 0 Epoch Time: 52.22s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 69.84%\n",
      "Epoch [25/200] Loss: 0.3428 Train Acc: 89.71% Test Acc: 69.51% Total Spikes: 0 Epoch Time: 52.01s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 69.84%\n",
      "Epoch [26/200] Loss: 0.3166 Train Acc: 90.46% Test Acc: 69.71% Total Spikes: 0 Epoch Time: 52.37s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 69.84%\n",
      "Epoch [27/200] Loss: 0.2981 Train Acc: 91.03% Test Acc: 69.13% Total Spikes: 0 Epoch Time: 52.16s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 69.84%\n",
      "Epoch [28/200] Loss: 0.2820 Train Acc: 91.35% Test Acc: 68.96% Total Spikes: 0 Epoch Time: 52.54s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 69.84%\n",
      "Epoch [29/200] Loss: 0.2669 Train Acc: 91.89% Test Acc: 69.39% Total Spikes: 0 Epoch Time: 51.62s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 69.84%\n",
      "Epoch [30/200] Loss: 0.2497 Train Acc: 92.33% Test Acc: 69.11% Total Spikes: 0 Epoch Time: 51.67s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 69.84%\n",
      "\n",
      "--- Early stopping triggered after 30 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 69.84%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 69.84%\n",
      "--- Baseline (CNN-ANN) finished. Best Acc: 69.84%, Spikes at Convergence (Epoch 15): 0, Time: 1681.36s, Epochs Trained: 30 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Baseline (CNN-ANN): Best Acc=69.84, Spikes at Convergence=0, Time=1681.36s, Epochs=30, Convergence Epoch=15\n",
      "\n",
      "--- Training Baseline (CNN-SNN) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 4.3938 Train Acc: 25.80% Test Acc: 42.17% Total Spikes: 8514100 Epoch Time: 54.11s LR: 1.0e-05\n",
      "  -> New best test accuracy: 42.17%. Model saved.\n",
      "Epoch [2/200] Loss: 2.9736 Train Acc: 47.58% Test Acc: 54.15% Total Spikes: 9067737 Epoch Time: 53.61s LR: 1.0e-05\n",
      "  -> New best test accuracy: 54.15%. Model saved.\n",
      "Epoch [3/200] Loss: 2.2365 Train Acc: 57.52% Test Acc: 61.12% Total Spikes: 9260028 Epoch Time: 53.57s LR: 1.0e-05\n",
      "  -> New best test accuracy: 61.12%. Model saved.\n",
      "Epoch [4/200] Loss: 1.8301 Train Acc: 63.33% Test Acc: 65.14% Total Spikes: 9385071 Epoch Time: 53.67s LR: 1.0e-05\n",
      "  -> New best test accuracy: 65.14%. Model saved.\n",
      "Epoch [5/200] Loss: 1.5770 Train Acc: 67.18% Test Acc: 67.44% Total Spikes: 9429154 Epoch Time: 53.76s LR: 1.0e-05\n",
      "  -> New best test accuracy: 67.44%. Model saved.\n",
      "Epoch [6/200] Loss: 1.4055 Train Acc: 69.85% Test Acc: 68.97% Total Spikes: 9499893 Epoch Time: 53.47s LR: 1.0e-05\n",
      "  -> New best test accuracy: 68.97%. Model saved.\n",
      "Epoch [7/200] Loss: 1.2834 Train Acc: 71.99% Test Acc: 69.65% Total Spikes: 9488831 Epoch Time: 53.95s LR: 1.0e-05\n",
      "  -> New best test accuracy: 69.65%. Model saved.\n",
      "Epoch [8/200] Loss: 1.1875 Train Acc: 73.77% Test Acc: 70.53% Total Spikes: 9470336 Epoch Time: 53.58s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.53%. Model saved.\n",
      "Epoch [9/200] Loss: 1.1092 Train Acc: 75.20% Test Acc: 71.28% Total Spikes: 9536103 Epoch Time: 53.61s LR: 1.0e-05\n",
      "  -> New best test accuracy: 71.28%. Model saved.\n",
      "Epoch [10/200] Loss: 1.0455 Train Acc: 76.54% Test Acc: 71.46% Total Spikes: 9502505 Epoch Time: 53.64s LR: 1.0e-05\n",
      "  -> New best test accuracy: 71.46%. Model saved.\n",
      "Epoch [11/200] Loss: 0.9872 Train Acc: 77.81% Test Acc: 71.82% Total Spikes: 9496159 Epoch Time: 53.64s LR: 9.9e-06\n",
      "  -> New best test accuracy: 71.82%. Model saved.\n",
      "Epoch [12/200] Loss: 0.9368 Train Acc: 78.87% Test Acc: 72.08% Total Spikes: 9503152 Epoch Time: 54.01s LR: 9.9e-06\n",
      "  -> New best test accuracy: 72.08%. Model saved.\n",
      "Epoch [13/200] Loss: 0.8924 Train Acc: 79.98% Test Acc: 72.37% Total Spikes: 9464150 Epoch Time: 53.72s LR: 9.9e-06\n",
      "  -> New best test accuracy: 72.37%. Model saved.\n",
      "Epoch [14/200] Loss: 0.8523 Train Acc: 80.87% Test Acc: 72.56% Total Spikes: 9458620 Epoch Time: 53.99s LR: 9.9e-06\n",
      "  -> New best test accuracy: 72.56%. Model saved.\n",
      "Epoch [15/200] Loss: 0.8158 Train Acc: 81.79% Test Acc: 72.87% Total Spikes: 9471378 Epoch Time: 53.77s LR: 9.9e-06\n",
      "  -> New best test accuracy: 72.87%. Model saved.\n",
      "Epoch [16/200] Loss: 0.7831 Train Acc: 82.58% Test Acc: 72.90% Total Spikes: 9468632 Epoch Time: 53.95s LR: 9.9e-06\n",
      "  -> New best test accuracy: 72.90%. Model saved.\n",
      "Epoch [17/200] Loss: 0.7507 Train Acc: 83.47% Test Acc: 72.48% Total Spikes: 9423523 Epoch Time: 53.85s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 72.90%\n",
      "Epoch [18/200] Loss: 0.7189 Train Acc: 84.28% Test Acc: 72.85% Total Spikes: 9463904 Epoch Time: 53.77s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 72.90%\n",
      "Epoch [19/200] Loss: 0.6919 Train Acc: 84.96% Test Acc: 73.08% Total Spikes: 9462487 Epoch Time: 53.87s LR: 9.8e-06\n",
      "  -> New best test accuracy: 73.08%. Model saved.\n",
      "Epoch [20/200] Loss: 0.6641 Train Acc: 85.71% Test Acc: 73.04% Total Spikes: 9432892 Epoch Time: 53.87s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 73.08%\n",
      "Epoch [21/200] Loss: 0.6378 Train Acc: 86.43% Test Acc: 72.98% Total Spikes: 9424812 Epoch Time: 53.82s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 73.08%\n",
      "Epoch [22/200] Loss: 0.6140 Train Acc: 86.97% Test Acc: 73.02% Total Spikes: 9431535 Epoch Time: 54.05s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 73.08%\n",
      "Epoch [23/200] Loss: 0.5920 Train Acc: 87.65% Test Acc: 72.98% Total Spikes: 9415941 Epoch Time: 54.68s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 73.08%\n",
      "Epoch [24/200] Loss: 0.5690 Train Acc: 88.29% Test Acc: 72.90% Total Spikes: 9406741 Epoch Time: 54.21s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 73.08%\n",
      "Epoch [25/200] Loss: 0.5503 Train Acc: 88.87% Test Acc: 73.09% Total Spikes: 9415433 Epoch Time: 53.54s LR: 9.6e-06\n",
      "  -> New best test accuracy: 73.09%. Model saved.\n",
      "Epoch [26/200] Loss: 0.5285 Train Acc: 89.41% Test Acc: 73.04% Total Spikes: 9367562 Epoch Time: 53.81s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 73.09%\n",
      "Epoch [27/200] Loss: 0.5099 Train Acc: 89.87% Test Acc: 73.36% Total Spikes: 9347620 Epoch Time: 53.78s LR: 9.6e-06\n",
      "  -> New best test accuracy: 73.36%. Model saved.\n",
      "Epoch [28/200] Loss: 0.4941 Train Acc: 90.36% Test Acc: 72.56% Total Spikes: 9385722 Epoch Time: 53.98s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 73.36%\n",
      "Epoch [29/200] Loss: 0.4764 Train Acc: 90.81% Test Acc: 72.87% Total Spikes: 9401707 Epoch Time: 54.47s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 73.36%\n",
      "Epoch [30/200] Loss: 0.4611 Train Acc: 91.28% Test Acc: 72.88% Total Spikes: 9367101 Epoch Time: 53.54s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 73.36%\n",
      "Epoch [31/200] Loss: 0.4404 Train Acc: 91.86% Test Acc: 72.60% Total Spikes: 9386363 Epoch Time: 53.87s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 73.36%\n",
      "Epoch [32/200] Loss: 0.4289 Train Acc: 92.25% Test Acc: 72.80% Total Spikes: 9358995 Epoch Time: 53.64s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 73.36%\n",
      "Epoch [33/200] Loss: 0.4140 Train Acc: 92.53% Test Acc: 72.61% Total Spikes: 9317525 Epoch Time: 55.19s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 73.36%\n",
      "Epoch [34/200] Loss: 0.4014 Train Acc: 92.87% Test Acc: 73.14% Total Spikes: 9278505 Epoch Time: 55.07s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 73.36%\n",
      "Epoch [35/200] Loss: 0.3865 Train Acc: 93.28% Test Acc: 72.72% Total Spikes: 9352528 Epoch Time: 54.00s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 73.36%\n",
      "Epoch [36/200] Loss: 0.3759 Train Acc: 93.60% Test Acc: 72.89% Total Spikes: 9341938 Epoch Time: 54.16s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 73.36%\n",
      "Epoch [37/200] Loss: 0.3620 Train Acc: 94.02% Test Acc: 72.51% Total Spikes: 9316739 Epoch Time: 54.28s LR: 9.2e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 73.36%\n",
      "Epoch [38/200] Loss: 0.3509 Train Acc: 94.29% Test Acc: 72.48% Total Spikes: 9277011 Epoch Time: 53.98s LR: 9.2e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 73.36%\n",
      "Epoch [39/200] Loss: 0.3393 Train Acc: 94.63% Test Acc: 72.58% Total Spikes: 9229882 Epoch Time: 54.39s LR: 9.1e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 73.36%\n",
      "Epoch [40/200] Loss: 0.3302 Train Acc: 94.88% Test Acc: 72.88% Total Spikes: 9231796 Epoch Time: 54.74s LR: 9.1e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 73.36%\n",
      "Epoch [41/200] Loss: 0.3182 Train Acc: 95.17% Test Acc: 72.49% Total Spikes: 9271798 Epoch Time: 55.05s LR: 9.0e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 73.36%\n",
      "Epoch [42/200] Loss: 0.3111 Train Acc: 95.38% Test Acc: 72.65% Total Spikes: 9255191 Epoch Time: 54.35s LR: 9.0e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 73.36%\n",
      "\n",
      "--- Early stopping triggered after 42 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 73.36%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 73.36%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 27): 9347620\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 9347620\n",
      "--- Baseline (CNN-SNN) finished. Best Acc: 73.36%, Spikes at Convergence (Epoch 27): 9347620, Time: 2438.78s, Epochs Trained: 42 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Baseline (CNN-SNN): Best Acc=73.36, Spikes at Convergence=9347620, Time=2438.78s, Epochs=42, Convergence Epoch=27\n",
      "\n",
      "--- Training Proposed (CNN-Lorenz-SNN) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 2.7140 Train Acc: 42.05% Test Acc: 61.69% Total Spikes: 14767644 Epoch Time: 56.24s LR: 1.0e-05\n",
      "  -> New best test accuracy: 61.69%. Model saved.\n",
      "Epoch [2/200] Loss: 1.4227 Train Acc: 64.28% Test Acc: 68.27% Total Spikes: 15216215 Epoch Time: 56.17s LR: 1.0e-05\n",
      "  -> New best test accuracy: 68.27%. Model saved.\n",
      "Epoch [3/200] Loss: 1.1688 Train Acc: 69.56% Test Acc: 70.68% Total Spikes: 15603290 Epoch Time: 56.61s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.68%. Model saved.\n",
      "Epoch [4/200] Loss: 1.0315 Train Acc: 72.65% Test Acc: 72.13% Total Spikes: 15845345 Epoch Time: 56.26s LR: 1.0e-05\n",
      "  -> New best test accuracy: 72.13%. Model saved.\n",
      "Epoch [5/200] Loss: 0.9304 Train Acc: 75.03% Test Acc: 72.55% Total Spikes: 15767745 Epoch Time: 56.54s LR: 1.0e-05\n",
      "  -> New best test accuracy: 72.55%. Model saved.\n",
      "Epoch [6/200] Loss: 0.8534 Train Acc: 76.85% Test Acc: 73.36% Total Spikes: 16317520 Epoch Time: 56.17s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.36%. Model saved.\n",
      "Epoch [7/200] Loss: 0.7863 Train Acc: 78.46% Test Acc: 72.87% Total Spikes: 16101721 Epoch Time: 56.18s LR: 1.0e-05\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 73.36%\n",
      "Epoch [8/200] Loss: 0.7271 Train Acc: 79.84% Test Acc: 73.33% Total Spikes: 16490517 Epoch Time: 55.85s LR: 1.0e-05\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 73.36%\n",
      "Epoch [9/200] Loss: 0.6776 Train Acc: 81.11% Test Acc: 73.64% Total Spikes: 16385647 Epoch Time: 55.66s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.64%. Model saved.\n",
      "Epoch [10/200] Loss: 0.6306 Train Acc: 82.47% Test Acc: 73.56% Total Spikes: 16523316 Epoch Time: 55.92s LR: 1.0e-05\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 73.64%\n",
      "Epoch [11/200] Loss: 0.5869 Train Acc: 83.52% Test Acc: 73.86% Total Spikes: 16423671 Epoch Time: 55.83s LR: 9.9e-06\n",
      "  -> New best test accuracy: 73.86%. Model saved.\n",
      "Epoch [12/200] Loss: 0.5464 Train Acc: 84.63% Test Acc: 73.84% Total Spikes: 16584143 Epoch Time: 55.78s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 73.86%\n",
      "Epoch [13/200] Loss: 0.5090 Train Acc: 85.58% Test Acc: 73.45% Total Spikes: 16732191 Epoch Time: 56.18s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 73.86%\n",
      "Epoch [14/200] Loss: 0.4765 Train Acc: 86.57% Test Acc: 74.06% Total Spikes: 16891070 Epoch Time: 56.04s LR: 9.9e-06\n",
      "  -> New best test accuracy: 74.06%. Model saved.\n",
      "Epoch [15/200] Loss: 0.4440 Train Acc: 87.38% Test Acc: 73.51% Total Spikes: 16992028 Epoch Time: 55.96s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 74.06%\n",
      "Epoch [16/200] Loss: 0.4191 Train Acc: 88.08% Test Acc: 73.64% Total Spikes: 17140011 Epoch Time: 55.77s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 74.06%\n",
      "Epoch [17/200] Loss: 0.3842 Train Acc: 89.12% Test Acc: 73.62% Total Spikes: 17103476 Epoch Time: 56.04s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 74.06%\n",
      "Epoch [18/200] Loss: 0.3601 Train Acc: 89.84% Test Acc: 73.87% Total Spikes: 17275422 Epoch Time: 55.89s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 74.06%\n",
      "Epoch [19/200] Loss: 0.3360 Train Acc: 90.43% Test Acc: 73.58% Total Spikes: 17130597 Epoch Time: 55.70s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 74.06%\n",
      "Epoch [20/200] Loss: 0.3158 Train Acc: 91.01% Test Acc: 73.45% Total Spikes: 17473859 Epoch Time: 55.70s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 74.06%\n",
      "Epoch [21/200] Loss: 0.2929 Train Acc: 91.68% Test Acc: 73.07% Total Spikes: 17415444 Epoch Time: 55.94s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 74.06%\n",
      "Epoch [22/200] Loss: 0.2729 Train Acc: 92.25% Test Acc: 73.25% Total Spikes: 17541573 Epoch Time: 55.78s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 74.06%\n",
      "Epoch [23/200] Loss: 0.2555 Train Acc: 92.77% Test Acc: 73.63% Total Spikes: 17502768 Epoch Time: 56.45s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 74.06%\n",
      "Epoch [24/200] Loss: 0.2409 Train Acc: 93.13% Test Acc: 73.56% Total Spikes: 17428156 Epoch Time: 56.17s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 74.06%\n",
      "Epoch [25/200] Loss: 0.2233 Train Acc: 93.73% Test Acc: 73.21% Total Spikes: 17548168 Epoch Time: 55.65s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 74.06%\n",
      "Epoch [26/200] Loss: 0.2114 Train Acc: 94.07% Test Acc: 73.23% Total Spikes: 17766313 Epoch Time: 55.93s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 74.06%\n",
      "Epoch [27/200] Loss: 0.1968 Train Acc: 94.52% Test Acc: 73.04% Total Spikes: 17874428 Epoch Time: 55.81s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 74.06%\n",
      "Epoch [28/200] Loss: 0.1869 Train Acc: 94.84% Test Acc: 72.99% Total Spikes: 17873458 Epoch Time: 56.01s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 74.06%\n",
      "Epoch [29/200] Loss: 0.1752 Train Acc: 95.18% Test Acc: 72.94% Total Spikes: 17657220 Epoch Time: 55.79s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 74.06%\n",
      "\n",
      "--- Early stopping triggered after 29 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 74.06%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 74.06%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 14): 16891070\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 16891070\n",
      "--- Proposed (CNN-Lorenz-SNN) finished. Best Acc: 74.06%, Spikes at Convergence (Epoch 14): 16891070, Time: 1743.50s, Epochs Trained: 29 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Proposed (CNN-Lorenz-SNN): Best Acc=74.06, Spikes at Convergence=16891070, Time=1743.50s, Epochs=29, Convergence Epoch=14\n",
      "\n",
      "--- Training Proposed (CNN-Osc-SNN Delta=-1.5) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 2.8591 Train Acc: 41.03% Test Acc: 61.04% Total Spikes: 9624711 Epoch Time: 57.23s LR: 1.0e-05\n",
      "  -> New best test accuracy: 61.04%. Model saved.\n",
      "Epoch [2/200] Loss: 1.4688 Train Acc: 63.96% Test Acc: 67.60% Total Spikes: 9948600 Epoch Time: 56.60s LR: 1.0e-05\n",
      "  -> New best test accuracy: 67.60%. Model saved.\n",
      "Epoch [3/200] Loss: 1.1960 Train Acc: 69.20% Test Acc: 70.18% Total Spikes: 10113021 Epoch Time: 56.65s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.18%. Model saved.\n",
      "Epoch [4/200] Loss: 1.0479 Train Acc: 72.57% Test Acc: 71.59% Total Spikes: 10250009 Epoch Time: 56.61s LR: 1.0e-05\n",
      "  -> New best test accuracy: 71.59%. Model saved.\n",
      "Epoch [5/200] Loss: 0.9441 Train Acc: 74.96% Test Acc: 72.65% Total Spikes: 10364495 Epoch Time: 56.38s LR: 1.0e-05\n",
      "  -> New best test accuracy: 72.65%. Model saved.\n",
      "Epoch [6/200] Loss: 0.8632 Train Acc: 76.76% Test Acc: 72.56% Total Spikes: 10519583 Epoch Time: 56.38s LR: 1.0e-05\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 72.65%\n",
      "Epoch [7/200] Loss: 0.7965 Train Acc: 78.61% Test Acc: 73.32% Total Spikes: 10562499 Epoch Time: 56.41s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.32%. Model saved.\n",
      "Epoch [8/200] Loss: 0.7378 Train Acc: 79.90% Test Acc: 73.46% Total Spikes: 10637226 Epoch Time: 56.44s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.46%. Model saved.\n",
      "Epoch [9/200] Loss: 0.6866 Train Acc: 81.15% Test Acc: 73.91% Total Spikes: 10704138 Epoch Time: 56.41s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.91%. Model saved.\n",
      "Epoch [10/200] Loss: 0.6378 Train Acc: 82.36% Test Acc: 73.90% Total Spikes: 10746150 Epoch Time: 56.36s LR: 1.0e-05\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 73.91%\n",
      "Epoch [11/200] Loss: 0.5943 Train Acc: 83.57% Test Acc: 74.03% Total Spikes: 10819997 Epoch Time: 56.69s LR: 9.9e-06\n",
      "  -> New best test accuracy: 74.03%. Model saved.\n",
      "Epoch [12/200] Loss: 0.5528 Train Acc: 84.75% Test Acc: 74.12% Total Spikes: 10839630 Epoch Time: 56.81s LR: 9.9e-06\n",
      "  -> New best test accuracy: 74.12%. Model saved.\n",
      "Epoch [13/200] Loss: 0.5149 Train Acc: 85.72% Test Acc: 74.14% Total Spikes: 10898830 Epoch Time: 56.14s LR: 9.9e-06\n",
      "  -> New best test accuracy: 74.14%. Model saved.\n",
      "Epoch [14/200] Loss: 0.4835 Train Acc: 86.41% Test Acc: 74.03% Total Spikes: 10950308 Epoch Time: 56.28s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 74.14%\n",
      "Epoch [15/200] Loss: 0.4479 Train Acc: 87.37% Test Acc: 74.06% Total Spikes: 11058716 Epoch Time: 56.59s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 74.14%\n",
      "Epoch [16/200] Loss: 0.4213 Train Acc: 88.30% Test Acc: 74.13% Total Spikes: 11042247 Epoch Time: 56.22s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 74.14%\n",
      "Epoch [17/200] Loss: 0.3880 Train Acc: 89.11% Test Acc: 74.12% Total Spikes: 11085863 Epoch Time: 57.10s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 74.14%\n",
      "Epoch [18/200] Loss: 0.3639 Train Acc: 89.81% Test Acc: 73.61% Total Spikes: 11150447 Epoch Time: 56.72s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 74.14%\n",
      "Epoch [19/200] Loss: 0.3390 Train Acc: 90.56% Test Acc: 73.99% Total Spikes: 11170120 Epoch Time: 56.38s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 74.14%\n",
      "Epoch [20/200] Loss: 0.3139 Train Acc: 91.32% Test Acc: 74.06% Total Spikes: 11257905 Epoch Time: 56.34s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 74.14%\n",
      "Epoch [21/200] Loss: 0.2979 Train Acc: 91.75% Test Acc: 73.92% Total Spikes: 11264568 Epoch Time: 56.45s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 74.14%\n",
      "Epoch [22/200] Loss: 0.2767 Train Acc: 92.44% Test Acc: 73.34% Total Spikes: 11345859 Epoch Time: 56.11s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 74.14%\n",
      "Epoch [23/200] Loss: 0.2568 Train Acc: 93.01% Test Acc: 73.95% Total Spikes: 11333700 Epoch Time: 56.17s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 74.14%\n",
      "Epoch [24/200] Loss: 0.2413 Train Acc: 93.38% Test Acc: 73.59% Total Spikes: 11421702 Epoch Time: 56.24s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 74.14%\n",
      "Epoch [25/200] Loss: 0.2274 Train Acc: 93.87% Test Acc: 73.60% Total Spikes: 11424740 Epoch Time: 56.89s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 74.14%\n",
      "Epoch [26/200] Loss: 0.2130 Train Acc: 94.27% Test Acc: 73.34% Total Spikes: 11432083 Epoch Time: 55.91s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 74.14%\n",
      "Epoch [27/200] Loss: 0.2003 Train Acc: 94.70% Test Acc: 73.20% Total Spikes: 11483937 Epoch Time: 56.73s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 74.14%\n",
      "Epoch [28/200] Loss: 0.1868 Train Acc: 95.08% Test Acc: 73.64% Total Spikes: 11539189 Epoch Time: 56.31s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 74.14%\n",
      "\n",
      "--- Early stopping triggered after 28 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 74.14%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 74.14%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 13): 10898830\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 10898830\n",
      "--- Proposed (CNN-Osc-SNN Delta=-1.5) finished. Best Acc: 74.14%, Spikes at Convergence (Epoch 13): 10898830, Time: 1694.99s, Epochs Trained: 28 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Proposed (CNN-Osc-SNN Delta=-1.5): Best Acc=74.14, Spikes at Convergence=10898830, Time=1694.99s, Epochs=28, Convergence Epoch=13\n",
      "\n",
      "--- Training Proposed (CNN-Osc-SNN Delta=10.0) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 3.1199 Train Acc: 39.02% Test Acc: 60.88% Total Spikes: 8592728 Epoch Time: 56.56s LR: 1.0e-05\n",
      "  -> New best test accuracy: 60.88%. Model saved.\n",
      "Epoch [2/200] Loss: 1.5911 Train Acc: 63.18% Test Acc: 67.52% Total Spikes: 9012441 Epoch Time: 56.59s LR: 1.0e-05\n",
      "  -> New best test accuracy: 67.52%. Model saved.\n",
      "Epoch [3/200] Loss: 1.2687 Train Acc: 68.65% Test Acc: 70.11% Total Spikes: 9170257 Epoch Time: 56.50s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.11%. Model saved.\n",
      "Epoch [4/200] Loss: 1.1036 Train Acc: 71.99% Test Acc: 71.36% Total Spikes: 9376543 Epoch Time: 56.29s LR: 1.0e-05\n",
      "  -> New best test accuracy: 71.36%. Model saved.\n",
      "Epoch [5/200] Loss: 0.9963 Train Acc: 74.39% Test Acc: 71.76% Total Spikes: 9369855 Epoch Time: 56.21s LR: 1.0e-05\n",
      "  -> New best test accuracy: 71.76%. Model saved.\n",
      "Epoch [6/200] Loss: 0.9122 Train Acc: 76.21% Test Acc: 72.69% Total Spikes: 9550424 Epoch Time: 56.41s LR: 1.0e-05\n",
      "  -> New best test accuracy: 72.69%. Model saved.\n",
      "Epoch [7/200] Loss: 0.8429 Train Acc: 77.84% Test Acc: 73.13% Total Spikes: 9567034 Epoch Time: 57.02s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.13%. Model saved.\n",
      "Epoch [8/200] Loss: 0.7817 Train Acc: 79.27% Test Acc: 73.40% Total Spikes: 9598980 Epoch Time: 56.28s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.40%. Model saved.\n",
      "Epoch [9/200] Loss: 0.7284 Train Acc: 80.62% Test Acc: 73.12% Total Spikes: 9634636 Epoch Time: 56.13s LR: 1.0e-05\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 73.40%\n",
      "Epoch [10/200] Loss: 0.6798 Train Acc: 81.71% Test Acc: 73.17% Total Spikes: 9841842 Epoch Time: 57.24s LR: 1.0e-05\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 73.40%\n",
      "Epoch [11/200] Loss: 0.6359 Train Acc: 82.87% Test Acc: 73.49% Total Spikes: 9820626 Epoch Time: 56.99s LR: 9.9e-06\n",
      "  -> New best test accuracy: 73.49%. Model saved.\n",
      "Epoch [12/200] Loss: 0.5949 Train Acc: 83.90% Test Acc: 73.50% Total Spikes: 9938599 Epoch Time: 56.52s LR: 9.9e-06\n",
      "  -> New best test accuracy: 73.50%. Model saved.\n",
      "Epoch [13/200] Loss: 0.5578 Train Acc: 84.91% Test Acc: 73.42% Total Spikes: 9809927 Epoch Time: 56.21s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 73.50%\n",
      "Epoch [14/200] Loss: 0.5176 Train Acc: 85.99% Test Acc: 73.67% Total Spikes: 9859015 Epoch Time: 56.55s LR: 9.9e-06\n",
      "  -> New best test accuracy: 73.67%. Model saved.\n",
      "Epoch [15/200] Loss: 0.4911 Train Acc: 86.73% Test Acc: 73.35% Total Spikes: 9990748 Epoch Time: 56.26s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 73.67%\n",
      "Epoch [16/200] Loss: 0.4565 Train Acc: 87.66% Test Acc: 73.59% Total Spikes: 10064650 Epoch Time: 56.25s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 73.67%\n",
      "Epoch [17/200] Loss: 0.4304 Train Acc: 88.29% Test Acc: 73.53% Total Spikes: 9905195 Epoch Time: 56.26s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 73.67%\n",
      "Epoch [18/200] Loss: 0.4030 Train Acc: 89.15% Test Acc: 73.78% Total Spikes: 10115093 Epoch Time: 56.38s LR: 9.8e-06\n",
      "  -> New best test accuracy: 73.78%. Model saved.\n",
      "Epoch [19/200] Loss: 0.3792 Train Acc: 89.70% Test Acc: 73.64% Total Spikes: 10237485 Epoch Time: 56.76s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 73.78%\n",
      "Epoch [20/200] Loss: 0.3526 Train Acc: 90.58% Test Acc: 73.29% Total Spikes: 10200664 Epoch Time: 56.56s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 73.78%\n",
      "Epoch [21/200] Loss: 0.3290 Train Acc: 91.16% Test Acc: 73.16% Total Spikes: 10114466 Epoch Time: 56.35s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 73.78%\n",
      "Epoch [22/200] Loss: 0.3059 Train Acc: 91.89% Test Acc: 73.47% Total Spikes: 10103926 Epoch Time: 56.26s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 73.78%\n",
      "Epoch [23/200] Loss: 0.2892 Train Acc: 92.37% Test Acc: 73.07% Total Spikes: 10154972 Epoch Time: 56.16s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 73.78%\n",
      "Epoch [24/200] Loss: 0.2729 Train Acc: 92.81% Test Acc: 73.31% Total Spikes: 10172381 Epoch Time: 56.39s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 73.78%\n",
      "Epoch [25/200] Loss: 0.2553 Train Acc: 93.37% Test Acc: 73.34% Total Spikes: 10185776 Epoch Time: 56.42s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 73.78%\n",
      "Epoch [26/200] Loss: 0.2373 Train Acc: 93.97% Test Acc: 73.21% Total Spikes: 10211799 Epoch Time: 56.60s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 73.78%\n",
      "Epoch [27/200] Loss: 0.2243 Train Acc: 94.24% Test Acc: 72.90% Total Spikes: 10228239 Epoch Time: 56.94s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 73.78%\n",
      "Epoch [28/200] Loss: 0.2097 Train Acc: 94.75% Test Acc: 72.97% Total Spikes: 10220943 Epoch Time: 57.06s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 73.78%\n",
      "Epoch [29/200] Loss: 0.2009 Train Acc: 94.92% Test Acc: 72.94% Total Spikes: 10190199 Epoch Time: 56.30s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 73.78%\n",
      "Epoch [30/200] Loss: 0.1875 Train Acc: 95.42% Test Acc: 73.06% Total Spikes: 10281416 Epoch Time: 56.54s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 73.78%\n",
      "Epoch [31/200] Loss: 0.1736 Train Acc: 95.82% Test Acc: 73.04% Total Spikes: 10225833 Epoch Time: 56.17s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 73.78%\n",
      "Epoch [32/200] Loss: 0.1677 Train Acc: 95.94% Test Acc: 73.14% Total Spikes: 10391939 Epoch Time: 56.60s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 73.78%\n",
      "Epoch [33/200] Loss: 0.1585 Train Acc: 96.25% Test Acc: 72.87% Total Spikes: 10316813 Epoch Time: 56.45s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 73.78%\n",
      "\n",
      "--- Early stopping triggered after 33 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 73.78%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 73.78%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 18): 10115093\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 10115093\n",
      "--- Proposed (CNN-Osc-SNN Delta=10.0) finished. Best Acc: 73.78%, Spikes at Convergence (Epoch 18): 10115093, Time: 1996.68s, Epochs Trained: 33 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Proposed (CNN-Osc-SNN Delta=10.0): Best Acc=73.78, Spikes at Convergence=10115093, Time=1996.68s, Epochs=33, Convergence Epoch=18\n",
      "\n",
      "--- All models processed for this configuration ---\n",
      "Results saved to experiment_results_TinyImageNet_ResNet-18_pretrained/results.json\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Baseline (CNN-ANN)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Baseline (CNN-SNN)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Proposed (CNN-Lorenz-SNN)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Proposed (CNN-Osc-SNN Delta=-1.5)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Proposed (CNN-Osc-SNN Delta=10.0)_spikes.csv\n",
      "Summary table saved to experiment_results_TinyImageNet_ResNet-18_pretrained/summary.csv\n",
      "\n",
      "============================================================\n",
      "实验完成! 结果保存在 'experiment_results_TinyImageNet_ResNet-18_pretrained' 目录中\n",
      "============================================================\n",
      "\n",
      "结果汇总:\n",
      "                      Config Name                             Model Delta/System Best Test Accuracy (%) Spikes at Convergence Training Time (s)  Epochs Trained  Convergence Epoch\n",
      "TinyImageNet_ResNet-18_pretrained                Baseline (CNN-ANN)          ANN                  69.84                     0           1681.36              30                 15\n",
      "TinyImageNet_ResNet-18_pretrained                Baseline (CNN-SNN)   Direct SNN                  73.36               9347620           2438.78              42                 27\n",
      "TinyImageNet_ResNet-18_pretrained         Proposed (CNN-Lorenz-SNN)       Lorenz                  74.06              16891070           1743.50              29                 14\n",
      "TinyImageNet_ResNet-18_pretrained Proposed (CNN-Osc-SNN Delta=-1.5)  Osc(Δ=-1.5)                  74.14              10898830           1694.99              28                 13\n",
      "TinyImageNet_ResNet-18_pretrained Proposed (CNN-Osc-SNN Delta=10.0)  Osc(Δ=10.0)                  73.78              10115093           1996.68              33                 18\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder # Useful for Tiny ImageNet structure\n",
    "import torchvision.transforms as transforms\n",
    "# import matplotlib.pyplot as plt # Keep if needed later\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import copy\n",
    "# from itertools import product # No longer needed for CNN configs\n",
    "import os\n",
    "import json\n",
    "import snntorch as snn\n",
    "import snntorch.surrogate as surrogate\n",
    "from snntorch import utils\n",
    "from snntorch import functional as SF\n",
    "from PIL import Image # Needed for TinyImageNet loading potentially\n",
    "\n",
    "# --- Configuration Class (Updated for Tiny ImageNet & ResNet) ---\n",
    "class Config:\n",
    "    # 数据集\n",
    "    dataset_name = \"TinyImageNet\"\n",
    "    data_root = './tiny-imagenet-200' # <<<--- IMPORTANT: SET PATH TO YOUR TINY IMAGENET FOLDER\n",
    "    batch_size = 64 # May need to reduce based on GPU memory with ResNet\n",
    "    input_size = 224 # Standard input size for ImageNet pre-trained models\n",
    "    num_classes = 200 # Tiny ImageNet has 200 classes\n",
    "\n",
    "    # CNN Backbone (Fixed to ResNet-18)\n",
    "    backbone_name = \"ResNet-18_pretrained\"\n",
    "\n",
    "    # Common SNN/Encoding Parameters\n",
    "    # Projecting 512 ResNet features to 32 might be aggressive.\n",
    "    # Consider increasing chaos_dim, e.g., 128 or 256, for better results.\n",
    "    chaos_dim = 256 # Dimension for projection before oscillator/lorenz/SNN layers\n",
    "    num_steps = 5 # Reduced num_steps initially for faster testing with ResNet\n",
    "\n",
    "    # --- Oscillator Parameters ---\n",
    "    osc_alpha = 2.0\n",
    "    osc_beta = 0.1\n",
    "    osc_gamma = 0.1\n",
    "    osc_omega = 1.0\n",
    "    osc_drive = 0.0\n",
    "    # osc_delta will be set specifically\n",
    "    osc_dt = 0.05\n",
    "\n",
    "    # --- Lorenz Parameters ---\n",
    "    lorenz_sigma = 10.0\n",
    "    lorenz_rho = 28.0\n",
    "    lorenz_beta = 8.0/3.0\n",
    "    lorenz_dt = 0.05\n",
    "\n",
    "    # SNN Decay Rate\n",
    "    beta = 0.95 # SNN Leaky Neuron Beta (Decay Rate)\n",
    "\n",
    "    # 训练\n",
    "    epochs = 200 # Adjust max epochs for Tiny ImageNet & fine-tuning\n",
    "    # Learning rate might need adjustment for fine-tuning ResNet\n",
    "    lr = 1e-4 # Lower initial LR often better for fine-tuning\n",
    "    weight_decay = 5e-4\n",
    "    # Early Stopping\n",
    "    patience = 15 # Maybe increase patience slightly\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "spike_grad = surrogate.fast_sigmoid()\n",
    "\n",
    "# --- OscillatorTransformFast Class (Unchanged) ---\n",
    "class OscillatorTransformFast(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.alpha = config.osc_alpha\n",
    "        self.beta_osc = config.osc_beta\n",
    "        self.gamma = config.osc_gamma\n",
    "        self.delta = getattr(config, 'osc_delta', 0.0)\n",
    "        self.omega = config.osc_omega\n",
    "        self.dt = config.osc_dt\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, dim = x.shape\n",
    "        device = x.device\n",
    "        trajectories = torch.zeros(batch_size, self.num_steps, dim * 3, device=device)\n",
    "        current_delta = self.delta\n",
    "        state = torch.cat([x, x*0.2, -x], dim=1)\n",
    "        trajectories[:, 0, :] = state\n",
    "        for t in range(1, self.num_steps):\n",
    "            x_cur = state[:, :dim]\n",
    "            y_cur = state[:, dim:2 * dim]\n",
    "            z_cur = state[:, 2 * dim:]\n",
    "            dx = y_cur\n",
    "            dy = -self.alpha * x_cur - self.beta_osc * (x_cur**3) - current_delta * y_cur + self.gamma * z_cur\n",
    "            dz = -self.omega * x_cur - current_delta * z_cur + self.gamma * x_cur * y_cur\n",
    "            derivatives = torch.cat([dx, dy, dz], dim=1)\n",
    "            state = state + self.dt * derivatives\n",
    "            trajectories[:, t, :] = state\n",
    "        return trajectories\n",
    "\n",
    "# --- LorenzTransformFast Class (Unchanged) ---\n",
    "class LorenzTransformFast(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.sigma = config.lorenz_sigma\n",
    "        self.rho = config.lorenz_rho\n",
    "        self.lorenz_beta_param = config.lorenz_beta\n",
    "        self.dt = config.lorenz_dt\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, dim = x.shape\n",
    "        device = x.device\n",
    "        trajectories = torch.zeros(batch_size, self.num_steps, dim * 3, device=device)\n",
    "        state = torch.cat([\n",
    "            x,\n",
    "            0.2*x,\n",
    "            -x\n",
    "        ], dim=1)\n",
    "        trajectories[:, 0, :] = state\n",
    "        for t in range(1, self.num_steps):\n",
    "            x_cur = state[:, :dim]\n",
    "            y_cur = state[:, dim:2 * dim]\n",
    "            z_cur = state[:, 2 * dim:]\n",
    "            dx = self.sigma * (y_cur - x_cur)\n",
    "            dy = x_cur * (self.rho - z_cur) - y_cur\n",
    "            dz = x_cur * y_cur - self.lorenz_beta_param * z_cur\n",
    "            state = state + self.dt * torch.cat([dx, dy, dz], dim=1)\n",
    "            trajectories[:, t, :] = state\n",
    "        return trajectories\n",
    "\n",
    "# --- Helper function to get ResNet-18 backbone ---\n",
    "def _get_resnet_backbone(pretrained=True):\n",
    "    \"\"\"Loads a pretrained ResNet-18 model and removes the final fc layer.\"\"\"\n",
    "    if pretrained:\n",
    "        weights = torchvision.models.ResNet18_Weights.IMAGENET1K_V1\n",
    "        model = torchvision.models.resnet18(weights=weights)\n",
    "        print(\"Loaded PRETRAINED ResNet-18 weights.\")\n",
    "    else:\n",
    "        model = torchvision.models.resnet18(weights=None)\n",
    "        print(\"Initialized ResNet-18 weights FROM SCRATCH.\")\n",
    "\n",
    "    # Remove the final fully connected layer (classifier)\n",
    "    model.fc = nn.Identity() # Replace fc layer with identity\n",
    "    return model\n",
    "\n",
    "# --- CNNOscSNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class CNNOscSNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.oscillator = OscillatorTransformFast(config)\n",
    "        self.lif1 = snn.Leaky(beta=config.beta)\n",
    "        self.lif2 = snn.Leaky(beta=config.beta)\n",
    "        self.fc_out = nn.Linear(config.chaos_dim * 3, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, return_spikes=False):\n",
    "        features = self.backbone(x)\n",
    "        x = torch.tanh(self.proj(features))\n",
    "        encoded = self.oscillator(x)\n",
    "        outputs = []\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        batch_total_spikes = 0.0\n",
    "        for step in range(self.num_steps):\n",
    "            cur = encoded[:, step]\n",
    "            spk1, mem1 = self.lif1(cur, mem1)\n",
    "            spk2, mem2 = self.lif2(spk1, mem2)\n",
    "            outputs.append(self.fc_out(spk2))\n",
    "            if return_spikes:\n",
    "                batch_total_spikes += spk1.sum().item() + spk2.sum().item()\n",
    "        final_output = torch.stack(outputs).sum(0)\n",
    "        if return_spikes:\n",
    "            return final_output, torch.tensor(batch_total_spikes, device=final_output.device)\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "# --- CNNLorenzSNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class CNNLorenzSNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.lorenz = LorenzTransformFast(config)\n",
    "        self.lif1 = snn.Leaky(beta=config.beta)\n",
    "        self.lif2 = snn.Leaky(beta=config.beta)\n",
    "        self.fc_out = nn.Linear(config.chaos_dim * 3, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, return_spikes=False):\n",
    "        features = self.backbone(x)\n",
    "        x = torch.tanh(self.proj(features))\n",
    "        encoded = self.lorenz(x)\n",
    "        outputs = []\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        batch_total_spikes = 0.0\n",
    "        for step in range(self.num_steps):\n",
    "            cur = encoded[:, step]\n",
    "            spk1, mem1 = self.lif1(cur, mem1)\n",
    "            spk2, mem2 = self.lif2(spk1, mem2)\n",
    "            outputs.append(self.fc_out(spk2))\n",
    "            if return_spikes:\n",
    "                batch_total_spikes += spk1.sum().item() + spk2.sum().item()\n",
    "        final_output = torch.stack(outputs).sum(0)\n",
    "        if return_spikes:\n",
    "            return final_output, torch.tensor(batch_total_spikes, device=final_output.device)\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "# --- BasicCSNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class BasicCSNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.lif1 = snn.Leaky(beta=config.beta)\n",
    "        self.lif2 = snn.Leaky(beta=config.beta)\n",
    "        self.fc_out = nn.Linear(config.chaos_dim, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, return_spikes=False):\n",
    "        features = self.backbone(x)\n",
    "        cnn_features = torch.tanh(self.proj(features))\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        total_output_mem = 0\n",
    "        batch_total_spikes = 0.0\n",
    "        for _ in range(self.num_steps):\n",
    "            spk1, mem1 = self.lif1(cnn_features, mem1)\n",
    "            spk2, mem2 = self.lif2(spk1, mem2)\n",
    "            total_output_mem += self.fc_out(spk2)\n",
    "            if return_spikes:\n",
    "                batch_total_spikes += spk1.sum().item() + spk2.sum().item()\n",
    "        final_output = total_output_mem / self.num_steps\n",
    "        if return_spikes:\n",
    "            return final_output, torch.tensor(batch_total_spikes, device=final_output.device)\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "# --- BaseCNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class BaseCNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.fc1 = nn.Linear(config.chaos_dim, config.chaos_dim)\n",
    "        self.fc2 = nn.Linear(config.chaos_dim, config.chaos_dim)\n",
    "        self.classifier = nn.Linear(config.chaos_dim, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        features = self.backbone(x)\n",
    "        x = torch.tanh(self.proj(features))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# --- 修改后的 Evaluate 函数 - 返回 total_spikes 而不是 average ---\n",
    "def evaluate(model, loader, config):\n",
    "    \"\"\"Evaluates the model, returns accuracy and total spikes.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_spikes_evaluated = 0.0\n",
    "    is_snn = isinstance(model, (CNNOscSNN, BasicCSNN, CNNLorenzSNN))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            if is_snn:\n",
    "                outputs, batch_spikes = model(images, return_spikes=True)\n",
    "                total_spikes_evaluated += batch_spikes.item()\n",
    "            else:\n",
    "                outputs = model(images) # **kwargs in BaseCNN handles extra args\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    # 修改: 返回 total_spikes 而不是平均值\n",
    "    return accuracy, total_spikes_evaluated\n",
    "\n",
    "\n",
    "# --- 修改后的 Train and Evaluate with History ---\n",
    "def train_and_evaluate_with_history(model, train_loader, test_loader, config):\n",
    "    \"\"\"Trains model with early stopping, returns best test acc, epoch history, and spikes at convergence.\"\"\"\n",
    "    model = model.to(device)\n",
    "    # --- OPTIONAL: Differential Learning Rate ---\n",
    "    # You might want different LRs for backbone and head\n",
    "    # Example:\n",
    "    head_params = [p for n, p in model.named_parameters() if not n.startswith('backbone.')]\n",
    "    backbone_params = [p for n, p in model.named_parameters() if n.startswith('backbone.')]\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': backbone_params, 'lr': config.lr * 0.1}, # Lower LR for backbone\n",
    "        {'params': head_params, 'lr': config.lr} # Normal LR for head\n",
    "    ], weight_decay=config.weight_decay)\n",
    "    # --- Using single LR for simplicity now ---\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_test_acc_epoch = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    patience = config.patience\n",
    "    # Ensure output directory exists before saving temp model\n",
    "    output_dir = f\"experiment_results_{config.dataset_name}_{config.backbone_name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True) # Ensure directory exists\n",
    "    best_model_path = os.path.join(output_dir, f\"temp_best_model_{time.time()}_{id(model)}.pth\") # Save inside output dir\n",
    "    \n",
    "    # 修改: 添加 spike 记录\n",
    "    history = []\n",
    "    spike_counts = []  # 记录每个epoch的spikes\n",
    "    best_epoch = 0  # 记录达到最佳性能的epoch\n",
    "\n",
    "    print(f\"--- Starting Training (Max Epochs: {config.epochs}, Patience: {patience}) ---\")\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        start_epoch_time = time.time()\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader): # Add index i for progress printing\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images, return_spikes=False) # No need for spikes during training loop\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                print(f\"WARNING: Loss is {loss.item()} at epoch {epoch+1}, batch {i}. Skipping backward pass.\")\n",
    "                continue # Skip batch if loss is invalid\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Optional: Print progress within epoch\n",
    "            # if (i + 1) % 100 == 0:\n",
    "            #     print(f'  Epoch [{epoch+1}/{config.epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "        end_epoch_time = time.time()\n",
    "        epoch_duration = end_epoch_time - start_epoch_time\n",
    "\n",
    "        # 修改: 在每个epoch结束后评估并记录spikes\n",
    "        test_acc, epoch_spikes = evaluate(model, test_loader, config)\n",
    "        history.append(test_acc)\n",
    "        spike_counts.append(epoch_spikes)  # 记录总spike数\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader) if len(train_loader) > 0 else 0\n",
    "        train_acc = 100. * train_correct / train_total if train_total > 0 else 0\n",
    "\n",
    "        # 修改: 打印spike信息\n",
    "        print(f\"Epoch [{epoch + 1}/{config.epochs}] Loss: {avg_loss:.4f} \"\n",
    "              f\"Train Acc: {train_acc:.2f}% Test Acc: {test_acc:.2f}% \"\n",
    "              f\"Total Spikes: {epoch_spikes:.0f} \"\n",
    "              f\"Epoch Time: {epoch_duration:.2f}s LR: {scheduler.get_last_lr()[0]:.1e}\")\n",
    "\n",
    "        # Early Stopping Logic\n",
    "        if test_acc > best_test_acc_epoch:\n",
    "            best_test_acc_epoch = test_acc\n",
    "            best_epoch = epoch  # 记录最佳epoch索引\n",
    "            epochs_no_improve = 0\n",
    "            try:\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f\"  -> New best test accuracy: {best_test_acc_epoch:.2f}%. Model saved.\")\n",
    "            except Exception as e:\n",
    "                print(f\"  -> Error saving model: {e}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  -> Test accuracy did not improve for {epochs_no_improve} epoch(s). Best: {best_test_acc_epoch:.2f}%\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"\\n--- Early stopping triggered after {epoch + 1} epochs. ---\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Post-Training: Load Best Model and Final Evaluation\n",
    "    print(\"\\n--- Training finished. Loading best model for final evaluation. ---\")\n",
    "    if os.path.exists(best_model_path):\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(best_model_path))\n",
    "            print(f\"Successfully loaded best model state (Accuracy: {best_test_acc_epoch:.2f}%)\")\n",
    "            os.remove(best_model_path)\n",
    "            # print(f\"Removed temporary model file: {best_model_path}\") # Optional: uncomment to confirm\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading best model state from {best_model_path}: {e}. Using model from last epoch.\")\n",
    "            best_test_acc_epoch = history[-1] if history else 0.0\n",
    "    else:\n",
    "        print(\"No best model was saved (or file missing). Using model from last epoch.\")\n",
    "        best_test_acc_epoch = history[-1] if history else 0.0\n",
    "\n",
    "    print(\"--- Running final evaluation on the best performing model state ---\")\n",
    "    final_test_acc, final_total_spikes = evaluate(model, test_loader, config)\n",
    "\n",
    "    # 修改: 获取收敛时的spike数\n",
    "    spikes_at_convergence = spike_counts[best_epoch] if spike_counts and best_epoch < len(spike_counts) else 0\n",
    "\n",
    "    print(f\"Final Evaluation - Test Accuracy: {final_test_acc:.2f}%\")\n",
    "    if isinstance(model, (CNNOscSNN, BasicCSNN, CNNLorenzSNN)):\n",
    "        print(f\"Final Evaluation - Total Spikes at Convergence (Epoch {best_epoch+1}): {spikes_at_convergence:.0f}\")\n",
    "        print(f\"Final Evaluation - Total Spikes in Final Evaluation: {final_total_spikes:.0f}\")\n",
    "\n",
    "    # 修改: 返回收敛时的spikes (不是平均值)\n",
    "    return best_test_acc_epoch, history, spikes_at_convergence, spike_counts\n",
    "\n",
    "# --- Tiny ImageNet Loading Function (未更改) ---\n",
    "def load_tiny_imagenet(config):\n",
    "    \"\"\"Loads the Tiny ImageNet dataset.\"\"\"\n",
    "    data_dir = config.data_root\n",
    "    num_workers = min(4, os.cpu_count()) if os.cpu_count() else 0\n",
    "    image_size = config.input_size # Should be 224 for pre-trained ResNet\n",
    "\n",
    "    # Standard ImageNet normalization\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # Data augmentation and normalization for training\n",
    "    # Adjust augmentation based on standard practices for ImageNet fine-tuning\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size), # Resize first\n",
    "        transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)), # Standard crop\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    # Just normalization for validation/testing\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size), # Ensure validation images are also resized\n",
    "        transforms.CenterCrop(image_size), # Use CenterCrop for validation\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    # --- Dataset Loading ---\n",
    "    # Tiny ImageNet structure: train/[wnid]/images/*.JPEG, val/images/*.JPEG, val/val_annotations.txt\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    val_dir = os.path.join(data_dir, 'val', 'images') # Validation images are flat\n",
    "\n",
    "    if not os.path.exists(train_dir) or not os.path.exists(val_dir):\n",
    "         raise FileNotFoundError(f\"Tiny ImageNet data not found at expected paths: {train_dir} and {val_dir}. \"\n",
    "                                f\"Please ensure Tiny ImageNet is downloaded and extracted to '{data_dir}' \"\n",
    "                                \"following the standard directory structure.\")\n",
    "\n",
    "    train_dataset = ImageFolder(train_dir, transform=train_transform)\n",
    "\n",
    "    # Validation dataset requires special handling due to annotations file\n",
    "    # Creating a custom Dataset class is cleaner\n",
    "    class TinyImageNetVal(Dataset):\n",
    "        def __init__(self, val_dir, annotations_file, class_to_idx, transform=None):\n",
    "            self.val_dir = val_dir\n",
    "            self.transform = transform\n",
    "            self.class_to_idx = class_to_idx\n",
    "            self.samples = []\n",
    "            try:\n",
    "                with open(annotations_file, 'r') as f:\n",
    "                    for line in f:\n",
    "                        parts = line.strip().split('\\t')\n",
    "                        if len(parts) >= 2:\n",
    "                            img_name, wnid = parts[0], parts[1]\n",
    "                            img_path = os.path.join(self.val_dir, img_name)\n",
    "                            if os.path.exists(img_path) and wnid in self.class_to_idx:\n",
    "                                self.samples.append((img_path, self.class_to_idx[wnid]))\n",
    "                            # else:\n",
    "                                # print(f\"Warning: Skipping invalid validation entry: {line.strip()}\")\n",
    "            except FileNotFoundError:\n",
    "                 raise FileNotFoundError(f\"Validation annotations file not found: {annotations_file}\")\n",
    "\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.samples)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img_path, target = self.samples[idx]\n",
    "            # Ensure images are loaded in RGB format\n",
    "            try:\n",
    "                with open(img_path, 'rb') as f:\n",
    "                    img = Image.open(f).convert('RGB')\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "                # Return a dummy image/target or handle appropriately\n",
    "                return torch.zeros(3, image_size, image_size), -1 # Indicate error\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, target\n",
    "\n",
    "    # Need class_to_idx mapping from the training set folders\n",
    "    class_to_idx = train_dataset.class_to_idx\n",
    "    val_annotations_file = os.path.join(data_dir, 'val', 'val_annotations.txt')\n",
    "    val_dataset = TinyImageNetVal(val_dir, val_annotations_file, class_to_idx, transform=val_transform)\n",
    "\n",
    "\n",
    "    print(f\"Tiny ImageNet - Found {len(train_dataset)} training images belonging to {len(train_dataset.classes)} classes.\")\n",
    "    print(f\"Tiny ImageNet - Found {len(val_dataset)} validation images.\")\n",
    "\n",
    "\n",
    "    # Data Loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=config.batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    # Use validation set as the test set for Tiny ImageNet evaluation\n",
    "    test_loader = DataLoader(\n",
    "        val_dataset, batch_size=config.batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "# --- 修改 Experiment Logger Class ---\n",
    "class ExperimentLogger:\n",
    "    def __init__(self, output_dir=\"experiment_results_tinyimagenet_resnet18\"): # Changed dir name\n",
    "        self.results = {}\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        # 修改: 更新CSV标题，将Average Spikes改为Spikes at Convergence\n",
    "        self.csv_headers = [\n",
    "            \"Config Name\", # Renamed from CNN Config\n",
    "            \"Model\",\n",
    "            \"Delta/System\",\n",
    "            \"Best Test Accuracy (%)\",\n",
    "            \"Spikes at Convergence\", # 修改: 更改列名\n",
    "            \"Training Time (s)\",\n",
    "            \"Epochs Trained\",\n",
    "            \"Convergence Epoch\" # 添加收敛epoch的列\n",
    "        ]\n",
    "\n",
    "    def log_config(self, config_name, config):\n",
    "        config_dict = {}\n",
    "        config_dict['patience'] = config.patience\n",
    "        for key, value in vars(config).items():\n",
    "             if isinstance(value, (int, float, str, bool, list, tuple, dict, type(None))):\n",
    "                 config_dict[key] = value\n",
    "             # ... (rest of serialization logic from previous version)\n",
    "        self.results[config_name] = {\n",
    "            \"config\": config_dict,\n",
    "            \"models\": {}\n",
    "        }\n",
    "\n",
    "    # 修改: 更新log_model_result参数和逻辑\n",
    "    def log_model_result(self, config_name, model_name, accuracy, training_time, epochs_history, spikes_at_convergence, spike_counts, best_epoch):\n",
    "        if config_name not in self.results:\n",
    "            self.results[config_name] = {\"config\": {}, \"models\": {}}\n",
    "            print(f\"Warning: Config '{config_name}' not pre-logged. Creating entry.\")\n",
    "        epochs_trained = len(epochs_history)\n",
    "        self.results[config_name][\"models\"][model_name] = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"training_time\": training_time,\n",
    "            \"epochs_history\": epochs_history, # Storing history can make JSON large\n",
    "            \"spikes_at_convergence\": spikes_at_convergence, # 修改: 改为收敛时的spikes\n",
    "            \"epochs_trained\": epochs_trained,\n",
    "            \"spike_counts\": spike_counts, # 添加: 存储每个epoch的spike数据\n",
    "            \"convergence_epoch\": best_epoch + 1 # 添加: 转换为1-indexed的epoch号\n",
    "        }\n",
    "        print(f\"Logged for {config_name} - {model_name}: Best Acc={accuracy:.2f}, Spikes at Convergence={spikes_at_convergence:.0f}, \"\n",
    "              f\"Time={training_time:.2f}s, Epochs={epochs_trained}, Convergence Epoch={best_epoch+1}\")\n",
    "\n",
    "    def save_results(self):\n",
    "        filepath = os.path.join(self.output_dir, \"results.json\")\n",
    "        try:\n",
    "            # Save only essential results to JSON to avoid large files due to history\n",
    "            results_to_save = {}\n",
    "            for cfg_name, cfg_data in self.results.items():\n",
    "                results_to_save[cfg_name] = {\"config\": cfg_data[\"config\"], \"models\": {}}\n",
    "                for mdl_name, mdl_data in cfg_data[\"models\"].items():\n",
    "                    results_to_save[cfg_name][\"models\"][mdl_name] = {\n",
    "                        k: v for k, v in mdl_data.items() if k not in ['epochs_history', 'spike_counts']\n",
    "                    }\n",
    "            with open(filepath, \"w\") as f:\n",
    "                json.dump(results_to_save, f, indent=4, default=lambda o: '<not serializable>')\n",
    "            print(f\"Results saved to {filepath}\")\n",
    "            \n",
    "            # 添加: 保存spike数据到CSV文件\n",
    "            for cfg_name, cfg_data in self.results.items():\n",
    "                for mdl_name, mdl_data in cfg_data[\"models\"].items():\n",
    "                    if 'spike_counts' in mdl_data and mdl_data['spike_counts']:\n",
    "                        spike_df = pd.DataFrame({\n",
    "                            'Epoch': range(1, len(mdl_data['spike_counts'])+1),\n",
    "                            'Total Spikes': mdl_data['spike_counts']\n",
    "                        })\n",
    "                        spike_file = os.path.join(self.output_dir, f\"{cfg_name}_{mdl_name}_spikes.csv\")\n",
    "                        spike_df.to_csv(spike_file, index=False)\n",
    "                        print(f\"Spike data saved to {spike_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving JSON results: {e}\")\n",
    "\n",
    "\n",
    "    def generate_summary_table(self):\n",
    "        rows = []\n",
    "        for config_name, data in self.results.items():\n",
    "            for model_name, model_data in data[\"models\"].items():\n",
    "                delta_str = \"N/A\"\n",
    "                # Simplified model type identification for summary\n",
    "                if \"Osc-SNN Delta=\" in model_name:\n",
    "                    delta_str = f\"Osc(Δ={model_name.split('=')[-1].split(')')[0]})\"\n",
    "                elif \"Lorenz-SNN\" in model_name:\n",
    "                    delta_str = \"Lorenz\"\n",
    "                elif \"CNN-SNN\" in model_name and \"Osc\" not in model_name and \"Lorenz\" not in model_name:\n",
    "                     delta_str = \"Direct SNN\"\n",
    "                elif \"CNN-ANN\" in model_name:\n",
    "                     delta_str = \"ANN\"\n",
    "\n",
    "                spikes = model_data.get(\"spikes_at_convergence\", 0.0)  # 修改: 使用收敛时的spikes\n",
    "                epochs_trained = model_data.get(\"epochs_trained\", \"N/A\")\n",
    "                convergence_epoch = model_data.get(\"convergence_epoch\", \"N/A\")  # 添加: 获取收敛epoch\n",
    "\n",
    "                row = {\n",
    "                    self.csv_headers[0]: config_name, # Use \"Config Name\"\n",
    "                    self.csv_headers[1]: model_name,\n",
    "                    self.csv_headers[2]: delta_str,\n",
    "                    self.csv_headers[3]: model_data[\"accuracy\"],\n",
    "                    self.csv_headers[4]: spikes,  # 修改: 使用收敛时的spikes\n",
    "                    self.csv_headers[5]: model_data[\"training_time\"],\n",
    "                    self.csv_headers[6]: epochs_trained,\n",
    "                    self.csv_headers[7]: convergence_epoch  # 添加: 收敛epoch\n",
    "                }\n",
    "                rows.append(row)\n",
    "        if not rows: return pd.DataFrame(columns=self.csv_headers)\n",
    "        df = pd.DataFrame(rows)\n",
    "        df = df[self.csv_headers] # Ensure column order\n",
    "        try:\n",
    "            df[self.csv_headers[3]] = pd.to_numeric(df[self.csv_headers[3]], errors='coerce').map('{:.2f}'.format)\n",
    "            df[self.csv_headers[4]] = pd.to_numeric(df[self.csv_headers[4]], errors='coerce').map('{:.0f}'.format)  # 修改: 整数格式\n",
    "            df[self.csv_headers[5]] = pd.to_numeric(df[self.csv_headers[5]], errors='coerce').map('{:.2f}'.format)\n",
    "        except Exception as e: print(f\"Error formatting summary table columns: {e}\")\n",
    "        filepath = os.path.join(self.output_dir, \"summary.csv\")\n",
    "        try: df.to_csv(filepath, index=False); print(f\"Summary table saved to {filepath}\")\n",
    "        except Exception as e: print(f\"Error saving summary CSV: {e}\")\n",
    "        return df\n",
    "\n",
    "    # --- Plotting (Requires Matplotlib) ---\n",
    "    # Consider simplifying or removing plotting if matplotlib is not available/needed now\n",
    "    # def plot_results(self):\n",
    "    #     # ... (Plotting code from previous version - needs matplotlib)\n",
    "    #     # If keeping plots, update logic to handle single config name and model types\n",
    "    #     pass\n",
    "\n",
    "# --- 修改 Main Experiment Function ---\n",
    "def run_experiment():\n",
    "    print(f\"使用设备: {device}\")\n",
    "    config = Config() # Use the updated config\n",
    "    config_name = f\"{config.dataset_name}_{config.backbone_name}\" # Single config name\n",
    "    logger = ExperimentLogger(output_dir=f\"experiment_results_{config_name}\")\n",
    "\n",
    "    # Define the specific oscillator deltas for the two modes\n",
    "    # Use values inspired by Table D1, e.g., one expansive, one dissipative\n",
    "    osc_delta_mode_b = -1.5 # High performance potential (Expansive)\n",
    "    osc_delta_mode_a = 10.0 # High efficiency (Dissipative)\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"开始实验配置: {config_name}\")\n",
    "    print(f\"Dataset: {config.dataset_name} (Root: {config.data_root}, Classes: {config.num_classes}, Input Size: {config.input_size})\")\n",
    "    print(f\"Backbone: {config.backbone_name}\")\n",
    "    print(f\"Max Epochs: {config.epochs}, Patience: {config.patience}, LR: {config.lr}\")\n",
    "    print(f\"Osc Params: alpha={config.osc_alpha}, beta={config.osc_beta}, gamma={config.osc_gamma}, omega={config.osc_omega}, dt={config.osc_dt}\")\n",
    "    print(f\"Lorenz Params: sigma={config.lorenz_sigma:.2f}, rho={config.lorenz_rho:.2f}, beta={config.lorenz_beta:.2f}, dt={config.lorenz_dt}\")\n",
    "    print(f\"SNN Params: steps={config.num_steps}, decay_beta={config.beta:.2f}, chaos_dim={config.chaos_dim}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    logger.log_config(config_name, config)\n",
    "\n",
    "    try:\n",
    "        # Load Tiny ImageNet data\n",
    "        train_loader, test_loader = load_tiny_imagenet(config)\n",
    "    except Exception as e:\n",
    "        print(f\"无法加载数据集 {config_name}. 终止实验. 错误: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None # Exit if data loading fails\n",
    "\n",
    "    # --- Define Models to Run ---\n",
    "    # Ensure pretrained_backbone=True is passed correctly\n",
    "    models_to_run = {\n",
    "        \"Baseline (CNN-ANN)\": BaseCNN(config, pretrained_backbone=True),\n",
    "        \"Baseline (CNN-SNN)\": BasicCSNN(config, pretrained_backbone=True),\n",
    "        \"Proposed (CNN-Lorenz-SNN)\": CNNLorenzSNN(config, pretrained_backbone=True)\n",
    "    }\n",
    "    # Add Oscillator SNNs with specific deltas\n",
    "    osc_config_b = copy.deepcopy(config); osc_config_b.osc_delta = osc_delta_mode_b\n",
    "    models_to_run[f\"Proposed (CNN-Osc-SNN Delta={osc_delta_mode_b})\"] = CNNOscSNN(osc_config_b, pretrained_backbone=True)\n",
    "\n",
    "    osc_config_a = copy.deepcopy(config); osc_config_a.osc_delta = osc_delta_mode_a\n",
    "    models_to_run[f\"Proposed (CNN-Osc-SNN Delta={osc_delta_mode_a})\"] = CNNOscSNN(osc_config_a, pretrained_backbone=True)\n",
    "\n",
    "\n",
    "    # --- Train and Evaluate Models ---\n",
    "    for model_name, model_instance in models_to_run.items():\n",
    "        print(f\"\\n--- Training {model_name} for {config_name} ---\")\n",
    "        start_time = time.time()\n",
    "        # Use a fresh copy for each training run (already done by creating new instances above)\n",
    "        current_model = model_instance\n",
    "        current_config = config # Default config for non-oscillator models\n",
    "        if \"Osc-SNN Delta=\" in model_name:\n",
    "             delta_val = float(model_name.split('=')[-1].split(')')[0])\n",
    "             if delta_val == osc_delta_mode_a: current_config = osc_config_a\n",
    "             elif delta_val == osc_delta_mode_b: current_config = osc_config_b\n",
    "             else: print(f\"Warning: Could not match delta for {model_name}\")\n",
    "\n",
    "\n",
    "        try:\n",
    "            # 修改: 添加对spike_counts和best_epoch的接收\n",
    "            best_acc, epochs_history, spikes_at_convergence, spike_counts = train_and_evaluate_with_history(\n",
    "                current_model, train_loader, test_loader, current_config # Pass correct config\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "            \n",
    "            # 计算best_epoch (0-indexed)\n",
    "            best_epoch = epochs_history.index(best_acc) if best_acc in epochs_history else 0\n",
    "            \n",
    "            print(f\"--- {model_name} finished. Best Acc: {best_acc:.2f}%, \"\n",
    "                 f\"Spikes at Convergence (Epoch {best_epoch+1}): {spikes_at_convergence:.0f}, \"\n",
    "                 f\"Time: {training_time:.2f}s, Epochs Trained: {len(epochs_history)} ---\")\n",
    "                 \n",
    "            # 修改: 更新logger.log_model_result调用\n",
    "            logger.log_model_result(\n",
    "                config_name, model_name, best_acc, training_time, \n",
    "                epochs_history, spikes_at_convergence, spike_counts, best_epoch\n",
    "            )\n",
    "        except Exception as e:\n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "            print(f\"!!! ERROR during training/evaluation for {model_name} on {config_name}: {e}\")\n",
    "            # 修改: 更新错误情况下的logger.log_model_result调用\n",
    "            logger.log_model_result(config_name, model_name, 0.0, training_time, [], 0.0, [], 0)\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            # Decide whether to continue with other models upon error\n",
    "            # continue\n",
    "\n",
    "\n",
    "    # --- Finalize and Save Results ---\n",
    "    print(\"\\n--- All models processed for this configuration ---\")\n",
    "    logger.save_results()\n",
    "    summary_df = logger.generate_summary_table()\n",
    "    # try:\n",
    "    #     logger.plot_results() # Optional plotting\n",
    "    # except Exception as e:\n",
    "    #     print(f\"An error occurred during final plotting: {e}\")\n",
    "    #     import traceback\n",
    "    #     traceback.print_exc()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"实验完成! 结果保存在 '{logger.output_dir}' 目录中\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    if not summary_df.empty:\n",
    "        print(\"结果汇总:\")\n",
    "        # Configure pandas for wider output\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', 2000)\n",
    "        pd.set_option('display.max_colwidth', None) # Show full column width\n",
    "        print(summary_df.to_string(index=False)) # Use to_string for better control\n",
    "        pd.reset_option('all') # Reset pandas display options\n",
    "    else:\n",
    "        print(\"结果汇总为空.\")\n",
    "\n",
    "    return logger\n",
    "\n",
    "# --- Run Experiment ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Optional: Set seeds for reproducibility\n",
    "    # seed = 42\n",
    "    # torch.manual_seed(seed)\n",
    "    # np.random.seed(seed)\n",
    "    # if torch.cuda.is_available():\n",
    "    #     torch.cuda.manual_seed_all(seed)\n",
    "    # # Note: Full determinism can impact performance and might not be guaranteed on GPU\n",
    "    # # torch.backends.cudnn.deterministic = True\n",
    "    # # torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    logger = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da90712e-b958-4594-98f9-185fc1fa1647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "\n",
      "============================================================\n",
      "开始实验配置: TinyImageNet_ResNet-18_pretrained\n",
      "Dataset: TinyImageNet (Root: ./tiny-imagenet-200, Classes: 200, Input Size: 224)\n",
      "Backbone: ResNet-18_pretrained\n",
      "Max Epochs: 200, Patience: 15, LR: 0.0001\n",
      "Osc Params: alpha=2.0, beta=0.1, gamma=0.1, omega=1.0, dt=0.05\n",
      "Lorenz Params: sigma=10.00, rho=28.00, beta=2.67, dt=0.05\n",
      "SNN Params: steps=5, decay_beta=0.95, chaos_dim=512\n",
      "============================================================\n",
      "Tiny ImageNet - Found 100000 training images belonging to 200 classes.\n",
      "Tiny ImageNet - Found 10000 validation images.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "Loaded PRETRAINED ResNet-18 weights.\n",
      "\n",
      "--- Training Baseline (CNN-ANN) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 2.9028 Train Acc: 32.86% Test Acc: 52.59% Total Spikes: 0 Epoch Time: 51.71s LR: 1.0e-05\n",
      "  -> New best test accuracy: 52.59%. Model saved.\n",
      "Epoch [2/200] Loss: 1.6568 Train Acc: 57.48% Test Acc: 62.62% Total Spikes: 0 Epoch Time: 51.75s LR: 1.0e-05\n",
      "  -> New best test accuracy: 62.62%. Model saved.\n",
      "Epoch [3/200] Loss: 1.3791 Train Acc: 63.99% Test Acc: 66.62% Total Spikes: 0 Epoch Time: 51.78s LR: 1.0e-05\n",
      "  -> New best test accuracy: 66.62%. Model saved.\n",
      "Epoch [4/200] Loss: 1.2092 Train Acc: 68.01% Test Acc: 67.60% Total Spikes: 0 Epoch Time: 51.84s LR: 1.0e-05\n",
      "  -> New best test accuracy: 67.60%. Model saved.\n",
      "Epoch [5/200] Loss: 1.0986 Train Acc: 70.57% Test Acc: 69.06% Total Spikes: 0 Epoch Time: 51.86s LR: 1.0e-05\n",
      "  -> New best test accuracy: 69.06%. Model saved.\n",
      "Epoch [6/200] Loss: 1.0066 Train Acc: 72.80% Test Acc: 69.64% Total Spikes: 0 Epoch Time: 51.88s LR: 1.0e-05\n",
      "  -> New best test accuracy: 69.64%. Model saved.\n",
      "Epoch [7/200] Loss: 0.9289 Train Acc: 74.75% Test Acc: 70.34% Total Spikes: 0 Epoch Time: 51.58s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.34%. Model saved.\n",
      "Epoch [8/200] Loss: 0.8621 Train Acc: 76.32% Test Acc: 70.77% Total Spikes: 0 Epoch Time: 51.92s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.77%. Model saved.\n",
      "Epoch [9/200] Loss: 0.8046 Train Acc: 77.75% Test Acc: 70.84% Total Spikes: 0 Epoch Time: 51.87s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.84%. Model saved.\n",
      "Epoch [10/200] Loss: 0.7529 Train Acc: 78.80% Test Acc: 71.70% Total Spikes: 0 Epoch Time: 51.84s LR: 1.0e-05\n",
      "  -> New best test accuracy: 71.70%. Model saved.\n",
      "Epoch [11/200] Loss: 0.6984 Train Acc: 80.17% Test Acc: 71.27% Total Spikes: 0 Epoch Time: 51.76s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 71.70%\n",
      "Epoch [12/200] Loss: 0.6531 Train Acc: 81.44% Test Acc: 71.09% Total Spikes: 0 Epoch Time: 51.84s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 71.70%\n",
      "Epoch [13/200] Loss: 0.6094 Train Acc: 82.59% Test Acc: 71.46% Total Spikes: 0 Epoch Time: 52.42s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 71.70%\n",
      "Epoch [14/200] Loss: 0.5696 Train Acc: 83.59% Test Acc: 71.74% Total Spikes: 0 Epoch Time: 52.22s LR: 9.9e-06\n",
      "  -> New best test accuracy: 71.74%. Model saved.\n",
      "Epoch [15/200] Loss: 0.5334 Train Acc: 84.44% Test Acc: 71.24% Total Spikes: 0 Epoch Time: 52.09s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 71.74%\n",
      "Epoch [16/200] Loss: 0.4972 Train Acc: 85.36% Test Acc: 71.52% Total Spikes: 0 Epoch Time: 53.18s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 71.74%\n",
      "Epoch [17/200] Loss: 0.4681 Train Acc: 86.12% Test Acc: 71.54% Total Spikes: 0 Epoch Time: 52.80s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 71.74%\n",
      "Epoch [18/200] Loss: 0.4314 Train Acc: 87.11% Test Acc: 70.82% Total Spikes: 0 Epoch Time: 52.60s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 71.74%\n",
      "Epoch [19/200] Loss: 0.4055 Train Acc: 87.93% Test Acc: 71.72% Total Spikes: 0 Epoch Time: 52.82s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 71.74%\n",
      "Epoch [20/200] Loss: 0.3785 Train Acc: 88.59% Test Acc: 70.97% Total Spikes: 0 Epoch Time: 52.50s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 71.74%\n",
      "Epoch [21/200] Loss: 0.3572 Train Acc: 89.22% Test Acc: 71.39% Total Spikes: 0 Epoch Time: 52.67s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 71.74%\n",
      "Epoch [22/200] Loss: 0.3344 Train Acc: 89.80% Test Acc: 70.65% Total Spikes: 0 Epoch Time: 52.61s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 71.74%\n",
      "Epoch [23/200] Loss: 0.3116 Train Acc: 90.48% Test Acc: 71.29% Total Spikes: 0 Epoch Time: 52.23s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 71.74%\n",
      "Epoch [24/200] Loss: 0.2895 Train Acc: 91.02% Test Acc: 70.95% Total Spikes: 0 Epoch Time: 52.50s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 71.74%\n",
      "Epoch [25/200] Loss: 0.2741 Train Acc: 91.54% Test Acc: 70.63% Total Spikes: 0 Epoch Time: 52.57s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 71.74%\n",
      "Epoch [26/200] Loss: 0.2566 Train Acc: 92.03% Test Acc: 71.10% Total Spikes: 0 Epoch Time: 52.12s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 71.74%\n",
      "Epoch [27/200] Loss: 0.2435 Train Acc: 92.47% Test Acc: 70.73% Total Spikes: 0 Epoch Time: 52.06s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 71.74%\n",
      "Epoch [28/200] Loss: 0.2327 Train Acc: 92.89% Test Acc: 70.95% Total Spikes: 0 Epoch Time: 52.88s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 71.74%\n",
      "Epoch [29/200] Loss: 0.2176 Train Acc: 93.31% Test Acc: 70.86% Total Spikes: 0 Epoch Time: 52.30s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 71.74%\n",
      "\n",
      "--- Early stopping triggered after 29 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 71.74%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 71.74%\n",
      "--- Baseline (CNN-ANN) finished. Best Acc: 71.74%, Spikes at Convergence (Epoch 14): 0, Time: 1632.26s, Epochs Trained: 29 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Baseline (CNN-ANN): Best Acc=71.74, Spikes at Convergence=0, Time=1632.26s, Epochs=29, Convergence Epoch=14\n",
      "\n",
      "--- Training Baseline (CNN-SNN) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 3.8636 Train Acc: 32.55% Test Acc: 52.11% Total Spikes: 17297474 Epoch Time: 54.03s LR: 1.0e-05\n",
      "  -> New best test accuracy: 52.11%. Model saved.\n",
      "Epoch [2/200] Loss: 2.2190 Train Acc: 57.18% Test Acc: 62.80% Total Spikes: 18035116 Epoch Time: 53.75s LR: 1.0e-05\n",
      "  -> New best test accuracy: 62.80%. Model saved.\n",
      "Epoch [3/200] Loss: 1.6466 Train Acc: 65.06% Test Acc: 67.01% Total Spikes: 18074976 Epoch Time: 53.98s LR: 1.0e-05\n",
      "  -> New best test accuracy: 67.01%. Model saved.\n",
      "Epoch [4/200] Loss: 1.3763 Train Acc: 69.18% Test Acc: 69.37% Total Spikes: 18209906 Epoch Time: 53.80s LR: 1.0e-05\n",
      "  -> New best test accuracy: 69.37%. Model saved.\n",
      "Epoch [5/200] Loss: 1.2141 Train Acc: 71.97% Test Acc: 70.88% Total Spikes: 18139615 Epoch Time: 53.95s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.88%. Model saved.\n",
      "Epoch [6/200] Loss: 1.1033 Train Acc: 74.03% Test Acc: 71.88% Total Spikes: 18273587 Epoch Time: 54.20s LR: 1.0e-05\n",
      "  -> New best test accuracy: 71.88%. Model saved.\n",
      "Epoch [7/200] Loss: 1.0186 Train Acc: 75.81% Test Acc: 72.31% Total Spikes: 18297780 Epoch Time: 53.89s LR: 1.0e-05\n",
      "  -> New best test accuracy: 72.31%. Model saved.\n",
      "Epoch [8/200] Loss: 0.9466 Train Acc: 77.32% Test Acc: 72.87% Total Spikes: 18197162 Epoch Time: 54.00s LR: 1.0e-05\n",
      "  -> New best test accuracy: 72.87%. Model saved.\n",
      "Epoch [9/200] Loss: 0.8878 Train Acc: 78.67% Test Acc: 72.76% Total Spikes: 18162189 Epoch Time: 54.09s LR: 1.0e-05\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 72.87%\n",
      "Epoch [10/200] Loss: 0.8410 Train Acc: 79.73% Test Acc: 73.58% Total Spikes: 18270335 Epoch Time: 54.00s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.58%. Model saved.\n",
      "Epoch [11/200] Loss: 0.7955 Train Acc: 80.91% Test Acc: 73.78% Total Spikes: 18233757 Epoch Time: 54.08s LR: 9.9e-06\n",
      "  -> New best test accuracy: 73.78%. Model saved.\n",
      "Epoch [12/200] Loss: 0.7538 Train Acc: 82.05% Test Acc: 73.81% Total Spikes: 18247830 Epoch Time: 53.98s LR: 9.9e-06\n",
      "  -> New best test accuracy: 73.81%. Model saved.\n",
      "Epoch [13/200] Loss: 0.7151 Train Acc: 82.97% Test Acc: 74.13% Total Spikes: 18129505 Epoch Time: 54.06s LR: 9.9e-06\n",
      "  -> New best test accuracy: 74.13%. Model saved.\n",
      "Epoch [14/200] Loss: 0.6810 Train Acc: 83.85% Test Acc: 74.05% Total Spikes: 18178646 Epoch Time: 54.21s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 74.13%\n",
      "Epoch [15/200] Loss: 0.6478 Train Acc: 84.71% Test Acc: 73.81% Total Spikes: 18081339 Epoch Time: 53.94s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 74.13%\n",
      "Epoch [16/200] Loss: 0.6147 Train Acc: 85.74% Test Acc: 74.27% Total Spikes: 18056715 Epoch Time: 53.78s LR: 9.9e-06\n",
      "  -> New best test accuracy: 74.27%. Model saved.\n",
      "Epoch [17/200] Loss: 0.5879 Train Acc: 86.39% Test Acc: 74.08% Total Spikes: 17964182 Epoch Time: 53.82s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 74.27%\n",
      "Epoch [18/200] Loss: 0.5587 Train Acc: 87.24% Test Acc: 74.38% Total Spikes: 18017292 Epoch Time: 53.82s LR: 9.8e-06\n",
      "  -> New best test accuracy: 74.38%. Model saved.\n",
      "Epoch [19/200] Loss: 0.5359 Train Acc: 87.97% Test Acc: 74.11% Total Spikes: 18059425 Epoch Time: 53.78s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 74.38%\n",
      "Epoch [20/200] Loss: 0.5119 Train Acc: 88.49% Test Acc: 74.40% Total Spikes: 18024711 Epoch Time: 53.97s LR: 9.8e-06\n",
      "  -> New best test accuracy: 74.40%. Model saved.\n",
      "Epoch [21/200] Loss: 0.4896 Train Acc: 89.31% Test Acc: 74.09% Total Spikes: 17913745 Epoch Time: 53.86s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 74.40%\n",
      "Epoch [22/200] Loss: 0.4676 Train Acc: 89.82% Test Acc: 73.97% Total Spikes: 18031020 Epoch Time: 53.68s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 74.40%\n",
      "Epoch [23/200] Loss: 0.4454 Train Acc: 90.45% Test Acc: 73.90% Total Spikes: 17948132 Epoch Time: 53.99s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 74.40%\n",
      "Epoch [24/200] Loss: 0.4261 Train Acc: 90.99% Test Acc: 74.03% Total Spikes: 17878422 Epoch Time: 54.12s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 74.40%\n",
      "Epoch [25/200] Loss: 0.4087 Train Acc: 91.59% Test Acc: 73.76% Total Spikes: 17905943 Epoch Time: 54.20s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 74.40%\n",
      "Epoch [26/200] Loss: 0.3932 Train Acc: 92.08% Test Acc: 74.01% Total Spikes: 17840893 Epoch Time: 53.74s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 74.40%\n",
      "Epoch [27/200] Loss: 0.3769 Train Acc: 92.46% Test Acc: 73.90% Total Spikes: 17851428 Epoch Time: 54.61s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 74.40%\n",
      "Epoch [28/200] Loss: 0.3586 Train Acc: 93.08% Test Acc: 73.66% Total Spikes: 17785952 Epoch Time: 53.69s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 74.40%\n",
      "Epoch [29/200] Loss: 0.3434 Train Acc: 93.39% Test Acc: 73.69% Total Spikes: 17815966 Epoch Time: 53.82s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 74.40%\n",
      "Epoch [30/200] Loss: 0.3320 Train Acc: 93.79% Test Acc: 73.56% Total Spikes: 17760061 Epoch Time: 54.04s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 74.40%\n",
      "Epoch [31/200] Loss: 0.3158 Train Acc: 94.19% Test Acc: 73.38% Total Spikes: 17713852 Epoch Time: 53.81s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 74.40%\n",
      "Epoch [32/200] Loss: 0.3043 Train Acc: 94.59% Test Acc: 73.61% Total Spikes: 17677753 Epoch Time: 53.92s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 74.40%\n",
      "Epoch [33/200] Loss: 0.2917 Train Acc: 94.88% Test Acc: 73.48% Total Spikes: 17708271 Epoch Time: 53.77s LR: 9.4e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 74.40%\n",
      "Epoch [34/200] Loss: 0.2821 Train Acc: 95.22% Test Acc: 73.72% Total Spikes: 17719884 Epoch Time: 53.98s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 74.40%\n",
      "Epoch [35/200] Loss: 0.2689 Train Acc: 95.64% Test Acc: 73.36% Total Spikes: 17705782 Epoch Time: 53.75s LR: 9.3e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 74.40%\n",
      "\n",
      "--- Early stopping triggered after 35 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 74.40%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 74.40%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 20): 18024711\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 18024711\n",
      "--- Baseline (CNN-SNN) finished. Best Acc: 74.40%, Spikes at Convergence (Epoch 20): 18024711, Time: 2031.27s, Epochs Trained: 35 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Baseline (CNN-SNN): Best Acc=74.40, Spikes at Convergence=18024711, Time=2031.27s, Epochs=35, Convergence Epoch=20\n",
      "\n",
      "--- Training Proposed (CNN-Lorenz-SNN) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 2.3037 Train Acc: 48.82% Test Acc: 66.05% Total Spikes: 26996655 Epoch Time: 55.76s LR: 1.0e-05\n",
      "  -> New best test accuracy: 66.05%. Model saved.\n",
      "Epoch [2/200] Loss: 1.2538 Train Acc: 67.50% Test Acc: 70.93% Total Spikes: 27669092 Epoch Time: 55.72s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.93%. Model saved.\n",
      "Epoch [3/200] Loss: 1.0552 Train Acc: 72.02% Test Acc: 71.73% Total Spikes: 27557248 Epoch Time: 56.11s LR: 1.0e-05\n",
      "  -> New best test accuracy: 71.73%. Model saved.\n",
      "Epoch [4/200] Loss: 0.9366 Train Acc: 74.79% Test Acc: 72.75% Total Spikes: 27809278 Epoch Time: 55.98s LR: 1.0e-05\n",
      "  -> New best test accuracy: 72.75%. Model saved.\n",
      "Epoch [5/200] Loss: 0.8465 Train Acc: 76.96% Test Acc: 72.98% Total Spikes: 28583227 Epoch Time: 56.07s LR: 1.0e-05\n",
      "  -> New best test accuracy: 72.98%. Model saved.\n",
      "Epoch [6/200] Loss: 0.7699 Train Acc: 78.77% Test Acc: 73.28% Total Spikes: 28466603 Epoch Time: 55.98s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.28%. Model saved.\n",
      "Epoch [7/200] Loss: 0.7075 Train Acc: 80.32% Test Acc: 73.54% Total Spikes: 28853188 Epoch Time: 55.59s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.54%. Model saved.\n",
      "Epoch [8/200] Loss: 0.6456 Train Acc: 81.85% Test Acc: 73.66% Total Spikes: 29202411 Epoch Time: 56.27s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.66%. Model saved.\n",
      "Epoch [9/200] Loss: 0.5970 Train Acc: 83.12% Test Acc: 73.84% Total Spikes: 29149641 Epoch Time: 55.68s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.84%. Model saved.\n",
      "Epoch [10/200] Loss: 0.5479 Train Acc: 84.41% Test Acc: 73.89% Total Spikes: 29567112 Epoch Time: 55.97s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.89%. Model saved.\n",
      "Epoch [11/200] Loss: 0.5082 Train Acc: 85.44% Test Acc: 74.17% Total Spikes: 29295466 Epoch Time: 56.23s LR: 9.9e-06\n",
      "  -> New best test accuracy: 74.17%. Model saved.\n",
      "Epoch [12/200] Loss: 0.4661 Train Acc: 86.61% Test Acc: 74.21% Total Spikes: 29690092 Epoch Time: 55.90s LR: 9.9e-06\n",
      "  -> New best test accuracy: 74.21%. Model saved.\n",
      "Epoch [13/200] Loss: 0.4293 Train Acc: 87.52% Test Acc: 73.79% Total Spikes: 29688643 Epoch Time: 56.11s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 74.21%\n",
      "Epoch [14/200] Loss: 0.3990 Train Acc: 88.37% Test Acc: 73.70% Total Spikes: 29863377 Epoch Time: 56.38s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 74.21%\n",
      "Epoch [15/200] Loss: 0.3675 Train Acc: 89.30% Test Acc: 73.81% Total Spikes: 29741767 Epoch Time: 55.92s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 74.21%\n",
      "Epoch [16/200] Loss: 0.3371 Train Acc: 90.11% Test Acc: 73.62% Total Spikes: 30138429 Epoch Time: 55.79s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 74.21%\n",
      "Epoch [17/200] Loss: 0.3100 Train Acc: 90.96% Test Acc: 74.14% Total Spikes: 30310126 Epoch Time: 55.78s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 74.21%\n",
      "Epoch [18/200] Loss: 0.2863 Train Acc: 91.62% Test Acc: 74.06% Total Spikes: 30554020 Epoch Time: 55.94s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 74.21%\n",
      "Epoch [19/200] Loss: 0.2684 Train Acc: 92.19% Test Acc: 73.43% Total Spikes: 30442743 Epoch Time: 55.82s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 74.21%\n",
      "Epoch [20/200] Loss: 0.2450 Train Acc: 92.93% Test Acc: 73.73% Total Spikes: 30529624 Epoch Time: 55.82s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 74.21%\n",
      "Epoch [21/200] Loss: 0.2287 Train Acc: 93.36% Test Acc: 73.41% Total Spikes: 30717246 Epoch Time: 55.53s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 74.21%\n",
      "Epoch [22/200] Loss: 0.2114 Train Acc: 93.98% Test Acc: 73.42% Total Spikes: 30806871 Epoch Time: 55.53s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 74.21%\n",
      "Epoch [23/200] Loss: 0.2002 Train Acc: 94.23% Test Acc: 73.66% Total Spikes: 30925697 Epoch Time: 55.98s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 74.21%\n",
      "Epoch [24/200] Loss: 0.1877 Train Acc: 94.56% Test Acc: 73.52% Total Spikes: 30729107 Epoch Time: 56.10s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 74.21%\n",
      "Epoch [25/200] Loss: 0.1744 Train Acc: 95.01% Test Acc: 73.71% Total Spikes: 31199527 Epoch Time: 56.16s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 74.21%\n",
      "Epoch [26/200] Loss: 0.1630 Train Acc: 95.40% Test Acc: 73.38% Total Spikes: 30986903 Epoch Time: 55.97s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 74.21%\n",
      "Epoch [27/200] Loss: 0.1525 Train Acc: 95.71% Test Acc: 73.56% Total Spikes: 31150496 Epoch Time: 55.92s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 74.21%\n",
      "\n",
      "--- Early stopping triggered after 27 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 74.21%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 74.21%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 12): 29690092\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 29690092\n",
      "--- Proposed (CNN-Lorenz-SNN) finished. Best Acc: 74.21%, Spikes at Convergence (Epoch 12): 29690092, Time: 1621.83s, Epochs Trained: 27 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Proposed (CNN-Lorenz-SNN): Best Acc=74.21, Spikes at Convergence=29690092, Time=1621.83s, Epochs=27, Convergence Epoch=12\n",
      "\n",
      "--- Training Proposed (CNN-Osc-SNN Delta=-1.5) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 2.4084 Train Acc: 48.32% Test Acc: 65.24% Total Spikes: 17315641 Epoch Time: 56.23s LR: 1.0e-05\n",
      "  -> New best test accuracy: 65.24%. Model saved.\n",
      "Epoch [2/200] Loss: 1.2778 Train Acc: 67.33% Test Acc: 70.02% Total Spikes: 17904731 Epoch Time: 56.33s LR: 1.0e-05\n",
      "  -> New best test accuracy: 70.02%. Model saved.\n",
      "Epoch [3/200] Loss: 1.0640 Train Acc: 71.96% Test Acc: 72.04% Total Spikes: 18223084 Epoch Time: 56.76s LR: 1.0e-05\n",
      "  -> New best test accuracy: 72.04%. Model saved.\n",
      "Epoch [4/200] Loss: 0.9378 Train Acc: 74.79% Test Acc: 72.88% Total Spikes: 18402291 Epoch Time: 57.22s LR: 1.0e-05\n",
      "  -> New best test accuracy: 72.88%. Model saved.\n",
      "Epoch [5/200] Loss: 0.8442 Train Acc: 77.14% Test Acc: 73.18% Total Spikes: 18508517 Epoch Time: 56.78s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.18%. Model saved.\n",
      "Epoch [6/200] Loss: 0.7678 Train Acc: 78.97% Test Acc: 73.36% Total Spikes: 18728793 Epoch Time: 56.56s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.36%. Model saved.\n",
      "Epoch [7/200] Loss: 0.7044 Train Acc: 80.56% Test Acc: 73.87% Total Spikes: 18822348 Epoch Time: 56.65s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.87%. Model saved.\n",
      "Epoch [8/200] Loss: 0.6503 Train Acc: 81.80% Test Acc: 73.76% Total Spikes: 18833655 Epoch Time: 56.63s LR: 1.0e-05\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 73.87%\n",
      "Epoch [9/200] Loss: 0.5946 Train Acc: 83.36% Test Acc: 74.20% Total Spikes: 19040998 Epoch Time: 56.61s LR: 1.0e-05\n",
      "  -> New best test accuracy: 74.20%. Model saved.\n",
      "Epoch [10/200] Loss: 0.5472 Train Acc: 84.54% Test Acc: 74.24% Total Spikes: 19187180 Epoch Time: 56.50s LR: 1.0e-05\n",
      "  -> New best test accuracy: 74.24%. Model saved.\n",
      "Epoch [11/200] Loss: 0.5051 Train Acc: 85.69% Test Acc: 74.33% Total Spikes: 19251281 Epoch Time: 56.85s LR: 9.9e-06\n",
      "  -> New best test accuracy: 74.33%. Model saved.\n",
      "Epoch [12/200] Loss: 0.4656 Train Acc: 86.77% Test Acc: 73.67% Total Spikes: 19513362 Epoch Time: 56.37s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 74.33%\n",
      "Epoch [13/200] Loss: 0.4295 Train Acc: 87.70% Test Acc: 74.16% Total Spikes: 19517491 Epoch Time: 56.67s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 74.33%\n",
      "Epoch [14/200] Loss: 0.3962 Train Acc: 88.80% Test Acc: 74.25% Total Spikes: 19608275 Epoch Time: 56.65s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 74.33%\n",
      "Epoch [15/200] Loss: 0.3622 Train Acc: 89.70% Test Acc: 73.96% Total Spikes: 19776448 Epoch Time: 56.49s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 74.33%\n",
      "Epoch [16/200] Loss: 0.3339 Train Acc: 90.52% Test Acc: 74.17% Total Spikes: 19808645 Epoch Time: 56.40s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 74.33%\n",
      "Epoch [17/200] Loss: 0.3128 Train Acc: 91.06% Test Acc: 74.14% Total Spikes: 19906814 Epoch Time: 56.66s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 74.33%\n",
      "Epoch [18/200] Loss: 0.2847 Train Acc: 91.86% Test Acc: 74.13% Total Spikes: 19973969 Epoch Time: 56.51s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 74.33%\n",
      "Epoch [19/200] Loss: 0.2663 Train Acc: 92.49% Test Acc: 74.25% Total Spikes: 20018583 Epoch Time: 56.60s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 74.33%\n",
      "Epoch [20/200] Loss: 0.2461 Train Acc: 93.17% Test Acc: 74.10% Total Spikes: 20268912 Epoch Time: 57.06s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 74.33%\n",
      "Epoch [21/200] Loss: 0.2278 Train Acc: 93.69% Test Acc: 74.14% Total Spikes: 20255363 Epoch Time: 56.44s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 74.33%\n",
      "Epoch [22/200] Loss: 0.2105 Train Acc: 94.15% Test Acc: 73.36% Total Spikes: 20398660 Epoch Time: 56.70s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 74.33%\n",
      "Epoch [23/200] Loss: 0.1976 Train Acc: 94.58% Test Acc: 73.50% Total Spikes: 20389822 Epoch Time: 56.75s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 74.33%\n",
      "Epoch [24/200] Loss: 0.1823 Train Acc: 94.98% Test Acc: 73.88% Total Spikes: 20352792 Epoch Time: 56.44s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 74.33%\n",
      "Epoch [25/200] Loss: 0.1683 Train Acc: 95.51% Test Acc: 73.74% Total Spikes: 20434671 Epoch Time: 57.05s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 74.33%\n",
      "Epoch [26/200] Loss: 0.1595 Train Acc: 95.68% Test Acc: 73.21% Total Spikes: 20469268 Epoch Time: 56.52s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 74.33%\n",
      "\n",
      "--- Early stopping triggered after 26 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 74.33%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 74.33%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 11): 19251281\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 19251281\n",
      "--- Proposed (CNN-Osc-SNN Delta=-1.5) finished. Best Acc: 74.33%, Spikes at Convergence (Epoch 11): 19251281, Time: 1578.16s, Epochs Trained: 26 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Proposed (CNN-Osc-SNN Delta=-1.5): Best Acc=74.33, Spikes at Convergence=19251281, Time=1578.16s, Epochs=26, Convergence Epoch=11\n",
      "\n",
      "--- Training Proposed (CNN-Osc-SNN Delta=10.0) for TinyImageNet_ResNet-18_pretrained ---\n",
      "--- Starting Training (Max Epochs: 200, Patience: 15) ---\n",
      "Epoch [1/200] Loss: 2.6033 Train Acc: 46.41% Test Acc: 65.10% Total Spikes: 16379993 Epoch Time: 56.33s LR: 1.0e-05\n",
      "  -> New best test accuracy: 65.10%. Model saved.\n",
      "Epoch [2/200] Loss: 1.3293 Train Acc: 66.95% Test Acc: 69.63% Total Spikes: 16819736 Epoch Time: 56.65s LR: 1.0e-05\n",
      "  -> New best test accuracy: 69.63%. Model saved.\n",
      "Epoch [3/200] Loss: 1.1020 Train Acc: 71.64% Test Acc: 71.93% Total Spikes: 17158437 Epoch Time: 56.07s LR: 1.0e-05\n",
      "  -> New best test accuracy: 71.93%. Model saved.\n",
      "Epoch [4/200] Loss: 0.9720 Train Acc: 74.48% Test Acc: 73.03% Total Spikes: 17227631 Epoch Time: 56.32s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.03%. Model saved.\n",
      "Epoch [5/200] Loss: 0.8792 Train Acc: 76.60% Test Acc: 73.64% Total Spikes: 17435673 Epoch Time: 57.18s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.64%. Model saved.\n",
      "Epoch [6/200] Loss: 0.8070 Train Acc: 78.34% Test Acc: 73.99% Total Spikes: 17494793 Epoch Time: 56.08s LR: 1.0e-05\n",
      "  -> New best test accuracy: 73.99%. Model saved.\n",
      "Epoch [7/200] Loss: 0.7389 Train Acc: 80.17% Test Acc: 73.78% Total Spikes: 17709895 Epoch Time: 56.42s LR: 1.0e-05\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 73.99%\n",
      "Epoch [8/200] Loss: 0.6853 Train Acc: 81.30% Test Acc: 74.14% Total Spikes: 17828193 Epoch Time: 56.72s LR: 1.0e-05\n",
      "  -> New best test accuracy: 74.14%. Model saved.\n",
      "Epoch [9/200] Loss: 0.6379 Train Acc: 82.50% Test Acc: 74.13% Total Spikes: 17950808 Epoch Time: 56.69s LR: 1.0e-05\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 74.14%\n",
      "Epoch [10/200] Loss: 0.5870 Train Acc: 83.92% Test Acc: 74.54% Total Spikes: 17979625 Epoch Time: 56.58s LR: 1.0e-05\n",
      "  -> New best test accuracy: 74.54%. Model saved.\n",
      "Epoch [11/200] Loss: 0.5485 Train Acc: 84.84% Test Acc: 74.41% Total Spikes: 18012661 Epoch Time: 56.67s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 74.54%\n",
      "Epoch [12/200] Loss: 0.5079 Train Acc: 85.78% Test Acc: 74.26% Total Spikes: 17875655 Epoch Time: 56.30s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 74.54%\n",
      "Epoch [13/200] Loss: 0.4704 Train Acc: 86.88% Test Acc: 74.29% Total Spikes: 18197483 Epoch Time: 56.52s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 74.54%\n",
      "Epoch [14/200] Loss: 0.4351 Train Acc: 87.91% Test Acc: 74.56% Total Spikes: 18240135 Epoch Time: 56.62s LR: 9.9e-06\n",
      "  -> New best test accuracy: 74.56%. Model saved.\n",
      "Epoch [15/200] Loss: 0.4023 Train Acc: 88.78% Test Acc: 74.57% Total Spikes: 18382305 Epoch Time: 56.24s LR: 9.9e-06\n",
      "  -> New best test accuracy: 74.57%. Model saved.\n",
      "Epoch [16/200] Loss: 0.3752 Train Acc: 89.52% Test Acc: 74.10% Total Spikes: 18249768 Epoch Time: 56.13s LR: 9.9e-06\n",
      "  -> Test accuracy did not improve for 1 epoch(s). Best: 74.57%\n",
      "Epoch [17/200] Loss: 0.3461 Train Acc: 90.32% Test Acc: 74.16% Total Spikes: 18383269 Epoch Time: 56.39s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 2 epoch(s). Best: 74.57%\n",
      "Epoch [18/200] Loss: 0.3188 Train Acc: 91.14% Test Acc: 74.11% Total Spikes: 18256214 Epoch Time: 56.55s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 3 epoch(s). Best: 74.57%\n",
      "Epoch [19/200] Loss: 0.2984 Train Acc: 91.70% Test Acc: 74.21% Total Spikes: 18348966 Epoch Time: 56.45s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 4 epoch(s). Best: 74.57%\n",
      "Epoch [20/200] Loss: 0.2767 Train Acc: 92.31% Test Acc: 73.96% Total Spikes: 18442497 Epoch Time: 56.17s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 5 epoch(s). Best: 74.57%\n",
      "Epoch [21/200] Loss: 0.2538 Train Acc: 92.98% Test Acc: 73.98% Total Spikes: 18245141 Epoch Time: 56.31s LR: 9.8e-06\n",
      "  -> Test accuracy did not improve for 6 epoch(s). Best: 74.57%\n",
      "Epoch [22/200] Loss: 0.2365 Train Acc: 93.51% Test Acc: 73.81% Total Spikes: 18366142 Epoch Time: 56.02s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 7 epoch(s). Best: 74.57%\n",
      "Epoch [23/200] Loss: 0.2202 Train Acc: 94.00% Test Acc: 73.86% Total Spikes: 18536452 Epoch Time: 56.56s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 8 epoch(s). Best: 74.57%\n",
      "Epoch [24/200] Loss: 0.2081 Train Acc: 94.34% Test Acc: 73.93% Total Spikes: 18653258 Epoch Time: 56.68s LR: 9.7e-06\n",
      "  -> Test accuracy did not improve for 9 epoch(s). Best: 74.57%\n",
      "Epoch [25/200] Loss: 0.1915 Train Acc: 94.83% Test Acc: 73.60% Total Spikes: 18385496 Epoch Time: 56.19s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 10 epoch(s). Best: 74.57%\n",
      "Epoch [26/200] Loss: 0.1786 Train Acc: 95.23% Test Acc: 73.73% Total Spikes: 18738183 Epoch Time: 56.39s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 11 epoch(s). Best: 74.57%\n",
      "Epoch [27/200] Loss: 0.1652 Train Acc: 95.62% Test Acc: 73.14% Total Spikes: 18996593 Epoch Time: 56.33s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 12 epoch(s). Best: 74.57%\n",
      "Epoch [28/200] Loss: 0.1555 Train Acc: 96.02% Test Acc: 73.65% Total Spikes: 18714336 Epoch Time: 56.54s LR: 9.6e-06\n",
      "  -> Test accuracy did not improve for 13 epoch(s). Best: 74.57%\n",
      "Epoch [29/200] Loss: 0.1498 Train Acc: 96.07% Test Acc: 73.55% Total Spikes: 18725583 Epoch Time: 55.99s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 14 epoch(s). Best: 74.57%\n",
      "Epoch [30/200] Loss: 0.1419 Train Acc: 96.38% Test Acc: 73.41% Total Spikes: 18859274 Epoch Time: 56.06s LR: 9.5e-06\n",
      "  -> Test accuracy did not improve for 15 epoch(s). Best: 74.57%\n",
      "\n",
      "--- Early stopping triggered after 30 epochs. ---\n",
      "\n",
      "--- Training finished. Loading best model for final evaluation. ---\n",
      "Successfully loaded best model state (Accuracy: 74.57%)\n",
      "--- Running final evaluation on the best performing model state ---\n",
      "Final Evaluation - Test Accuracy: 74.57%\n",
      "Final Evaluation - Total Spikes at Convergence (Epoch 15): 18382305\n",
      "Final Evaluation - Total Spikes in Final Evaluation: 18382305\n",
      "--- Proposed (CNN-Osc-SNN Delta=10.0) finished. Best Acc: 74.57%, Spikes at Convergence (Epoch 15): 18382305, Time: 1815.30s, Epochs Trained: 30 ---\n",
      "Logged for TinyImageNet_ResNet-18_pretrained - Proposed (CNN-Osc-SNN Delta=10.0): Best Acc=74.57, Spikes at Convergence=18382305, Time=1815.30s, Epochs=30, Convergence Epoch=15\n",
      "\n",
      "--- All models processed for this configuration ---\n",
      "Results saved to experiment_results_TinyImageNet_ResNet-18_pretrained/results.json\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Baseline (CNN-ANN)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Baseline (CNN-SNN)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Proposed (CNN-Lorenz-SNN)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Proposed (CNN-Osc-SNN Delta=-1.5)_spikes.csv\n",
      "Spike data saved to experiment_results_TinyImageNet_ResNet-18_pretrained/TinyImageNet_ResNet-18_pretrained_Proposed (CNN-Osc-SNN Delta=10.0)_spikes.csv\n",
      "Summary table saved to experiment_results_TinyImageNet_ResNet-18_pretrained/summary.csv\n",
      "\n",
      "============================================================\n",
      "实验完成! 结果保存在 'experiment_results_TinyImageNet_ResNet-18_pretrained' 目录中\n",
      "============================================================\n",
      "\n",
      "结果汇总:\n",
      "                      Config Name                             Model Delta/System Best Test Accuracy (%) Spikes at Convergence Training Time (s)  Epochs Trained  Convergence Epoch\n",
      "TinyImageNet_ResNet-18_pretrained                Baseline (CNN-ANN)          ANN                  71.74                     0           1632.26              29                 14\n",
      "TinyImageNet_ResNet-18_pretrained                Baseline (CNN-SNN)   Direct SNN                  74.40              18024711           2031.27              35                 20\n",
      "TinyImageNet_ResNet-18_pretrained         Proposed (CNN-Lorenz-SNN)       Lorenz                  74.21              29690092           1621.83              27                 12\n",
      "TinyImageNet_ResNet-18_pretrained Proposed (CNN-Osc-SNN Delta=-1.5)  Osc(Δ=-1.5)                  74.33              19251281           1578.16              26                 11\n",
      "TinyImageNet_ResNet-18_pretrained Proposed (CNN-Osc-SNN Delta=10.0)  Osc(Δ=10.0)                  74.57              18382305           1815.30              30                 15\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder # Useful for Tiny ImageNet structure\n",
    "import torchvision.transforms as transforms\n",
    "# import matplotlib.pyplot as plt # Keep if needed later\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import copy\n",
    "# from itertools import product # No longer needed for CNN configs\n",
    "import os\n",
    "import json\n",
    "import snntorch as snn\n",
    "import snntorch.surrogate as surrogate\n",
    "from snntorch import utils\n",
    "from snntorch import functional as SF\n",
    "from PIL import Image # Needed for TinyImageNet loading potentially\n",
    "\n",
    "# --- Configuration Class (Updated for Tiny ImageNet & ResNet) ---\n",
    "class Config:\n",
    "    # 数据集\n",
    "    dataset_name = \"TinyImageNet\"\n",
    "    data_root = './tiny-imagenet-200' # <<<--- IMPORTANT: SET PATH TO YOUR TINY IMAGENET FOLDER\n",
    "    batch_size = 64 # May need to reduce based on GPU memory with ResNet\n",
    "    input_size = 224 # Standard input size for ImageNet pre-trained models\n",
    "    num_classes = 200 # Tiny ImageNet has 200 classes\n",
    "\n",
    "    # CNN Backbone (Fixed to ResNet-18)\n",
    "    backbone_name = \"ResNet-18_pretrained\"\n",
    "\n",
    "    # Common SNN/Encoding Parameters\n",
    "    # Projecting 512 ResNet features to 32 might be aggressive.\n",
    "    # Consider increasing chaos_dim, e.g., 128 or 256, for better results.\n",
    "    chaos_dim = 512 # Dimension for projection before oscillator/lorenz/SNN layers\n",
    "    num_steps = 5 # Reduced num_steps initially for faster testing with ResNet\n",
    "\n",
    "    # --- Oscillator Parameters ---\n",
    "    osc_alpha = 2.0\n",
    "    osc_beta = 0.1\n",
    "    osc_gamma = 0.1\n",
    "    osc_omega = 1.0\n",
    "    osc_drive = 0.0\n",
    "    # osc_delta will be set specifically\n",
    "    osc_dt = 0.05\n",
    "\n",
    "    # --- Lorenz Parameters ---\n",
    "    lorenz_sigma = 10.0\n",
    "    lorenz_rho = 28.0\n",
    "    lorenz_beta = 8.0/3.0\n",
    "    lorenz_dt = 0.05\n",
    "\n",
    "    # SNN Decay Rate\n",
    "    beta = 0.95 # SNN Leaky Neuron Beta (Decay Rate)\n",
    "\n",
    "    # 训练\n",
    "    epochs = 200 # Adjust max epochs for Tiny ImageNet & fine-tuning\n",
    "    # Learning rate might need adjustment for fine-tuning ResNet\n",
    "    lr = 1e-4 # Lower initial LR often better for fine-tuning\n",
    "    weight_decay = 5e-4\n",
    "    # Early Stopping\n",
    "    patience = 15 # Maybe increase patience slightly\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "spike_grad = surrogate.fast_sigmoid()\n",
    "\n",
    "# --- OscillatorTransformFast Class (Unchanged) ---\n",
    "class OscillatorTransformFast(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.alpha = config.osc_alpha\n",
    "        self.beta_osc = config.osc_beta\n",
    "        self.gamma = config.osc_gamma\n",
    "        self.delta = getattr(config, 'osc_delta', 0.0)\n",
    "        self.omega = config.osc_omega\n",
    "        self.dt = config.osc_dt\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, dim = x.shape\n",
    "        device = x.device\n",
    "        trajectories = torch.zeros(batch_size, self.num_steps, dim * 3, device=device)\n",
    "        current_delta = self.delta\n",
    "        state = torch.cat([x, x*0.2, -x], dim=1)\n",
    "        trajectories[:, 0, :] = state\n",
    "        for t in range(1, self.num_steps):\n",
    "            x_cur = state[:, :dim]\n",
    "            y_cur = state[:, dim:2 * dim]\n",
    "            z_cur = state[:, 2 * dim:]\n",
    "            dx = y_cur\n",
    "            dy = -self.alpha * x_cur - self.beta_osc * (x_cur**3) - current_delta * y_cur + self.gamma * z_cur\n",
    "            dz = -self.omega * x_cur - current_delta * z_cur + self.gamma * x_cur * y_cur\n",
    "            derivatives = torch.cat([dx, dy, dz], dim=1)\n",
    "            state = state + self.dt * derivatives\n",
    "            trajectories[:, t, :] = state\n",
    "        return trajectories\n",
    "\n",
    "# --- LorenzTransformFast Class (Unchanged) ---\n",
    "class LorenzTransformFast(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.sigma = config.lorenz_sigma\n",
    "        self.rho = config.lorenz_rho\n",
    "        self.lorenz_beta_param = config.lorenz_beta\n",
    "        self.dt = config.lorenz_dt\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, dim = x.shape\n",
    "        device = x.device\n",
    "        trajectories = torch.zeros(batch_size, self.num_steps, dim * 3, device=device)\n",
    "        state = torch.cat([\n",
    "            x,\n",
    "            0.2*x,\n",
    "            -x\n",
    "        ], dim=1)\n",
    "        trajectories[:, 0, :] = state\n",
    "        for t in range(1, self.num_steps):\n",
    "            x_cur = state[:, :dim]\n",
    "            y_cur = state[:, dim:2 * dim]\n",
    "            z_cur = state[:, 2 * dim:]\n",
    "            dx = self.sigma * (y_cur - x_cur)\n",
    "            dy = x_cur * (self.rho - z_cur) - y_cur\n",
    "            dz = x_cur * y_cur - self.lorenz_beta_param * z_cur\n",
    "            state = state + self.dt * torch.cat([dx, dy, dz], dim=1)\n",
    "            trajectories[:, t, :] = state\n",
    "        return trajectories\n",
    "\n",
    "# --- Helper function to get ResNet-18 backbone ---\n",
    "def _get_resnet_backbone(pretrained=True):\n",
    "    \"\"\"Loads a pretrained ResNet-18 model and removes the final fc layer.\"\"\"\n",
    "    if pretrained:\n",
    "        weights = torchvision.models.ResNet18_Weights.IMAGENET1K_V1\n",
    "        model = torchvision.models.resnet18(weights=weights)\n",
    "        print(\"Loaded PRETRAINED ResNet-18 weights.\")\n",
    "    else:\n",
    "        model = torchvision.models.resnet18(weights=None)\n",
    "        print(\"Initialized ResNet-18 weights FROM SCRATCH.\")\n",
    "\n",
    "    # Remove the final fully connected layer (classifier)\n",
    "    model.fc = nn.Identity() # Replace fc layer with identity\n",
    "    return model\n",
    "\n",
    "# --- CNNOscSNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class CNNOscSNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.oscillator = OscillatorTransformFast(config)\n",
    "        self.lif1 = snn.Leaky(beta=config.beta)\n",
    "        self.lif2 = snn.Leaky(beta=config.beta)\n",
    "        self.fc_out = nn.Linear(config.chaos_dim * 3, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, return_spikes=False):\n",
    "        features = self.backbone(x)\n",
    "        x = torch.tanh(self.proj(features))\n",
    "        encoded = self.oscillator(x)\n",
    "        outputs = []\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        batch_total_spikes = 0.0\n",
    "        for step in range(self.num_steps):\n",
    "            cur = encoded[:, step]\n",
    "            spk1, mem1 = self.lif1(cur, mem1)\n",
    "            spk2, mem2 = self.lif2(spk1, mem2)\n",
    "            outputs.append(self.fc_out(spk2))\n",
    "            if return_spikes:\n",
    "                batch_total_spikes += spk1.sum().item() + spk2.sum().item()\n",
    "        final_output = torch.stack(outputs).sum(0)\n",
    "        if return_spikes:\n",
    "            return final_output, torch.tensor(batch_total_spikes, device=final_output.device)\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "# --- CNNLorenzSNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class CNNLorenzSNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.lorenz = LorenzTransformFast(config)\n",
    "        self.lif1 = snn.Leaky(beta=config.beta)\n",
    "        self.lif2 = snn.Leaky(beta=config.beta)\n",
    "        self.fc_out = nn.Linear(config.chaos_dim * 3, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, return_spikes=False):\n",
    "        features = self.backbone(x)\n",
    "        x = torch.tanh(self.proj(features))\n",
    "        encoded = self.lorenz(x)\n",
    "        outputs = []\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        batch_total_spikes = 0.0\n",
    "        for step in range(self.num_steps):\n",
    "            cur = encoded[:, step]\n",
    "            spk1, mem1 = self.lif1(cur, mem1)\n",
    "            spk2, mem2 = self.lif2(spk1, mem2)\n",
    "            outputs.append(self.fc_out(spk2))\n",
    "            if return_spikes:\n",
    "                batch_total_spikes += spk1.sum().item() + spk2.sum().item()\n",
    "        final_output = torch.stack(outputs).sum(0)\n",
    "        if return_spikes:\n",
    "            return final_output, torch.tensor(batch_total_spikes, device=final_output.device)\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "# --- BasicCSNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class BasicCSNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.num_steps = config.num_steps\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.lif1 = snn.Leaky(beta=config.beta)\n",
    "        self.lif2 = snn.Leaky(beta=config.beta)\n",
    "        self.fc_out = nn.Linear(config.chaos_dim, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, return_spikes=False):\n",
    "        features = self.backbone(x)\n",
    "        cnn_features = torch.tanh(self.proj(features))\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        total_output_mem = 0\n",
    "        batch_total_spikes = 0.0\n",
    "        for _ in range(self.num_steps):\n",
    "            spk1, mem1 = self.lif1(cnn_features, mem1)\n",
    "            spk2, mem2 = self.lif2(spk1, mem2)\n",
    "            total_output_mem += self.fc_out(spk2)\n",
    "            if return_spikes:\n",
    "                batch_total_spikes += spk1.sum().item() + spk2.sum().item()\n",
    "        final_output = total_output_mem / self.num_steps\n",
    "        if return_spikes:\n",
    "            return final_output, torch.tensor(batch_total_spikes, device=final_output.device)\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "# --- BaseCNN Class (Unchanged, relies on config.num_classes) ---\n",
    "class BaseCNN(nn.Module):\n",
    "    def __init__(self, config, pretrained_backbone=True):\n",
    "        super().__init__()\n",
    "        self.backbone = _get_resnet_backbone(pretrained=pretrained_backbone)\n",
    "        self.proj = nn.Linear(512, config.chaos_dim)\n",
    "        self.fc1 = nn.Linear(config.chaos_dim, config.chaos_dim)\n",
    "        self.fc2 = nn.Linear(config.chaos_dim, config.chaos_dim)\n",
    "        self.classifier = nn.Linear(config.chaos_dim, config.num_classes) # Automatically uses updated num_classes\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        features = self.backbone(x)\n",
    "        x = torch.tanh(self.proj(features))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# --- 修改后的 Evaluate 函数 - 返回 total_spikes 而不是 average ---\n",
    "def evaluate(model, loader, config):\n",
    "    \"\"\"Evaluates the model, returns accuracy and total spikes.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_spikes_evaluated = 0.0\n",
    "    is_snn = isinstance(model, (CNNOscSNN, BasicCSNN, CNNLorenzSNN))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            if is_snn:\n",
    "                outputs, batch_spikes = model(images, return_spikes=True)\n",
    "                total_spikes_evaluated += batch_spikes.item()\n",
    "            else:\n",
    "                outputs = model(images) # **kwargs in BaseCNN handles extra args\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    # 修改: 返回 total_spikes 而不是平均值\n",
    "    return accuracy, total_spikes_evaluated\n",
    "\n",
    "\n",
    "# --- 修改后的 Train and Evaluate with History ---\n",
    "def train_and_evaluate_with_history(model, train_loader, test_loader, config):\n",
    "    \"\"\"Trains model with early stopping, returns best test acc, epoch history, and spikes at convergence.\"\"\"\n",
    "    model = model.to(device)\n",
    "    # --- OPTIONAL: Differential Learning Rate ---\n",
    "    # You might want different LRs for backbone and head\n",
    "    # Example:\n",
    "    head_params = [p for n, p in model.named_parameters() if not n.startswith('backbone.')]\n",
    "    backbone_params = [p for n, p in model.named_parameters() if n.startswith('backbone.')]\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': backbone_params, 'lr': config.lr * 0.1}, # Lower LR for backbone\n",
    "        {'params': head_params, 'lr': config.lr} # Normal LR for head\n",
    "    ], weight_decay=config.weight_decay)\n",
    "    # --- Using single LR for simplicity now ---\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_test_acc_epoch = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    patience = config.patience\n",
    "    # Ensure output directory exists before saving temp model\n",
    "    output_dir = f\"experiment_results_{config.dataset_name}_{config.backbone_name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True) # Ensure directory exists\n",
    "    best_model_path = os.path.join(output_dir, f\"temp_best_model_{time.time()}_{id(model)}.pth\") # Save inside output dir\n",
    "    \n",
    "    # 修改: 添加 spike 记录\n",
    "    history = []\n",
    "    spike_counts = []  # 记录每个epoch的spikes\n",
    "    best_epoch = 0  # 记录达到最佳性能的epoch\n",
    "\n",
    "    print(f\"--- Starting Training (Max Epochs: {config.epochs}, Patience: {patience}) ---\")\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        start_epoch_time = time.time()\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader): # Add index i for progress printing\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images, return_spikes=False) # No need for spikes during training loop\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                print(f\"WARNING: Loss is {loss.item()} at epoch {epoch+1}, batch {i}. Skipping backward pass.\")\n",
    "                continue # Skip batch if loss is invalid\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Optional: Print progress within epoch\n",
    "            # if (i + 1) % 100 == 0:\n",
    "            #     print(f'  Epoch [{epoch+1}/{config.epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "        end_epoch_time = time.time()\n",
    "        epoch_duration = end_epoch_time - start_epoch_time\n",
    "\n",
    "        # 修改: 在每个epoch结束后评估并记录spikes\n",
    "        test_acc, epoch_spikes = evaluate(model, test_loader, config)\n",
    "        history.append(test_acc)\n",
    "        spike_counts.append(epoch_spikes)  # 记录总spike数\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader) if len(train_loader) > 0 else 0\n",
    "        train_acc = 100. * train_correct / train_total if train_total > 0 else 0\n",
    "\n",
    "        # 修改: 打印spike信息\n",
    "        print(f\"Epoch [{epoch + 1}/{config.epochs}] Loss: {avg_loss:.4f} \"\n",
    "              f\"Train Acc: {train_acc:.2f}% Test Acc: {test_acc:.2f}% \"\n",
    "              f\"Total Spikes: {epoch_spikes:.0f} \"\n",
    "              f\"Epoch Time: {epoch_duration:.2f}s LR: {scheduler.get_last_lr()[0]:.1e}\")\n",
    "\n",
    "        # Early Stopping Logic\n",
    "        if test_acc > best_test_acc_epoch:\n",
    "            best_test_acc_epoch = test_acc\n",
    "            best_epoch = epoch  # 记录最佳epoch索引\n",
    "            epochs_no_improve = 0\n",
    "            try:\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f\"  -> New best test accuracy: {best_test_acc_epoch:.2f}%. Model saved.\")\n",
    "            except Exception as e:\n",
    "                print(f\"  -> Error saving model: {e}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  -> Test accuracy did not improve for {epochs_no_improve} epoch(s). Best: {best_test_acc_epoch:.2f}%\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"\\n--- Early stopping triggered after {epoch + 1} epochs. ---\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Post-Training: Load Best Model and Final Evaluation\n",
    "    print(\"\\n--- Training finished. Loading best model for final evaluation. ---\")\n",
    "    if os.path.exists(best_model_path):\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(best_model_path))\n",
    "            print(f\"Successfully loaded best model state (Accuracy: {best_test_acc_epoch:.2f}%)\")\n",
    "            os.remove(best_model_path)\n",
    "            # print(f\"Removed temporary model file: {best_model_path}\") # Optional: uncomment to confirm\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading best model state from {best_model_path}: {e}. Using model from last epoch.\")\n",
    "            best_test_acc_epoch = history[-1] if history else 0.0\n",
    "    else:\n",
    "        print(\"No best model was saved (or file missing). Using model from last epoch.\")\n",
    "        best_test_acc_epoch = history[-1] if history else 0.0\n",
    "\n",
    "    print(\"--- Running final evaluation on the best performing model state ---\")\n",
    "    final_test_acc, final_total_spikes = evaluate(model, test_loader, config)\n",
    "\n",
    "    # 修改: 获取收敛时的spike数\n",
    "    spikes_at_convergence = spike_counts[best_epoch] if spike_counts and best_epoch < len(spike_counts) else 0\n",
    "\n",
    "    print(f\"Final Evaluation - Test Accuracy: {final_test_acc:.2f}%\")\n",
    "    if isinstance(model, (CNNOscSNN, BasicCSNN, CNNLorenzSNN)):\n",
    "        print(f\"Final Evaluation - Total Spikes at Convergence (Epoch {best_epoch+1}): {spikes_at_convergence:.0f}\")\n",
    "        print(f\"Final Evaluation - Total Spikes in Final Evaluation: {final_total_spikes:.0f}\")\n",
    "\n",
    "    # 修改: 返回收敛时的spikes (不是平均值)\n",
    "    return best_test_acc_epoch, history, spikes_at_convergence, spike_counts\n",
    "\n",
    "# --- Tiny ImageNet Loading Function (未更改) ---\n",
    "def load_tiny_imagenet(config):\n",
    "    \"\"\"Loads the Tiny ImageNet dataset.\"\"\"\n",
    "    data_dir = config.data_root\n",
    "    num_workers = min(4, os.cpu_count()) if os.cpu_count() else 0\n",
    "    image_size = config.input_size # Should be 224 for pre-trained ResNet\n",
    "\n",
    "    # Standard ImageNet normalization\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # Data augmentation and normalization for training\n",
    "    # Adjust augmentation based on standard practices for ImageNet fine-tuning\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size), # Resize first\n",
    "        transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)), # Standard crop\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    # Just normalization for validation/testing\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size), # Ensure validation images are also resized\n",
    "        transforms.CenterCrop(image_size), # Use CenterCrop for validation\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    # --- Dataset Loading ---\n",
    "    # Tiny ImageNet structure: train/[wnid]/images/*.JPEG, val/images/*.JPEG, val/val_annotations.txt\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    val_dir = os.path.join(data_dir, 'val', 'images') # Validation images are flat\n",
    "\n",
    "    if not os.path.exists(train_dir) or not os.path.exists(val_dir):\n",
    "         raise FileNotFoundError(f\"Tiny ImageNet data not found at expected paths: {train_dir} and {val_dir}. \"\n",
    "                                f\"Please ensure Tiny ImageNet is downloaded and extracted to '{data_dir}' \"\n",
    "                                \"following the standard directory structure.\")\n",
    "\n",
    "    train_dataset = ImageFolder(train_dir, transform=train_transform)\n",
    "\n",
    "    # Validation dataset requires special handling due to annotations file\n",
    "    # Creating a custom Dataset class is cleaner\n",
    "    class TinyImageNetVal(Dataset):\n",
    "        def __init__(self, val_dir, annotations_file, class_to_idx, transform=None):\n",
    "            self.val_dir = val_dir\n",
    "            self.transform = transform\n",
    "            self.class_to_idx = class_to_idx\n",
    "            self.samples = []\n",
    "            try:\n",
    "                with open(annotations_file, 'r') as f:\n",
    "                    for line in f:\n",
    "                        parts = line.strip().split('\\t')\n",
    "                        if len(parts) >= 2:\n",
    "                            img_name, wnid = parts[0], parts[1]\n",
    "                            img_path = os.path.join(self.val_dir, img_name)\n",
    "                            if os.path.exists(img_path) and wnid in self.class_to_idx:\n",
    "                                self.samples.append((img_path, self.class_to_idx[wnid]))\n",
    "                            # else:\n",
    "                                # print(f\"Warning: Skipping invalid validation entry: {line.strip()}\")\n",
    "            except FileNotFoundError:\n",
    "                 raise FileNotFoundError(f\"Validation annotations file not found: {annotations_file}\")\n",
    "\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.samples)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img_path, target = self.samples[idx]\n",
    "            # Ensure images are loaded in RGB format\n",
    "            try:\n",
    "                with open(img_path, 'rb') as f:\n",
    "                    img = Image.open(f).convert('RGB')\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "                # Return a dummy image/target or handle appropriately\n",
    "                return torch.zeros(3, image_size, image_size), -1 # Indicate error\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, target\n",
    "\n",
    "    # Need class_to_idx mapping from the training set folders\n",
    "    class_to_idx = train_dataset.class_to_idx\n",
    "    val_annotations_file = os.path.join(data_dir, 'val', 'val_annotations.txt')\n",
    "    val_dataset = TinyImageNetVal(val_dir, val_annotations_file, class_to_idx, transform=val_transform)\n",
    "\n",
    "\n",
    "    print(f\"Tiny ImageNet - Found {len(train_dataset)} training images belonging to {len(train_dataset.classes)} classes.\")\n",
    "    print(f\"Tiny ImageNet - Found {len(val_dataset)} validation images.\")\n",
    "\n",
    "\n",
    "    # Data Loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=config.batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    # Use validation set as the test set for Tiny ImageNet evaluation\n",
    "    test_loader = DataLoader(\n",
    "        val_dataset, batch_size=config.batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "# --- 修改 Experiment Logger Class ---\n",
    "class ExperimentLogger:\n",
    "    def __init__(self, output_dir=\"experiment_results_tinyimagenet_resnet18\"): # Changed dir name\n",
    "        self.results = {}\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        # 修改: 更新CSV标题，将Average Spikes改为Spikes at Convergence\n",
    "        self.csv_headers = [\n",
    "            \"Config Name\", # Renamed from CNN Config\n",
    "            \"Model\",\n",
    "            \"Delta/System\",\n",
    "            \"Best Test Accuracy (%)\",\n",
    "            \"Spikes at Convergence\", # 修改: 更改列名\n",
    "            \"Training Time (s)\",\n",
    "            \"Epochs Trained\",\n",
    "            \"Convergence Epoch\" # 添加收敛epoch的列\n",
    "        ]\n",
    "\n",
    "    def log_config(self, config_name, config):\n",
    "        config_dict = {}\n",
    "        config_dict['patience'] = config.patience\n",
    "        for key, value in vars(config).items():\n",
    "             if isinstance(value, (int, float, str, bool, list, tuple, dict, type(None))):\n",
    "                 config_dict[key] = value\n",
    "             # ... (rest of serialization logic from previous version)\n",
    "        self.results[config_name] = {\n",
    "            \"config\": config_dict,\n",
    "            \"models\": {}\n",
    "        }\n",
    "\n",
    "    # 修改: 更新log_model_result参数和逻辑\n",
    "    def log_model_result(self, config_name, model_name, accuracy, training_time, epochs_history, spikes_at_convergence, spike_counts, best_epoch):\n",
    "        if config_name not in self.results:\n",
    "            self.results[config_name] = {\"config\": {}, \"models\": {}}\n",
    "            print(f\"Warning: Config '{config_name}' not pre-logged. Creating entry.\")\n",
    "        epochs_trained = len(epochs_history)\n",
    "        self.results[config_name][\"models\"][model_name] = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"training_time\": training_time,\n",
    "            \"epochs_history\": epochs_history, # Storing history can make JSON large\n",
    "            \"spikes_at_convergence\": spikes_at_convergence, # 修改: 改为收敛时的spikes\n",
    "            \"epochs_trained\": epochs_trained,\n",
    "            \"spike_counts\": spike_counts, # 添加: 存储每个epoch的spike数据\n",
    "            \"convergence_epoch\": best_epoch + 1 # 添加: 转换为1-indexed的epoch号\n",
    "        }\n",
    "        print(f\"Logged for {config_name} - {model_name}: Best Acc={accuracy:.2f}, Spikes at Convergence={spikes_at_convergence:.0f}, \"\n",
    "              f\"Time={training_time:.2f}s, Epochs={epochs_trained}, Convergence Epoch={best_epoch+1}\")\n",
    "\n",
    "    def save_results(self):\n",
    "        filepath = os.path.join(self.output_dir, \"results.json\")\n",
    "        try:\n",
    "            # Save only essential results to JSON to avoid large files due to history\n",
    "            results_to_save = {}\n",
    "            for cfg_name, cfg_data in self.results.items():\n",
    "                results_to_save[cfg_name] = {\"config\": cfg_data[\"config\"], \"models\": {}}\n",
    "                for mdl_name, mdl_data in cfg_data[\"models\"].items():\n",
    "                    results_to_save[cfg_name][\"models\"][mdl_name] = {\n",
    "                        k: v for k, v in mdl_data.items() if k not in ['epochs_history', 'spike_counts']\n",
    "                    }\n",
    "            with open(filepath, \"w\") as f:\n",
    "                json.dump(results_to_save, f, indent=4, default=lambda o: '<not serializable>')\n",
    "            print(f\"Results saved to {filepath}\")\n",
    "            \n",
    "            # 添加: 保存spike数据到CSV文件\n",
    "            for cfg_name, cfg_data in self.results.items():\n",
    "                for mdl_name, mdl_data in cfg_data[\"models\"].items():\n",
    "                    if 'spike_counts' in mdl_data and mdl_data['spike_counts']:\n",
    "                        spike_df = pd.DataFrame({\n",
    "                            'Epoch': range(1, len(mdl_data['spike_counts'])+1),\n",
    "                            'Total Spikes': mdl_data['spike_counts']\n",
    "                        })\n",
    "                        spike_file = os.path.join(self.output_dir, f\"{cfg_name}_{mdl_name}_spikes.csv\")\n",
    "                        spike_df.to_csv(spike_file, index=False)\n",
    "                        print(f\"Spike data saved to {spike_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving JSON results: {e}\")\n",
    "\n",
    "\n",
    "    def generate_summary_table(self):\n",
    "        rows = []\n",
    "        for config_name, data in self.results.items():\n",
    "            for model_name, model_data in data[\"models\"].items():\n",
    "                delta_str = \"N/A\"\n",
    "                # Simplified model type identification for summary\n",
    "                if \"Osc-SNN Delta=\" in model_name:\n",
    "                    delta_str = f\"Osc(Δ={model_name.split('=')[-1].split(')')[0]})\"\n",
    "                elif \"Lorenz-SNN\" in model_name:\n",
    "                    delta_str = \"Lorenz\"\n",
    "                elif \"CNN-SNN\" in model_name and \"Osc\" not in model_name and \"Lorenz\" not in model_name:\n",
    "                     delta_str = \"Direct SNN\"\n",
    "                elif \"CNN-ANN\" in model_name:\n",
    "                     delta_str = \"ANN\"\n",
    "\n",
    "                spikes = model_data.get(\"spikes_at_convergence\", 0.0)  # 修改: 使用收敛时的spikes\n",
    "                epochs_trained = model_data.get(\"epochs_trained\", \"N/A\")\n",
    "                convergence_epoch = model_data.get(\"convergence_epoch\", \"N/A\")  # 添加: 获取收敛epoch\n",
    "\n",
    "                row = {\n",
    "                    self.csv_headers[0]: config_name, # Use \"Config Name\"\n",
    "                    self.csv_headers[1]: model_name,\n",
    "                    self.csv_headers[2]: delta_str,\n",
    "                    self.csv_headers[3]: model_data[\"accuracy\"],\n",
    "                    self.csv_headers[4]: spikes,  # 修改: 使用收敛时的spikes\n",
    "                    self.csv_headers[5]: model_data[\"training_time\"],\n",
    "                    self.csv_headers[6]: epochs_trained,\n",
    "                    self.csv_headers[7]: convergence_epoch  # 添加: 收敛epoch\n",
    "                }\n",
    "                rows.append(row)\n",
    "        if not rows: return pd.DataFrame(columns=self.csv_headers)\n",
    "        df = pd.DataFrame(rows)\n",
    "        df = df[self.csv_headers] # Ensure column order\n",
    "        try:\n",
    "            df[self.csv_headers[3]] = pd.to_numeric(df[self.csv_headers[3]], errors='coerce').map('{:.2f}'.format)\n",
    "            df[self.csv_headers[4]] = pd.to_numeric(df[self.csv_headers[4]], errors='coerce').map('{:.0f}'.format)  # 修改: 整数格式\n",
    "            df[self.csv_headers[5]] = pd.to_numeric(df[self.csv_headers[5]], errors='coerce').map('{:.2f}'.format)\n",
    "        except Exception as e: print(f\"Error formatting summary table columns: {e}\")\n",
    "        filepath = os.path.join(self.output_dir, \"summary.csv\")\n",
    "        try: df.to_csv(filepath, index=False); print(f\"Summary table saved to {filepath}\")\n",
    "        except Exception as e: print(f\"Error saving summary CSV: {e}\")\n",
    "        return df\n",
    "\n",
    "    # --- Plotting (Requires Matplotlib) ---\n",
    "    # Consider simplifying or removing plotting if matplotlib is not available/needed now\n",
    "    # def plot_results(self):\n",
    "    #     # ... (Plotting code from previous version - needs matplotlib)\n",
    "    #     # If keeping plots, update logic to handle single config name and model types\n",
    "    #     pass\n",
    "\n",
    "# --- 修改 Main Experiment Function ---\n",
    "def run_experiment():\n",
    "    print(f\"使用设备: {device}\")\n",
    "    config = Config() # Use the updated config\n",
    "    config_name = f\"{config.dataset_name}_{config.backbone_name}\" # Single config name\n",
    "    logger = ExperimentLogger(output_dir=f\"experiment_results_{config_name}\")\n",
    "\n",
    "    # Define the specific oscillator deltas for the two modes\n",
    "    # Use values inspired by Table D1, e.g., one expansive, one dissipative\n",
    "    osc_delta_mode_b = -1.5 # High performance potential (Expansive)\n",
    "    osc_delta_mode_a = 10.0 # High efficiency (Dissipative)\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"开始实验配置: {config_name}\")\n",
    "    print(f\"Dataset: {config.dataset_name} (Root: {config.data_root}, Classes: {config.num_classes}, Input Size: {config.input_size})\")\n",
    "    print(f\"Backbone: {config.backbone_name}\")\n",
    "    print(f\"Max Epochs: {config.epochs}, Patience: {config.patience}, LR: {config.lr}\")\n",
    "    print(f\"Osc Params: alpha={config.osc_alpha}, beta={config.osc_beta}, gamma={config.osc_gamma}, omega={config.osc_omega}, dt={config.osc_dt}\")\n",
    "    print(f\"Lorenz Params: sigma={config.lorenz_sigma:.2f}, rho={config.lorenz_rho:.2f}, beta={config.lorenz_beta:.2f}, dt={config.lorenz_dt}\")\n",
    "    print(f\"SNN Params: steps={config.num_steps}, decay_beta={config.beta:.2f}, chaos_dim={config.chaos_dim}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    logger.log_config(config_name, config)\n",
    "\n",
    "    try:\n",
    "        # Load Tiny ImageNet data\n",
    "        train_loader, test_loader = load_tiny_imagenet(config)\n",
    "    except Exception as e:\n",
    "        print(f\"无法加载数据集 {config_name}. 终止实验. 错误: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None # Exit if data loading fails\n",
    "\n",
    "    # --- Define Models to Run ---\n",
    "    # Ensure pretrained_backbone=True is passed correctly\n",
    "    models_to_run = {\n",
    "        \"Baseline (CNN-ANN)\": BaseCNN(config, pretrained_backbone=True),\n",
    "        \"Baseline (CNN-SNN)\": BasicCSNN(config, pretrained_backbone=True),\n",
    "        \"Proposed (CNN-Lorenz-SNN)\": CNNLorenzSNN(config, pretrained_backbone=True)\n",
    "    }\n",
    "    # Add Oscillator SNNs with specific deltas\n",
    "    osc_config_b = copy.deepcopy(config); osc_config_b.osc_delta = osc_delta_mode_b\n",
    "    models_to_run[f\"Proposed (CNN-Osc-SNN Delta={osc_delta_mode_b})\"] = CNNOscSNN(osc_config_b, pretrained_backbone=True)\n",
    "\n",
    "    osc_config_a = copy.deepcopy(config); osc_config_a.osc_delta = osc_delta_mode_a\n",
    "    models_to_run[f\"Proposed (CNN-Osc-SNN Delta={osc_delta_mode_a})\"] = CNNOscSNN(osc_config_a, pretrained_backbone=True)\n",
    "\n",
    "\n",
    "    # --- Train and Evaluate Models ---\n",
    "    for model_name, model_instance in models_to_run.items():\n",
    "        print(f\"\\n--- Training {model_name} for {config_name} ---\")\n",
    "        start_time = time.time()\n",
    "        # Use a fresh copy for each training run (already done by creating new instances above)\n",
    "        current_model = model_instance\n",
    "        current_config = config # Default config for non-oscillator models\n",
    "        if \"Osc-SNN Delta=\" in model_name:\n",
    "             delta_val = float(model_name.split('=')[-1].split(')')[0])\n",
    "             if delta_val == osc_delta_mode_a: current_config = osc_config_a\n",
    "             elif delta_val == osc_delta_mode_b: current_config = osc_config_b\n",
    "             else: print(f\"Warning: Could not match delta for {model_name}\")\n",
    "\n",
    "\n",
    "        try:\n",
    "            # 修改: 添加对spike_counts和best_epoch的接收\n",
    "            best_acc, epochs_history, spikes_at_convergence, spike_counts = train_and_evaluate_with_history(\n",
    "                current_model, train_loader, test_loader, current_config # Pass correct config\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "            \n",
    "            # 计算best_epoch (0-indexed)\n",
    "            best_epoch = epochs_history.index(best_acc) if best_acc in epochs_history else 0\n",
    "            \n",
    "            print(f\"--- {model_name} finished. Best Acc: {best_acc:.2f}%, \"\n",
    "                 f\"Spikes at Convergence (Epoch {best_epoch+1}): {spikes_at_convergence:.0f}, \"\n",
    "                 f\"Time: {training_time:.2f}s, Epochs Trained: {len(epochs_history)} ---\")\n",
    "                 \n",
    "            # 修改: 更新logger.log_model_result调用\n",
    "            logger.log_model_result(\n",
    "                config_name, model_name, best_acc, training_time, \n",
    "                epochs_history, spikes_at_convergence, spike_counts, best_epoch\n",
    "            )\n",
    "        except Exception as e:\n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "            print(f\"!!! ERROR during training/evaluation for {model_name} on {config_name}: {e}\")\n",
    "            # 修改: 更新错误情况下的logger.log_model_result调用\n",
    "            logger.log_model_result(config_name, model_name, 0.0, training_time, [], 0.0, [], 0)\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            # Decide whether to continue with other models upon error\n",
    "            # continue\n",
    "\n",
    "\n",
    "    # --- Finalize and Save Results ---\n",
    "    print(\"\\n--- All models processed for this configuration ---\")\n",
    "    logger.save_results()\n",
    "    summary_df = logger.generate_summary_table()\n",
    "    # try:\n",
    "    #     logger.plot_results() # Optional plotting\n",
    "    # except Exception as e:\n",
    "    #     print(f\"An error occurred during final plotting: {e}\")\n",
    "    #     import traceback\n",
    "    #     traceback.print_exc()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"实验完成! 结果保存在 '{logger.output_dir}' 目录中\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    if not summary_df.empty:\n",
    "        print(\"结果汇总:\")\n",
    "        # Configure pandas for wider output\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', 2000)\n",
    "        pd.set_option('display.max_colwidth', None) # Show full column width\n",
    "        print(summary_df.to_string(index=False)) # Use to_string for better control\n",
    "        pd.reset_option('all') # Reset pandas display options\n",
    "    else:\n",
    "        print(\"结果汇总为空.\")\n",
    "\n",
    "    return logger\n",
    "\n",
    "# --- Run Experiment ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Optional: Set seeds for reproducibility\n",
    "    # seed = 42\n",
    "    # torch.manual_seed(seed)\n",
    "    # np.random.seed(seed)\n",
    "    # if torch.cuda.is_available():\n",
    "    #     torch.cuda.manual_seed_all(seed)\n",
    "    # # Note: Full determinism can impact performance and might not be guaranteed on GPU\n",
    "    # # torch.backends.cudnn.deterministic = True\n",
    "    # # torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    logger = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88209d2-c0d4-4776-a443-4d7fd74ab832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
